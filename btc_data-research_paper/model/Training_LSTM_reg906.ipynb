{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Dependancies**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFJOnSzBk_uB",
    "ExecuteTime": {
     "end_time": "2024-04-15T17:03:10.885906Z",
     "start_time": "2024-04-15T17:03:10.819208Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import *\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from commons import mean_absolute_percentage_error\n",
    "from keras.layers import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import LogCosh"
   ],
   "outputs": [],
   "execution_count": 210
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0HH_FAAlRXx",
    "ExecuteTime": {
     "end_time": "2024-04-15T17:03:13.263577Z",
     "start_time": "2024-04-15T17:03:13.215559Z"
    }
   },
   "source": [
    "PATH_TO_DATA = \"reg_interval1.csv\"\n",
    "data = pd.read_csv(PATH_TO_DATA)"
   ],
   "outputs": [],
   "execution_count": 211
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-15T17:03:14.033796Z",
     "start_time": "2024-04-15T17:03:14.013652Z"
    }
   },
   "source": [
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   difficulty3var  fee_to_rewardUSD  hashrate90std  \\\n",
       "0   -4.294967e+09            24.447   5.438008e+18   \n",
       "1   -5.368709e+09            23.309   5.589062e+18   \n",
       "2   -5.368709e+09            19.255   5.634595e+18   \n",
       "3   -5.368709e+09            13.105   6.187523e+18   \n",
       "4   -5.368709e+09            11.452   6.338603e+18   \n",
       "\n",
       "   mediantransactionvalue90trxUSD  mining_profitability30trx  price14wmaUSD  \\\n",
       "0                           1.707                      0.516          13714   \n",
       "1                           1.716                      0.446          13332   \n",
       "2                           1.722                      0.376          12982   \n",
       "3                           1.715                      0.162          12322   \n",
       "4                           1.705                      0.090          12038   \n",
       "\n",
       "   price30emaUSD  price3wmaUSD  price7smaUSD  price7wmaUSD  price90momUSD  \\\n",
       "0          14124         11780         13261         12798         5091.0   \n",
       "1          13959         11405         12933         12373         5773.0   \n",
       "2          13804         11425         12605         12030         5483.0   \n",
       "3          13456         11694         11695         11707         5555.0   \n",
       "4          13285         11136         11487         11484         5254.0   \n",
       "\n",
       "   top100cap90sma  transactionvalue30smaUSD  transactionvalue90emaUSD  \\\n",
       "0          16.875                     96961                     85113   \n",
       "1          16.886                     96445                     85012   \n",
       "2          16.897                     96146                     85180   \n",
       "3          16.941                     94913                     84139   \n",
       "4          16.958                     94620                     83633   \n",
       "\n",
       "   priceUSD  \n",
       "0     10747  \n",
       "1     11561  \n",
       "2     11560  \n",
       "3     11217  \n",
       "4     10800  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty3var</th>\n",
       "      <th>fee_to_rewardUSD</th>\n",
       "      <th>hashrate90std</th>\n",
       "      <th>mediantransactionvalue90trxUSD</th>\n",
       "      <th>mining_profitability30trx</th>\n",
       "      <th>price14wmaUSD</th>\n",
       "      <th>price30emaUSD</th>\n",
       "      <th>price3wmaUSD</th>\n",
       "      <th>price7smaUSD</th>\n",
       "      <th>price7wmaUSD</th>\n",
       "      <th>price90momUSD</th>\n",
       "      <th>top100cap90sma</th>\n",
       "      <th>transactionvalue30smaUSD</th>\n",
       "      <th>transactionvalue90emaUSD</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.294967e+09</td>\n",
       "      <td>24.447</td>\n",
       "      <td>5.438008e+18</td>\n",
       "      <td>1.707</td>\n",
       "      <td>0.516</td>\n",
       "      <td>13714</td>\n",
       "      <td>14124</td>\n",
       "      <td>11780</td>\n",
       "      <td>13261</td>\n",
       "      <td>12798</td>\n",
       "      <td>5091.0</td>\n",
       "      <td>16.875</td>\n",
       "      <td>96961</td>\n",
       "      <td>85113</td>\n",
       "      <td>10747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>23.309</td>\n",
       "      <td>5.589062e+18</td>\n",
       "      <td>1.716</td>\n",
       "      <td>0.446</td>\n",
       "      <td>13332</td>\n",
       "      <td>13959</td>\n",
       "      <td>11405</td>\n",
       "      <td>12933</td>\n",
       "      <td>12373</td>\n",
       "      <td>5773.0</td>\n",
       "      <td>16.886</td>\n",
       "      <td>96445</td>\n",
       "      <td>85012</td>\n",
       "      <td>11561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>19.255</td>\n",
       "      <td>5.634595e+18</td>\n",
       "      <td>1.722</td>\n",
       "      <td>0.376</td>\n",
       "      <td>12982</td>\n",
       "      <td>13804</td>\n",
       "      <td>11425</td>\n",
       "      <td>12605</td>\n",
       "      <td>12030</td>\n",
       "      <td>5483.0</td>\n",
       "      <td>16.897</td>\n",
       "      <td>96146</td>\n",
       "      <td>85180</td>\n",
       "      <td>11560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>13.105</td>\n",
       "      <td>6.187523e+18</td>\n",
       "      <td>1.715</td>\n",
       "      <td>0.162</td>\n",
       "      <td>12322</td>\n",
       "      <td>13456</td>\n",
       "      <td>11694</td>\n",
       "      <td>11695</td>\n",
       "      <td>11707</td>\n",
       "      <td>5555.0</td>\n",
       "      <td>16.941</td>\n",
       "      <td>94913</td>\n",
       "      <td>84139</td>\n",
       "      <td>11217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>11.452</td>\n",
       "      <td>6.338603e+18</td>\n",
       "      <td>1.705</td>\n",
       "      <td>0.090</td>\n",
       "      <td>12038</td>\n",
       "      <td>13285</td>\n",
       "      <td>11136</td>\n",
       "      <td>11487</td>\n",
       "      <td>11484</td>\n",
       "      <td>5254.0</td>\n",
       "      <td>16.958</td>\n",
       "      <td>94620</td>\n",
       "      <td>83633</td>\n",
       "      <td>10800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 212
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:03:24.923192Z",
     "start_time": "2024-04-15T17:03:24.903678Z"
    }
   },
   "source": [
    "data.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(866, 15)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 213
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:03.587257Z",
     "start_time": "2024-04-15T17:05:03.574676Z"
    }
   },
   "cell_type": "code",
   "source": "X = data",
   "outputs": [],
   "execution_count": 220
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:48.059119Z",
     "start_time": "2024-04-15T17:05:48.037780Z"
    }
   },
   "cell_type": "code",
   "source": "X",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     difficulty3var  fee_to_rewardUSD  hashrate90std  \\\n",
       "0     -4.294967e+09            24.447   5.438008e+18   \n",
       "1     -5.368709e+09            23.309   5.589062e+18   \n",
       "2     -5.368709e+09            19.255   5.634595e+18   \n",
       "3     -5.368709e+09            13.105   6.187523e+18   \n",
       "4     -5.368709e+09            11.452   6.338603e+18   \n",
       "..              ...               ...            ...   \n",
       "861    0.000000e+00             7.662   2.259369e+19   \n",
       "862    1.374390e+11             6.213   2.227210e+19   \n",
       "863    1.191951e+22             3.487   2.261118e+19   \n",
       "864    8.458707e+22             4.637   2.262627e+19   \n",
       "865    4.859933e+22             6.082   2.255474e+19   \n",
       "\n",
       "     mediantransactionvalue90trxUSD  mining_profitability30trx  price14wmaUSD  \\\n",
       "0                             1.707                      0.516          13714   \n",
       "1                             1.716                      0.446          13332   \n",
       "2                             1.722                      0.376          12982   \n",
       "3                             1.715                      0.162          12322   \n",
       "4                             1.705                      0.090          12038   \n",
       "..                              ...                        ...            ...   \n",
       "861                           0.239                     -0.269          11180   \n",
       "862                           0.236                     -0.263          11230   \n",
       "863                           0.233                     -0.258          11270   \n",
       "864                           0.230                     -0.258          11313   \n",
       "865                           0.226                     -0.255          11368   \n",
       "\n",
       "     price30emaUSD  price3wmaUSD  price7smaUSD  price7wmaUSD  price90momUSD  \\\n",
       "0            14124         11780         13261         12798         5091.0   \n",
       "1            13959         11405         12933         12373         5773.0   \n",
       "2            13804         11425         12605         12030         5483.0   \n",
       "3            13456         11694         11695         11707         5555.0   \n",
       "4            13285         11136         11487         11484         5254.0   \n",
       "..             ...           ...           ...           ...            ...   \n",
       "861          10963         11421         11345         11400         2248.0   \n",
       "862          10989         11392         11400         11406         2169.0   \n",
       "863          11012         11367         11402         11393         2151.0   \n",
       "864          11040         11395         11412         11401         2213.0   \n",
       "865          11075         11494         11431         11444         2240.0   \n",
       "\n",
       "     top100cap90sma  transactionvalue30smaUSD  transactionvalue90emaUSD  \\\n",
       "0            16.875                     96961                     85113   \n",
       "1            16.886                     96445                     85012   \n",
       "2            16.897                     96146                     85180   \n",
       "3            16.941                     94913                     84139   \n",
       "4            16.958                     94620                     83633   \n",
       "..              ...                       ...                       ...   \n",
       "861          14.235                     86920                     70692   \n",
       "862          14.232                     86438                     70954   \n",
       "863          14.229                     85452                     71592   \n",
       "864          14.226                     84709                     72328   \n",
       "865          14.222                     85497                     73596   \n",
       "\n",
       "     priceUSD  \n",
       "0       10747  \n",
       "1       11561  \n",
       "2       11560  \n",
       "3       11217  \n",
       "4       10800  \n",
       "..        ...  \n",
       "861     11417  \n",
       "862     11370  \n",
       "863     11348  \n",
       "864     11433  \n",
       "865     11582  \n",
       "\n",
       "[866 rows x 15 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty3var</th>\n",
       "      <th>fee_to_rewardUSD</th>\n",
       "      <th>hashrate90std</th>\n",
       "      <th>mediantransactionvalue90trxUSD</th>\n",
       "      <th>mining_profitability30trx</th>\n",
       "      <th>price14wmaUSD</th>\n",
       "      <th>price30emaUSD</th>\n",
       "      <th>price3wmaUSD</th>\n",
       "      <th>price7smaUSD</th>\n",
       "      <th>price7wmaUSD</th>\n",
       "      <th>price90momUSD</th>\n",
       "      <th>top100cap90sma</th>\n",
       "      <th>transactionvalue30smaUSD</th>\n",
       "      <th>transactionvalue90emaUSD</th>\n",
       "      <th>priceUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.294967e+09</td>\n",
       "      <td>24.447</td>\n",
       "      <td>5.438008e+18</td>\n",
       "      <td>1.707</td>\n",
       "      <td>0.516</td>\n",
       "      <td>13714</td>\n",
       "      <td>14124</td>\n",
       "      <td>11780</td>\n",
       "      <td>13261</td>\n",
       "      <td>12798</td>\n",
       "      <td>5091.0</td>\n",
       "      <td>16.875</td>\n",
       "      <td>96961</td>\n",
       "      <td>85113</td>\n",
       "      <td>10747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>23.309</td>\n",
       "      <td>5.589062e+18</td>\n",
       "      <td>1.716</td>\n",
       "      <td>0.446</td>\n",
       "      <td>13332</td>\n",
       "      <td>13959</td>\n",
       "      <td>11405</td>\n",
       "      <td>12933</td>\n",
       "      <td>12373</td>\n",
       "      <td>5773.0</td>\n",
       "      <td>16.886</td>\n",
       "      <td>96445</td>\n",
       "      <td>85012</td>\n",
       "      <td>11561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>19.255</td>\n",
       "      <td>5.634595e+18</td>\n",
       "      <td>1.722</td>\n",
       "      <td>0.376</td>\n",
       "      <td>12982</td>\n",
       "      <td>13804</td>\n",
       "      <td>11425</td>\n",
       "      <td>12605</td>\n",
       "      <td>12030</td>\n",
       "      <td>5483.0</td>\n",
       "      <td>16.897</td>\n",
       "      <td>96146</td>\n",
       "      <td>85180</td>\n",
       "      <td>11560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>13.105</td>\n",
       "      <td>6.187523e+18</td>\n",
       "      <td>1.715</td>\n",
       "      <td>0.162</td>\n",
       "      <td>12322</td>\n",
       "      <td>13456</td>\n",
       "      <td>11694</td>\n",
       "      <td>11695</td>\n",
       "      <td>11707</td>\n",
       "      <td>5555.0</td>\n",
       "      <td>16.941</td>\n",
       "      <td>94913</td>\n",
       "      <td>84139</td>\n",
       "      <td>11217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.368709e+09</td>\n",
       "      <td>11.452</td>\n",
       "      <td>6.338603e+18</td>\n",
       "      <td>1.705</td>\n",
       "      <td>0.090</td>\n",
       "      <td>12038</td>\n",
       "      <td>13285</td>\n",
       "      <td>11136</td>\n",
       "      <td>11487</td>\n",
       "      <td>11484</td>\n",
       "      <td>5254.0</td>\n",
       "      <td>16.958</td>\n",
       "      <td>94620</td>\n",
       "      <td>83633</td>\n",
       "      <td>10800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.662</td>\n",
       "      <td>2.259369e+19</td>\n",
       "      <td>0.239</td>\n",
       "      <td>-0.269</td>\n",
       "      <td>11180</td>\n",
       "      <td>10963</td>\n",
       "      <td>11421</td>\n",
       "      <td>11345</td>\n",
       "      <td>11400</td>\n",
       "      <td>2248.0</td>\n",
       "      <td>14.235</td>\n",
       "      <td>86920</td>\n",
       "      <td>70692</td>\n",
       "      <td>11417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1.374390e+11</td>\n",
       "      <td>6.213</td>\n",
       "      <td>2.227210e+19</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>11230</td>\n",
       "      <td>10989</td>\n",
       "      <td>11392</td>\n",
       "      <td>11400</td>\n",
       "      <td>11406</td>\n",
       "      <td>2169.0</td>\n",
       "      <td>14.232</td>\n",
       "      <td>86438</td>\n",
       "      <td>70954</td>\n",
       "      <td>11370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>1.191951e+22</td>\n",
       "      <td>3.487</td>\n",
       "      <td>2.261118e+19</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>11270</td>\n",
       "      <td>11012</td>\n",
       "      <td>11367</td>\n",
       "      <td>11402</td>\n",
       "      <td>11393</td>\n",
       "      <td>2151.0</td>\n",
       "      <td>14.229</td>\n",
       "      <td>85452</td>\n",
       "      <td>71592</td>\n",
       "      <td>11348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>8.458707e+22</td>\n",
       "      <td>4.637</td>\n",
       "      <td>2.262627e+19</td>\n",
       "      <td>0.230</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>11313</td>\n",
       "      <td>11040</td>\n",
       "      <td>11395</td>\n",
       "      <td>11412</td>\n",
       "      <td>11401</td>\n",
       "      <td>2213.0</td>\n",
       "      <td>14.226</td>\n",
       "      <td>84709</td>\n",
       "      <td>72328</td>\n",
       "      <td>11433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>4.859933e+22</td>\n",
       "      <td>6.082</td>\n",
       "      <td>2.255474e+19</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.255</td>\n",
       "      <td>11368</td>\n",
       "      <td>11075</td>\n",
       "      <td>11494</td>\n",
       "      <td>11431</td>\n",
       "      <td>11444</td>\n",
       "      <td>2240.0</td>\n",
       "      <td>14.222</td>\n",
       "      <td>85497</td>\n",
       "      <td>73596</td>\n",
       "      <td>11582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>866 rows × 15 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 236
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSzHTpuzmScU",
    "ExecuteTime": {
     "end_time": "2024-04-15T17:03:54.654348Z",
     "start_time": "2024-04-15T17:03:54.649349Z"
    }
   },
   "source": "#X = data.iloc[:,:-1]",
   "outputs": [],
   "execution_count": 215
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:03:57.335913Z",
     "start_time": "2024-04-15T17:03:57.323414Z"
    }
   },
   "source": "#y=data.iloc[:,-1:]",
   "outputs": [],
   "execution_count": 216
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:04:26.662679Z",
     "start_time": "2024-04-15T17:04:26.646178Z"
    }
   },
   "cell_type": "code",
   "source": "y = data['priceUSD'].shift(-1,fill_value=1)",
   "outputs": [],
   "execution_count": 218
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:04:28.222274Z",
     "start_time": "2024-04-15T17:04:28.207827Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      11561\n",
       "1      11560\n",
       "2      11217\n",
       "3      10800\n",
       "4      11094\n",
       "       ...  \n",
       "861    11370\n",
       "862    11348\n",
       "863    11433\n",
       "864    11582\n",
       "865        1\n",
       "Name: priceUSD, Length: 866, dtype: int64"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 219
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:07.615269Z",
     "start_time": "2024-04-15T17:05:07.570767Z"
    }
   },
   "source": [
    "X_train, X_test, y_train, y_test =train_test_split(X,y, test_size=0.2, train_size=0.8, shuffle=True, random_state=7)"
   ],
   "outputs": [],
   "execution_count": 221
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:08.340921Z",
     "start_time": "2024-04-15T17:05:08.334920Z"
    }
   },
   "source": [
    "X_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 15)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 222
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:10.744001Z",
     "start_time": "2024-04-15T17:05:10.729498Z"
    }
   },
   "source": [
    "estimators=[]"
   ],
   "outputs": [],
   "execution_count": 223
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:11.794631Z",
     "start_time": "2024-04-15T17:05:11.779634Z"
    }
   },
   "source": [
    "estimators.append(['robust',RobustScaler()])"
   ],
   "outputs": [],
   "execution_count": 224
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:12.349104Z",
     "start_time": "2024-04-15T17:05:12.344604Z"
    }
   },
   "source": [
    "estimators.append(['mixmax',MinMaxScaler()])"
   ],
   "outputs": [],
   "execution_count": 225
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:13.631119Z",
     "start_time": "2024-04-15T17:05:13.617113Z"
    }
   },
   "source": [
    "scale=Pipeline(estimators,verbose=True)"
   ],
   "outputs": [],
   "execution_count": 226
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDojXgA7mpWa",
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:14.402723Z",
     "start_time": "2024-04-15T17:05:14.358223Z"
    }
   },
   "source": [
    "X_train=scale.fit_transform(X_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing robust, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing mixmax, total=   0.0s\n"
     ]
    }
   ],
   "execution_count": 227
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:15.638763Z",
     "start_time": "2024-04-15T17:05:15.626740Z"
    }
   },
   "source": [
    "X_test=scale.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 228
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:16.270957Z",
     "start_time": "2024-04-15T17:05:16.252310Z"
    }
   },
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))"
   ],
   "outputs": [],
   "execution_count": 229
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:17.134730Z",
     "start_time": "2024-04-15T17:05:17.126693Z"
    }
   },
   "source": [
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))"
   ],
   "outputs": [],
   "execution_count": 230
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wNcl2z_JKkM",
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:21.408370Z",
     "start_time": "2024-04-15T17:05:21.401370Z"
    }
   },
   "source": [
    "y_train=y_train.values"
   ],
   "outputs": [],
   "execution_count": 231
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:21.854756Z",
     "start_time": "2024-04-15T17:05:21.836009Z"
    }
   },
   "source": [
    "y_train=np.reshape(y_train, (y_train.shape[0],1,1))"
   ],
   "outputs": [],
   "execution_count": 232
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:22.457475Z",
     "start_time": "2024-04-15T17:05:22.451475Z"
    }
   },
   "source": [
    "y_test=y_test.values"
   ],
   "outputs": [],
   "execution_count": 233
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:24.214866Z",
     "start_time": "2024-04-15T17:05:24.206368Z"
    }
   },
   "source": [
    "y_test=np.reshape(y_test,(y_test.shape[0],1,1))"
   ],
   "outputs": [],
   "execution_count": 234
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:58.266089Z",
     "start_time": "2024-04-15T17:05:58.263384Z"
    }
   },
   "source": "X_train.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 1, 15)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 237
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:05:59.145616Z",
     "start_time": "2024-04-15T17:05:59.129258Z"
    }
   },
   "cell_type": "code",
   "source": "X_train",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.68717216e-13, 2.86952897e-01, 6.31738238e-02, ...,\n",
       "         8.02423045e-02, 2.00253448e-02, 3.13203301e-01]],\n",
       "\n",
       "       [[1.44614757e-13, 1.96331805e-02, 7.74825760e-01, ...,\n",
       "         1.99576087e-01, 1.49239656e-01, 7.54813703e-01]],\n",
       "\n",
       "       [[7.21955219e-03, 3.96415173e-02, 8.73710263e-01, ...,\n",
       "         1.35507491e-01, 3.49964635e-01, 5.74018505e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.44614757e-13, 3.86411005e-02, 6.81518733e-01, ...,\n",
       "         2.15605280e-01, 2.67240363e-01, 6.14528632e-01]],\n",
       "\n",
       "       [[6.32689560e-14, 1.32972072e-02, 2.20769253e-01, ...,\n",
       "         2.03453924e-01, 3.06421667e-01, 4.30982746e-01]],\n",
       "\n",
       "       [[6.32689560e-14, 1.82992914e-02, 1.68618009e-01, ...,\n",
       "         2.48036996e-01, 3.67632323e-01, 3.05076269e-01]]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 238
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:06:00.703585Z",
     "start_time": "2024-04-15T17:06:00.696584Z"
    }
   },
   "cell_type": "code",
   "source": "y_train.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(692, 1, 1)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 239
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:06:34.201724Z",
     "start_time": "2024-04-15T17:06:34.173219Z"
    }
   },
   "cell_type": "code",
   "source": "y_train",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 6807]],\n",
       "\n",
       "       [[ 9755]],\n",
       "\n",
       "       [[ 8340]],\n",
       "\n",
       "       [[ 9917]],\n",
       "\n",
       "       [[10237]],\n",
       "\n",
       "       [[ 9039]],\n",
       "\n",
       "       [[ 9968]],\n",
       "\n",
       "       [[10058]],\n",
       "\n",
       "       [[ 8559]],\n",
       "\n",
       "       [[ 9224]],\n",
       "\n",
       "       [[11297]],\n",
       "\n",
       "       [[ 7953]],\n",
       "\n",
       "       [[10404]],\n",
       "\n",
       "       [[10447]],\n",
       "\n",
       "       [[ 6799]],\n",
       "\n",
       "       [[10082]],\n",
       "\n",
       "       [[ 6526]],\n",
       "\n",
       "       [[ 6097]],\n",
       "\n",
       "       [[ 6405]],\n",
       "\n",
       "       [[ 7250]],\n",
       "\n",
       "       [[11521]],\n",
       "\n",
       "       [[ 7400]],\n",
       "\n",
       "       [[11614]],\n",
       "\n",
       "       [[10319]],\n",
       "\n",
       "       [[ 3933]],\n",
       "\n",
       "       [[ 8704]],\n",
       "\n",
       "       [[ 9457]],\n",
       "\n",
       "       [[ 8199]],\n",
       "\n",
       "       [[ 7211]],\n",
       "\n",
       "       [[ 6442]],\n",
       "\n",
       "       [[10289]],\n",
       "\n",
       "       [[ 3900]],\n",
       "\n",
       "       [[ 7583]],\n",
       "\n",
       "       [[ 8180]],\n",
       "\n",
       "       [[ 8081]],\n",
       "\n",
       "       [[10469]],\n",
       "\n",
       "       [[11801]],\n",
       "\n",
       "       [[ 9490]],\n",
       "\n",
       "       [[ 3935]],\n",
       "\n",
       "       [[ 7127]],\n",
       "\n",
       "       [[10566]],\n",
       "\n",
       "       [[ 8214]],\n",
       "\n",
       "       [[11403]],\n",
       "\n",
       "       [[10331]],\n",
       "\n",
       "       [[ 6568]],\n",
       "\n",
       "       [[11563]],\n",
       "\n",
       "       [[ 9087]],\n",
       "\n",
       "       [[ 7107]],\n",
       "\n",
       "       [[ 6666]],\n",
       "\n",
       "       [[ 8907]],\n",
       "\n",
       "       [[ 7274]],\n",
       "\n",
       "       [[ 7541]],\n",
       "\n",
       "       [[ 8171]],\n",
       "\n",
       "       [[ 9210]],\n",
       "\n",
       "       [[ 9055]],\n",
       "\n",
       "       [[ 8854]],\n",
       "\n",
       "       [[ 3823]],\n",
       "\n",
       "       [[ 5278]],\n",
       "\n",
       "       [[ 6330]],\n",
       "\n",
       "       [[ 3915]],\n",
       "\n",
       "       [[11383]],\n",
       "\n",
       "       [[ 9706]],\n",
       "\n",
       "       [[ 6410]],\n",
       "\n",
       "       [[10104]],\n",
       "\n",
       "       [[ 6085]],\n",
       "\n",
       "       [[ 3942]],\n",
       "\n",
       "       [[ 6733]],\n",
       "\n",
       "       [[ 6408]],\n",
       "\n",
       "       [[ 7810]],\n",
       "\n",
       "       [[ 9365]],\n",
       "\n",
       "       [[ 9279]],\n",
       "\n",
       "       [[ 7580]],\n",
       "\n",
       "       [[ 8657]],\n",
       "\n",
       "       [[ 7929]],\n",
       "\n",
       "       [[ 6502]],\n",
       "\n",
       "       [[ 7217]],\n",
       "\n",
       "       [[ 8176]],\n",
       "\n",
       "       [[ 8776]],\n",
       "\n",
       "       [[ 7501]],\n",
       "\n",
       "       [[10287]],\n",
       "\n",
       "       [[ 6278]],\n",
       "\n",
       "       [[ 6610]],\n",
       "\n",
       "       [[ 7283]],\n",
       "\n",
       "       [[ 7025]],\n",
       "\n",
       "       [[ 8767]],\n",
       "\n",
       "       [[ 8652]],\n",
       "\n",
       "       [[ 6284]],\n",
       "\n",
       "       [[ 8922]],\n",
       "\n",
       "       [[10928]],\n",
       "\n",
       "       [[10614]],\n",
       "\n",
       "       [[11217]],\n",
       "\n",
       "       [[ 6463]],\n",
       "\n",
       "       [[ 9374]],\n",
       "\n",
       "       [[ 3819]],\n",
       "\n",
       "       [[ 9793]],\n",
       "\n",
       "       [[ 6454]],\n",
       "\n",
       "       [[ 8713]],\n",
       "\n",
       "       [[ 7868]],\n",
       "\n",
       "       [[ 8236]],\n",
       "\n",
       "       [[ 7360]],\n",
       "\n",
       "       [[ 8556]],\n",
       "\n",
       "       [[10737]],\n",
       "\n",
       "       [[ 9049]],\n",
       "\n",
       "       [[ 7328]],\n",
       "\n",
       "       [[ 8697]],\n",
       "\n",
       "       [[ 6574]],\n",
       "\n",
       "       [[ 8589]],\n",
       "\n",
       "       [[ 6889]],\n",
       "\n",
       "       [[ 9939]],\n",
       "\n",
       "       [[ 6195]],\n",
       "\n",
       "       [[ 6507]],\n",
       "\n",
       "       [[ 6543]],\n",
       "\n",
       "       [[ 6691]],\n",
       "\n",
       "       [[ 9220]],\n",
       "\n",
       "       [[ 6451]],\n",
       "\n",
       "       [[ 9462]],\n",
       "\n",
       "       [[ 6134]],\n",
       "\n",
       "       [[ 9719]],\n",
       "\n",
       "       [[11098]],\n",
       "\n",
       "       [[ 8260]],\n",
       "\n",
       "       [[11461]],\n",
       "\n",
       "       [[ 4004]],\n",
       "\n",
       "       [[ 8778]],\n",
       "\n",
       "       [[ 7598]],\n",
       "\n",
       "       [[ 6450]],\n",
       "\n",
       "       [[ 9302]],\n",
       "\n",
       "       [[ 8327]],\n",
       "\n",
       "       [[11342]],\n",
       "\n",
       "       [[ 8894]],\n",
       "\n",
       "       [[ 7150]],\n",
       "\n",
       "       [[ 9728]],\n",
       "\n",
       "       [[ 9444]],\n",
       "\n",
       "       [[ 9421]],\n",
       "\n",
       "       [[10191]],\n",
       "\n",
       "       [[ 8378]],\n",
       "\n",
       "       [[ 8209]],\n",
       "\n",
       "       [[ 8549]],\n",
       "\n",
       "       [[ 9050]],\n",
       "\n",
       "       [[ 3837]],\n",
       "\n",
       "       [[10800]],\n",
       "\n",
       "       [[ 8360]],\n",
       "\n",
       "       [[ 7114]],\n",
       "\n",
       "       [[10868]],\n",
       "\n",
       "       [[ 9004]],\n",
       "\n",
       "       [[ 6947]],\n",
       "\n",
       "       [[ 3889]],\n",
       "\n",
       "       [[ 9445]],\n",
       "\n",
       "       [[ 9170]],\n",
       "\n",
       "       [[ 6852]],\n",
       "\n",
       "       [[ 3829]],\n",
       "\n",
       "       [[ 6044]],\n",
       "\n",
       "       [[ 7361]],\n",
       "\n",
       "       [[ 6470]],\n",
       "\n",
       "       [[ 6528]],\n",
       "\n",
       "       [[ 8973]],\n",
       "\n",
       "       [[ 9894]],\n",
       "\n",
       "       [[10902]],\n",
       "\n",
       "       [[ 7934]],\n",
       "\n",
       "       [[10778]],\n",
       "\n",
       "       [[ 8297]],\n",
       "\n",
       "       [[ 8337]],\n",
       "\n",
       "       [[ 8291]],\n",
       "\n",
       "       [[ 7726]],\n",
       "\n",
       "       [[ 6799]],\n",
       "\n",
       "       [[10035]],\n",
       "\n",
       "       [[10058]],\n",
       "\n",
       "       [[ 3833]],\n",
       "\n",
       "       [[ 7938]],\n",
       "\n",
       "       [[ 6398]],\n",
       "\n",
       "       [[ 9362]],\n",
       "\n",
       "       [[ 9649]],\n",
       "\n",
       "       [[ 9201]],\n",
       "\n",
       "       [[ 6893]],\n",
       "\n",
       "       [[11141]],\n",
       "\n",
       "       [[ 7980]],\n",
       "\n",
       "       [[ 8720]],\n",
       "\n",
       "       [[ 6483]],\n",
       "\n",
       "       [[11059]],\n",
       "\n",
       "       [[ 7128]],\n",
       "\n",
       "       [[ 6351]],\n",
       "\n",
       "       [[ 6696]],\n",
       "\n",
       "       [[ 6745]],\n",
       "\n",
       "       [[ 8662]],\n",
       "\n",
       "       [[ 3988]],\n",
       "\n",
       "       [[ 8146]],\n",
       "\n",
       "       [[ 7367]],\n",
       "\n",
       "       [[ 6146]],\n",
       "\n",
       "       [[ 9659]],\n",
       "\n",
       "       [[ 9932]],\n",
       "\n",
       "       [[ 7310]],\n",
       "\n",
       "       [[ 9850]],\n",
       "\n",
       "       [[ 9219]],\n",
       "\n",
       "       [[ 7979]],\n",
       "\n",
       "       [[10058]],\n",
       "\n",
       "       [[ 6581]],\n",
       "\n",
       "       [[ 7355]],\n",
       "\n",
       "       [[10266]],\n",
       "\n",
       "       [[10205]],\n",
       "\n",
       "       [[ 9176]],\n",
       "\n",
       "       [[10575]],\n",
       "\n",
       "       [[ 7469]],\n",
       "\n",
       "       [[ 3916]],\n",
       "\n",
       "       [[10781]],\n",
       "\n",
       "       [[10219]],\n",
       "\n",
       "       [[ 3958]],\n",
       "\n",
       "       [[10851]],\n",
       "\n",
       "       [[ 9934]],\n",
       "\n",
       "       [[10986]],\n",
       "\n",
       "       [[ 6406]],\n",
       "\n",
       "       [[ 7748]],\n",
       "\n",
       "       [[11772]],\n",
       "\n",
       "       [[ 9258]],\n",
       "\n",
       "       [[ 7388]],\n",
       "\n",
       "       [[ 9397]],\n",
       "\n",
       "       [[ 8537]],\n",
       "\n",
       "       [[11803]],\n",
       "\n",
       "       [[10900]],\n",
       "\n",
       "       [[ 8242]],\n",
       "\n",
       "       [[ 6592]],\n",
       "\n",
       "       [[ 4020]],\n",
       "\n",
       "       [[ 9252]],\n",
       "\n",
       "       [[ 7615]],\n",
       "\n",
       "       [[ 3989]],\n",
       "\n",
       "       [[11271]],\n",
       "\n",
       "       [[11294]],\n",
       "\n",
       "       [[ 9245]],\n",
       "\n",
       "       [[ 9261]],\n",
       "\n",
       "       [[ 6314]],\n",
       "\n",
       "       [[ 8021]],\n",
       "\n",
       "       [[ 8261]],\n",
       "\n",
       "       [[10666]],\n",
       "\n",
       "       [[ 3984]],\n",
       "\n",
       "       [[ 9798]],\n",
       "\n",
       "       [[ 9688]],\n",
       "\n",
       "       [[ 6252]],\n",
       "\n",
       "       [[ 6361]],\n",
       "\n",
       "       [[11466]],\n",
       "\n",
       "       [[ 6307]],\n",
       "\n",
       "       [[10710]],\n",
       "\n",
       "       [[ 8030]],\n",
       "\n",
       "       [[ 9285]],\n",
       "\n",
       "       [[ 8869]],\n",
       "\n",
       "       [[ 6712]],\n",
       "\n",
       "       [[ 8099]],\n",
       "\n",
       "       [[ 9099]],\n",
       "\n",
       "       [[ 6826]],\n",
       "\n",
       "       [[ 8803]],\n",
       "\n",
       "       [[ 6515]],\n",
       "\n",
       "       [[ 8464]],\n",
       "\n",
       "       [[ 6569]],\n",
       "\n",
       "       [[ 9225]],\n",
       "\n",
       "       [[10725]],\n",
       "\n",
       "       [[ 6516]],\n",
       "\n",
       "       [[ 3865]],\n",
       "\n",
       "       [[ 7287]],\n",
       "\n",
       "       [[ 8047]],\n",
       "\n",
       "       [[ 8925]],\n",
       "\n",
       "       [[ 3822]],\n",
       "\n",
       "       [[10672]],\n",
       "\n",
       "       [[11583]],\n",
       "\n",
       "       [[ 7943]],\n",
       "\n",
       "       [[ 9371]],\n",
       "\n",
       "       [[ 7886]],\n",
       "\n",
       "       [[ 8541]],\n",
       "\n",
       "       [[ 9339]],\n",
       "\n",
       "       [[ 6667]],\n",
       "\n",
       "       [[ 8075]],\n",
       "\n",
       "       [[ 6445]],\n",
       "\n",
       "       [[ 3999]],\n",
       "\n",
       "       [[ 6256]],\n",
       "\n",
       "       [[ 7286]],\n",
       "\n",
       "       [[ 6503]],\n",
       "\n",
       "       [[10028]],\n",
       "\n",
       "       [[ 9623]],\n",
       "\n",
       "       [[ 8115]],\n",
       "\n",
       "       [[ 8266]],\n",
       "\n",
       "       [[ 6614]],\n",
       "\n",
       "       [[ 8204]],\n",
       "\n",
       "       [[ 7796]],\n",
       "\n",
       "       [[ 9677]],\n",
       "\n",
       "       [[ 9150]],\n",
       "\n",
       "       [[11702]],\n",
       "\n",
       "       [[10323]],\n",
       "\n",
       "       [[ 9169]],\n",
       "\n",
       "       [[ 8833]],\n",
       "\n",
       "       [[ 6479]],\n",
       "\n",
       "       [[ 4006]],\n",
       "\n",
       "       [[ 8595]],\n",
       "\n",
       "       [[ 6128]],\n",
       "\n",
       "       [[ 6737]],\n",
       "\n",
       "       [[ 9469]],\n",
       "\n",
       "       [[10655]],\n",
       "\n",
       "       [[ 9612]],\n",
       "\n",
       "       [[ 7975]],\n",
       "\n",
       "       [[11551]],\n",
       "\n",
       "       [[ 8662]],\n",
       "\n",
       "       [[ 6658]],\n",
       "\n",
       "       [[ 8300]],\n",
       "\n",
       "       [[10243]],\n",
       "\n",
       "       [[ 8566]],\n",
       "\n",
       "       [[10423]],\n",
       "\n",
       "       [[11561]],\n",
       "\n",
       "       [[ 9710]],\n",
       "\n",
       "       [[ 9510]],\n",
       "\n",
       "       [[10393]],\n",
       "\n",
       "       [[ 8081]],\n",
       "\n",
       "       [[ 9760]],\n",
       "\n",
       "       [[ 7178]],\n",
       "\n",
       "       [[ 6598]],\n",
       "\n",
       "       [[10899]],\n",
       "\n",
       "       [[ 3925]],\n",
       "\n",
       "       [[ 9644]],\n",
       "\n",
       "       [[ 7594]],\n",
       "\n",
       "       [[ 7276]],\n",
       "\n",
       "       [[11094]],\n",
       "\n",
       "       [[ 8460]],\n",
       "\n",
       "       [[ 3819]],\n",
       "\n",
       "       [[ 3884]],\n",
       "\n",
       "       [[10309]],\n",
       "\n",
       "       [[ 6822]],\n",
       "\n",
       "       [[ 4006]],\n",
       "\n",
       "       [[ 6158]],\n",
       "\n",
       "       [[ 6805]],\n",
       "\n",
       "       [[ 6793]],\n",
       "\n",
       "       [[ 9838]],\n",
       "\n",
       "       [[ 7351]],\n",
       "\n",
       "       [[ 6731]],\n",
       "\n",
       "       [[ 9850]],\n",
       "\n",
       "       [[ 4021]],\n",
       "\n",
       "       [[ 6266]],\n",
       "\n",
       "       [[ 9015]],\n",
       "\n",
       "       [[ 6424]],\n",
       "\n",
       "       [[ 7900]],\n",
       "\n",
       "       [[11335]],\n",
       "\n",
       "       [[ 6482]],\n",
       "\n",
       "       [[ 9909]],\n",
       "\n",
       "       [[ 9091]],\n",
       "\n",
       "       [[ 6253]],\n",
       "\n",
       "       [[ 8104]],\n",
       "\n",
       "       [[ 8103]],\n",
       "\n",
       "       [[ 6602]],\n",
       "\n",
       "       [[ 9143]],\n",
       "\n",
       "       [[ 3871]],\n",
       "\n",
       "       [[ 8641]],\n",
       "\n",
       "       [[ 6318]],\n",
       "\n",
       "       [[ 9714]],\n",
       "\n",
       "       [[ 6429]],\n",
       "\n",
       "       [[11002]],\n",
       "\n",
       "       [[ 3857]],\n",
       "\n",
       "       [[ 9556]],\n",
       "\n",
       "       [[ 6918]],\n",
       "\n",
       "       [[10713]],\n",
       "\n",
       "       [[ 6579]],\n",
       "\n",
       "       [[ 8572]],\n",
       "\n",
       "       [[10085]],\n",
       "\n",
       "       [[ 7938]],\n",
       "\n",
       "       [[ 3861]],\n",
       "\n",
       "       [[ 8025]],\n",
       "\n",
       "       [[ 7513]],\n",
       "\n",
       "       [[ 8725]],\n",
       "\n",
       "       [[ 7403]],\n",
       "\n",
       "       [[ 7413]],\n",
       "\n",
       "       [[ 8129]],\n",
       "\n",
       "       [[ 7311]],\n",
       "\n",
       "       [[ 3874]],\n",
       "\n",
       "       [[ 7551]],\n",
       "\n",
       "       [[10279]],\n",
       "\n",
       "       [[ 7332]],\n",
       "\n",
       "       [[ 6642]],\n",
       "\n",
       "       [[11019]],\n",
       "\n",
       "       [[ 9387]],\n",
       "\n",
       "       [[ 9561]],\n",
       "\n",
       "       [[ 7047]],\n",
       "\n",
       "       [[ 7145]],\n",
       "\n",
       "       [[ 9150]],\n",
       "\n",
       "       [[ 3981]],\n",
       "\n",
       "       [[ 6511]],\n",
       "\n",
       "       [[ 7517]],\n",
       "\n",
       "       [[11337]],\n",
       "\n",
       "       [[11355]],\n",
       "\n",
       "       [[ 9649]],\n",
       "\n",
       "       [[ 7650]],\n",
       "\n",
       "       [[ 3813]],\n",
       "\n",
       "       [[ 6614]],\n",
       "\n",
       "       [[ 8830]],\n",
       "\n",
       "       [[ 7255]],\n",
       "\n",
       "       [[ 6411]],\n",
       "\n",
       "       [[10426]],\n",
       "\n",
       "       [[ 7000]],\n",
       "\n",
       "       [[ 9357]],\n",
       "\n",
       "       [[ 6846]],\n",
       "\n",
       "       [[ 6352]],\n",
       "\n",
       "       [[ 4003]],\n",
       "\n",
       "       [[ 7269]],\n",
       "\n",
       "       [[ 7884]],\n",
       "\n",
       "       [[ 9733]],\n",
       "\n",
       "       [[ 6377]],\n",
       "\n",
       "       [[ 6426]],\n",
       "\n",
       "       [[ 6288]],\n",
       "\n",
       "       [[ 7345]],\n",
       "\n",
       "       [[ 9670]],\n",
       "\n",
       "       [[ 8469]],\n",
       "\n",
       "       [[10887]],\n",
       "\n",
       "       [[ 7704]],\n",
       "\n",
       "       [[11811]],\n",
       "\n",
       "       [[ 8820]],\n",
       "\n",
       "       [[ 8085]],\n",
       "\n",
       "       [[10758]],\n",
       "\n",
       "       [[ 9128]],\n",
       "\n",
       "       [[ 6491]],\n",
       "\n",
       "       [[ 9398]],\n",
       "\n",
       "       [[ 6645]],\n",
       "\n",
       "       [[ 8466]],\n",
       "\n",
       "       [[ 6233]],\n",
       "\n",
       "       [[10211]],\n",
       "\n",
       "       [[ 8872]],\n",
       "\n",
       "       [[11587]],\n",
       "\n",
       "       [[ 7933]],\n",
       "\n",
       "       [[11445]],\n",
       "\n",
       "       [[ 8476]],\n",
       "\n",
       "       [[ 8670]],\n",
       "\n",
       "       [[ 6537]],\n",
       "\n",
       "       [[10482]],\n",
       "\n",
       "       [[ 9362]],\n",
       "\n",
       "       [[ 3874]],\n",
       "\n",
       "       [[ 9468]],\n",
       "\n",
       "       [[ 9407]],\n",
       "\n",
       "       [[ 7209]],\n",
       "\n",
       "       [[ 7353]],\n",
       "\n",
       "       [[ 8068]],\n",
       "\n",
       "       [[11752]],\n",
       "\n",
       "       [[ 9388]],\n",
       "\n",
       "       [[ 7778]],\n",
       "\n",
       "       [[11763]],\n",
       "\n",
       "       [[ 8023]],\n",
       "\n",
       "       [[ 7705]],\n",
       "\n",
       "       [[ 9523]],\n",
       "\n",
       "       [[ 8690]],\n",
       "\n",
       "       [[ 7020]],\n",
       "\n",
       "       [[ 7208]],\n",
       "\n",
       "       [[ 8410]],\n",
       "\n",
       "       [[ 6946]],\n",
       "\n",
       "       [[10556]],\n",
       "\n",
       "       [[ 9330]],\n",
       "\n",
       "       [[11199]],\n",
       "\n",
       "       [[10364]],\n",
       "\n",
       "       [[ 9840]],\n",
       "\n",
       "       [[ 7492]],\n",
       "\n",
       "       [[ 7940]],\n",
       "\n",
       "       [[ 8728]],\n",
       "\n",
       "       [[ 6916]],\n",
       "\n",
       "       [[ 9844]],\n",
       "\n",
       "       [[11417]],\n",
       "\n",
       "       [[ 6124]],\n",
       "\n",
       "       [[ 7556]],\n",
       "\n",
       "       [[ 9261]],\n",
       "\n",
       "       [[11553]],\n",
       "\n",
       "       [[ 6685]],\n",
       "\n",
       "       [[ 8092]],\n",
       "\n",
       "       [[10625]],\n",
       "\n",
       "       [[ 8829]],\n",
       "\n",
       "       [[ 8693]],\n",
       "\n",
       "       [[ 7912]],\n",
       "\n",
       "       [[ 6908]],\n",
       "\n",
       "       [[ 7165]],\n",
       "\n",
       "       [[ 6382]],\n",
       "\n",
       "       [[10154]],\n",
       "\n",
       "       [[ 6459]],\n",
       "\n",
       "       [[ 9321]],\n",
       "\n",
       "       [[ 9734]],\n",
       "\n",
       "       [[ 9520]],\n",
       "\n",
       "       [[ 6537]],\n",
       "\n",
       "       [[11602]],\n",
       "\n",
       "       [[ 9218]],\n",
       "\n",
       "       [[ 9429]],\n",
       "\n",
       "       [[11753]],\n",
       "\n",
       "       [[ 6308]],\n",
       "\n",
       "       [[ 6412]],\n",
       "\n",
       "       [[ 9065]],\n",
       "\n",
       "       [[ 6775]],\n",
       "\n",
       "       [[ 9466]],\n",
       "\n",
       "       [[11455]],\n",
       "\n",
       "       [[ 3850]],\n",
       "\n",
       "       [[ 9499]],\n",
       "\n",
       "       [[ 9349]],\n",
       "\n",
       "       [[11252]],\n",
       "\n",
       "       [[11710]],\n",
       "\n",
       "       [[ 6225]],\n",
       "\n",
       "       [[ 8584]],\n",
       "\n",
       "       [[ 8274]],\n",
       "\n",
       "       [[11680]],\n",
       "\n",
       "       [[ 6335]],\n",
       "\n",
       "       [[ 9608]],\n",
       "\n",
       "       [[ 7362]],\n",
       "\n",
       "       [[ 3904]],\n",
       "\n",
       "       [[ 6484]],\n",
       "\n",
       "       [[ 6986]],\n",
       "\n",
       "       [[ 9558]],\n",
       "\n",
       "       [[ 6228]],\n",
       "\n",
       "       [[ 7549]],\n",
       "\n",
       "       [[ 6474]],\n",
       "\n",
       "       [[ 6414]],\n",
       "\n",
       "       [[11560]],\n",
       "\n",
       "       [[ 3993]],\n",
       "\n",
       "       [[ 6609]],\n",
       "\n",
       "       [[ 6288]],\n",
       "\n",
       "       [[ 8777]],\n",
       "\n",
       "       [[10475]],\n",
       "\n",
       "       [[ 9231]],\n",
       "\n",
       "       [[10512]],\n",
       "\n",
       "       [[11365]],\n",
       "\n",
       "       [[ 6863]],\n",
       "\n",
       "       [[11364]],\n",
       "\n",
       "       [[ 9519]],\n",
       "\n",
       "       [[10272]],\n",
       "\n",
       "       [[11051]],\n",
       "\n",
       "       [[ 6388]],\n",
       "\n",
       "       [[10152]],\n",
       "\n",
       "       [[ 6451]],\n",
       "\n",
       "       [[ 7588]],\n",
       "\n",
       "       [[ 9300]],\n",
       "\n",
       "       [[11689]],\n",
       "\n",
       "       [[ 7529]],\n",
       "\n",
       "       [[ 3825]],\n",
       "\n",
       "       [[ 6380]],\n",
       "\n",
       "       [[ 8883]],\n",
       "\n",
       "       [[ 9724]],\n",
       "\n",
       "       [[ 6673]],\n",
       "\n",
       "       [[10091]],\n",
       "\n",
       "       [[10931]],\n",
       "\n",
       "       [[ 6424]],\n",
       "\n",
       "       [[10334]],\n",
       "\n",
       "       [[ 6722]],\n",
       "\n",
       "       [[ 8241]],\n",
       "\n",
       "       [[10467]],\n",
       "\n",
       "       [[ 7269]],\n",
       "\n",
       "       [[ 3896]],\n",
       "\n",
       "       [[ 6312]],\n",
       "\n",
       "       [[ 7503]],\n",
       "\n",
       "       [[10351]],\n",
       "\n",
       "       [[ 9244]],\n",
       "\n",
       "       [[ 9356]],\n",
       "\n",
       "       [[ 8693]],\n",
       "\n",
       "       [[10579]],\n",
       "\n",
       "       [[ 7157]],\n",
       "\n",
       "       [[ 7455]],\n",
       "\n",
       "       [[ 9356]],\n",
       "\n",
       "       [[ 3915]],\n",
       "\n",
       "       [[11726]],\n",
       "\n",
       "       [[ 9252]],\n",
       "\n",
       "       [[11384]],\n",
       "\n",
       "       [[ 9274]],\n",
       "\n",
       "       [[ 6287]],\n",
       "\n",
       "       [[ 8465]],\n",
       "\n",
       "       [[ 9169]],\n",
       "\n",
       "       [[ 8016]],\n",
       "\n",
       "       [[ 9292]],\n",
       "\n",
       "       [[ 9658]],\n",
       "\n",
       "       [[11161]],\n",
       "\n",
       "       [[ 8054]],\n",
       "\n",
       "       [[ 8791]],\n",
       "\n",
       "       [[ 9755]],\n",
       "\n",
       "       [[ 9320]],\n",
       "\n",
       "       [[ 8142]],\n",
       "\n",
       "       [[ 6331]],\n",
       "\n",
       "       [[10772]],\n",
       "\n",
       "       [[ 6739]],\n",
       "\n",
       "       [[ 7430]],\n",
       "\n",
       "       [[ 9304]],\n",
       "\n",
       "       [[ 7006]],\n",
       "\n",
       "       [[ 8173]],\n",
       "\n",
       "       [[ 9216]],\n",
       "\n",
       "       [[ 8767]],\n",
       "\n",
       "       [[10445]],\n",
       "\n",
       "       [[11675]],\n",
       "\n",
       "       [[ 8775]],\n",
       "\n",
       "       [[ 8648]],\n",
       "\n",
       "       [[ 6980]],\n",
       "\n",
       "       [[ 9203]],\n",
       "\n",
       "       [[ 9024]],\n",
       "\n",
       "       [[ 9556]],\n",
       "\n",
       "       [[11424]],\n",
       "\n",
       "       [[ 7517]],\n",
       "\n",
       "       [[10607]],\n",
       "\n",
       "       [[10790]],\n",
       "\n",
       "       [[ 6566]],\n",
       "\n",
       "       [[ 7319]],\n",
       "\n",
       "       [[ 7204]],\n",
       "\n",
       "       [[ 9125]],\n",
       "\n",
       "       [[10328]],\n",
       "\n",
       "       [[10349]],\n",
       "\n",
       "       [[ 6630]],\n",
       "\n",
       "       [[ 9975]],\n",
       "\n",
       "       [[ 3835]],\n",
       "\n",
       "       [[ 6530]],\n",
       "\n",
       "       [[ 9666]],\n",
       "\n",
       "       [[ 7856]],\n",
       "\n",
       "       [[ 9823]],\n",
       "\n",
       "       [[ 9161]],\n",
       "\n",
       "       [[11628]],\n",
       "\n",
       "       [[ 9367]],\n",
       "\n",
       "       [[11513]],\n",
       "\n",
       "       [[ 9292]],\n",
       "\n",
       "       [[ 9724]],\n",
       "\n",
       "       [[ 6316]],\n",
       "\n",
       "       [[11757]],\n",
       "\n",
       "       [[ 9723]],\n",
       "\n",
       "       [[ 8691]],\n",
       "\n",
       "       [[11569]],\n",
       "\n",
       "       [[ 8008]],\n",
       "\n",
       "       [[ 7454]],\n",
       "\n",
       "       [[10433]],\n",
       "\n",
       "       [[ 9427]],\n",
       "\n",
       "       [[ 8198]],\n",
       "\n",
       "       [[ 6385]],\n",
       "\n",
       "       [[ 7816]],\n",
       "\n",
       "       [[10325]],\n",
       "\n",
       "       [[10679]],\n",
       "\n",
       "       [[ 7873]],\n",
       "\n",
       "       [[ 8256]],\n",
       "\n",
       "       [[11719]],\n",
       "\n",
       "       [[ 6997]],\n",
       "\n",
       "       [[11370]],\n",
       "\n",
       "       [[10192]],\n",
       "\n",
       "       [[ 7158]],\n",
       "\n",
       "       [[ 6629]],\n",
       "\n",
       "       [[ 7249]],\n",
       "\n",
       "       [[ 9182]],\n",
       "\n",
       "       [[ 8913]],\n",
       "\n",
       "       [[ 6698]],\n",
       "\n",
       "       [[10766]],\n",
       "\n",
       "       [[ 3943]],\n",
       "\n",
       "       [[10295]],\n",
       "\n",
       "       [[11755]],\n",
       "\n",
       "       [[ 9500]],\n",
       "\n",
       "       [[ 9196]],\n",
       "\n",
       "       [[ 6491]],\n",
       "\n",
       "       [[ 7293]],\n",
       "\n",
       "       [[ 9110]],\n",
       "\n",
       "       [[ 8672]],\n",
       "\n",
       "       [[ 4014]],\n",
       "\n",
       "       [[ 8636]],\n",
       "\n",
       "       [[11320]],\n",
       "\n",
       "       [[ 9109]],\n",
       "\n",
       "       [[ 6584]],\n",
       "\n",
       "       [[ 7004]],\n",
       "\n",
       "       [[ 7260]],\n",
       "\n",
       "       [[10005]],\n",
       "\n",
       "       [[ 7619]],\n",
       "\n",
       "       [[ 8255]],\n",
       "\n",
       "       [[ 9316]],\n",
       "\n",
       "       [[ 7555]],\n",
       "\n",
       "       [[ 9636]],\n",
       "\n",
       "       [[ 6414]],\n",
       "\n",
       "       [[ 3821]],\n",
       "\n",
       "       [[ 6547]],\n",
       "\n",
       "       [[ 8206]],\n",
       "\n",
       "       [[ 9137]],\n",
       "\n",
       "       [[ 8438]],\n",
       "\n",
       "       [[ 7681]],\n",
       "\n",
       "       [[ 6755]],\n",
       "\n",
       "       [[10189]],\n",
       "\n",
       "       [[ 3833]],\n",
       "\n",
       "       [[ 8904]],\n",
       "\n",
       "       [[11537]],\n",
       "\n",
       "       [[10494]],\n",
       "\n",
       "       [[10988]],\n",
       "\n",
       "       [[11085]],\n",
       "\n",
       "       [[ 6683]],\n",
       "\n",
       "       [[10156]],\n",
       "\n",
       "       [[ 6780]],\n",
       "\n",
       "       [[ 8235]],\n",
       "\n",
       "       [[ 9081]],\n",
       "\n",
       "       [[10083]],\n",
       "\n",
       "       [[ 7548]],\n",
       "\n",
       "       [[ 6611]],\n",
       "\n",
       "       [[ 9581]],\n",
       "\n",
       "       [[ 7315]],\n",
       "\n",
       "       [[ 7884]],\n",
       "\n",
       "       [[ 4000]],\n",
       "\n",
       "       [[ 7238]],\n",
       "\n",
       "       [[ 8797]],\n",
       "\n",
       "       [[10780]],\n",
       "\n",
       "       [[ 8254]],\n",
       "\n",
       "       [[ 3933]],\n",
       "\n",
       "       [[ 9393]],\n",
       "\n",
       "       [[ 6462]],\n",
       "\n",
       "       [[ 7263]],\n",
       "\n",
       "       [[ 8404]],\n",
       "\n",
       "       [[ 8601]],\n",
       "\n",
       "       [[ 7009]],\n",
       "\n",
       "       [[ 6342]]], dtype=int64)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 241
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:06:05.744103Z",
     "start_time": "2024-04-15T17:06:05.725595Z"
    }
   },
   "cell_type": "code",
   "source": "X_test.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 1, 15)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 240
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVCJxdebqmOr"
   },
   "source": [
    "# **Model Architecture + Training**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:07:29.844550Z",
     "start_time": "2024-04-15T17:07:29.823130Z"
    }
   },
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ],
   "outputs": [],
   "execution_count": 242
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868",
    "ExecuteTime": {
     "end_time": "2024-04-15T17:07:30.943309Z",
     "start_time": "2024-04-15T17:07:30.856376Z"
    }
   },
   "source": [
    "\n",
    "adam = optimizers.Adam(learning_rate=lr_schedule(0), amsgrad=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "execution_count": 243
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:07:35.303322Z",
     "start_time": "2024-04-15T17:07:34.966109Z"
    }
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu')))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"log_cosh\", optimizer=adam, metrics=['mae'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DS440proj\\BTCpred\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 244
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6",
    "ExecuteTime": {
     "end_time": "2024-04-15T17:08:04.857828Z",
     "start_time": "2024-04-15T17:08:04.838328Z"
    }
   },
   "source": [
    "mcp_save = ModelCheckpoint('model/LSTM_reg_seven_new.keras', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='auto')"
   ],
   "outputs": [],
   "execution_count": 245
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bIJPsArMr8cs",
    "outputId": "91137564-8bb8-496c-c827-829e240a789a",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-15T17:15:26.737267Z",
     "start_time": "2024-04-15T17:08:06.143929Z"
    }
   },
   "source": [
    "#model.compile(optimizer='adam', loss='log_cosh', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=5000, batch_size=32, validation_data=(X_test,y_test), callbacks=[mcp_save,earlyStopping])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m5s\u001B[0m 48ms/step - loss: 8205.1289 - mae: 8205.8232 - val_loss: 8465.8789 - val_mae: 8466.5723\n",
      "Epoch 2/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 8281.9023 - mae: 8282.5957 - val_loss: 8381.6641 - val_mae: 8382.3564\n",
      "Epoch 3/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 8105.4233 - mae: 8106.1162 - val_loss: 7991.0322 - val_mae: 7991.7261\n",
      "Epoch 4/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 43ms/step - loss: 7682.5859 - mae: 7683.2798 - val_loss: 6845.1489 - val_mae: 6845.8428\n",
      "Epoch 5/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 6260.3706 - mae: 6261.0635 - val_loss: 4152.8745 - val_mae: 4153.5679\n",
      "Epoch 6/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 3079.3806 - mae: 3080.0737 - val_loss: 1497.0518 - val_mae: 1497.7417\n",
      "Epoch 7/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - loss: 1304.7050 - mae: 1305.3981 - val_loss: 1310.8428 - val_mae: 1311.5359\n",
      "Epoch 8/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - loss: 1144.7430 - mae: 1145.4351 - val_loss: 1223.3359 - val_mae: 1224.0291\n",
      "Epoch 9/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - loss: 951.5717 - mae: 952.2649 - val_loss: 1118.5573 - val_mae: 1119.2504\n",
      "Epoch 10/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 894.1351 - mae: 894.8280 - val_loss: 1027.7964 - val_mae: 1028.4895\n",
      "Epoch 11/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 873.7250 - mae: 874.4178 - val_loss: 964.4629 - val_mae: 965.1560\n",
      "Epoch 12/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 805.6740 - mae: 806.3671 - val_loss: 926.7856 - val_mae: 927.4750\n",
      "Epoch 13/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 788.9110 - mae: 789.6035 - val_loss: 854.5242 - val_mae: 855.2164\n",
      "Epoch 14/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 688.5909 - mae: 689.2837 - val_loss: 814.8283 - val_mae: 815.5206\n",
      "Epoch 15/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 668.2857 - mae: 668.9786 - val_loss: 779.3222 - val_mae: 780.0153\n",
      "Epoch 16/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - loss: 646.0512 - mae: 646.7440 - val_loss: 765.1624 - val_mae: 765.8552\n",
      "Epoch 17/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 645.1990 - mae: 645.8922 - val_loss: 729.2969 - val_mae: 729.9901\n",
      "Epoch 18/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 642.4058 - mae: 643.0989 - val_loss: 711.0057 - val_mae: 711.6988\n",
      "Epoch 19/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 632.0797 - mae: 632.7726 - val_loss: 704.1684 - val_mae: 704.8596\n",
      "Epoch 20/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 573.6035 - mae: 574.2961 - val_loss: 686.7202 - val_mae: 687.4133\n",
      "Epoch 21/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 620.0013 - mae: 620.6931 - val_loss: 674.5061 - val_mae: 675.1992\n",
      "Epoch 22/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 587.1567 - mae: 587.8489 - val_loss: 665.9068 - val_mae: 666.6000\n",
      "Epoch 23/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 559.3300 - mae: 560.0220 - val_loss: 662.9106 - val_mae: 663.6033\n",
      "Epoch 24/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 563.4702 - mae: 564.1633 - val_loss: 651.9747 - val_mae: 652.6679\n",
      "Epoch 25/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 577.1691 - mae: 577.8622 - val_loss: 644.8416 - val_mae: 645.5300\n",
      "Epoch 26/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 532.0845 - mae: 532.7769 - val_loss: 627.7100 - val_mae: 628.4013\n",
      "Epoch 27/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 560.6393 - mae: 561.3324 - val_loss: 622.9261 - val_mae: 623.6191\n",
      "Epoch 28/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 552.7733 - mae: 553.4663 - val_loss: 610.8233 - val_mae: 611.5146\n",
      "Epoch 29/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 529.3707 - mae: 530.0624 - val_loss: 604.0164 - val_mae: 604.7095\n",
      "Epoch 30/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 545.7532 - mae: 546.4463 - val_loss: 595.1028 - val_mae: 595.7959\n",
      "Epoch 31/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 525.6497 - mae: 526.3428 - val_loss: 586.9489 - val_mae: 587.6419\n",
      "Epoch 32/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 520.1246 - mae: 520.8176 - val_loss: 579.7352 - val_mae: 580.4282\n",
      "Epoch 33/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 51ms/step - loss: 539.8945 - mae: 540.5876 - val_loss: 572.8415 - val_mae: 573.5346\n",
      "Epoch 34/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 508.0070 - mae: 508.6993 - val_loss: 562.7912 - val_mae: 563.4841\n",
      "Epoch 35/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 486.5563 - mae: 487.2494 - val_loss: 575.0738 - val_mae: 575.7670\n",
      "Epoch 36/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 515.3755 - mae: 516.0667 - val_loss: 547.7851 - val_mae: 548.4775\n",
      "Epoch 37/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 461.1328 - mae: 461.8259 - val_loss: 546.2875 - val_mae: 546.9807\n",
      "Epoch 38/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 458.5527 - mae: 459.2438 - val_loss: 534.2316 - val_mae: 534.9247\n",
      "Epoch 39/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 472.7426 - mae: 473.4357 - val_loss: 524.9340 - val_mae: 525.6251\n",
      "Epoch 40/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 481.7509 - mae: 482.4441 - val_loss: 517.0729 - val_mae: 517.7661\n",
      "Epoch 41/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 457.9365 - mae: 458.6295 - val_loss: 509.9462 - val_mae: 510.6394\n",
      "Epoch 42/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 450.3659 - mae: 451.0591 - val_loss: 515.4657 - val_mae: 516.1589\n",
      "Epoch 43/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 49ms/step - loss: 460.8063 - mae: 461.4992 - val_loss: 495.6666 - val_mae: 496.3586\n",
      "Epoch 44/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 48ms/step - loss: 435.7651 - mae: 436.4581 - val_loss: 490.4318 - val_mae: 491.1248\n",
      "Epoch 45/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 420.7798 - mae: 421.4716 - val_loss: 484.8740 - val_mae: 485.5672\n",
      "Epoch 46/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 432.6905 - mae: 433.3835 - val_loss: 475.5819 - val_mae: 476.2750\n",
      "Epoch 47/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 419.5243 - mae: 420.2174 - val_loss: 466.9309 - val_mae: 467.6241\n",
      "Epoch 48/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 403.7690 - mae: 404.4616 - val_loss: 483.5012 - val_mae: 484.1943\n",
      "Epoch 49/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 408.5500 - mae: 409.2432 - val_loss: 454.7920 - val_mae: 455.4842\n",
      "Epoch 50/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 392.2021 - mae: 392.8940 - val_loss: 450.2503 - val_mae: 450.9429\n",
      "Epoch 51/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 406.2350 - mae: 406.9266 - val_loss: 451.8315 - val_mae: 452.5247\n",
      "Epoch 52/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 387.2428 - mae: 387.9352 - val_loss: 452.1284 - val_mae: 452.8216\n",
      "Epoch 53/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 392.6887 - mae: 393.3814 - val_loss: 430.2659 - val_mae: 430.9590\n",
      "Epoch 54/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 364.8843 - mae: 365.5764 - val_loss: 423.8149 - val_mae: 424.5080\n",
      "Epoch 55/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 349.7775 - mae: 350.4684 - val_loss: 420.6519 - val_mae: 421.3433\n",
      "Epoch 56/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 365.3097 - mae: 366.0022 - val_loss: 415.4832 - val_mae: 416.1747\n",
      "Epoch 57/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 360.1596 - mae: 360.8525 - val_loss: 408.9438 - val_mae: 409.6322\n",
      "Epoch 58/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 361.3034 - mae: 361.9956 - val_loss: 407.3354 - val_mae: 408.0283\n",
      "Epoch 59/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 351.4256 - mae: 352.1186 - val_loss: 421.3052 - val_mae: 421.9983\n",
      "Epoch 60/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 347.5160 - mae: 348.2085 - val_loss: 417.5476 - val_mae: 418.2408\n",
      "Epoch 61/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 362.8658 - mae: 363.5574 - val_loss: 387.4910 - val_mae: 388.1835\n",
      "Epoch 62/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 325.0159 - mae: 325.7090 - val_loss: 383.9318 - val_mae: 384.6224\n",
      "Epoch 63/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 326.9087 - mae: 327.6009 - val_loss: 387.9456 - val_mae: 388.6373\n",
      "Epoch 64/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 322.1664 - mae: 322.8579 - val_loss: 374.6857 - val_mae: 375.3759\n",
      "Epoch 65/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 317.0313 - mae: 317.7237 - val_loss: 372.7876 - val_mae: 373.4794\n",
      "Epoch 66/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 324.8740 - mae: 325.5670 - val_loss: 368.7312 - val_mae: 369.4239\n",
      "Epoch 67/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 322.5710 - mae: 323.2627 - val_loss: 363.2271 - val_mae: 363.9187\n",
      "Epoch 68/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 300.2328 - mae: 300.9257 - val_loss: 362.4915 - val_mae: 363.1846\n",
      "Epoch 69/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 293.2863 - mae: 293.9785 - val_loss: 360.4444 - val_mae: 361.1364\n",
      "Epoch 70/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 303.6525 - mae: 304.3429 - val_loss: 349.4692 - val_mae: 350.1616\n",
      "Epoch 71/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 295.3900 - mae: 296.0822 - val_loss: 342.8789 - val_mae: 343.5717\n",
      "Epoch 72/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 294.8638 - mae: 295.5564 - val_loss: 352.2413 - val_mae: 352.9336\n",
      "Epoch 73/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 300.4178 - mae: 301.1107 - val_loss: 343.5405 - val_mae: 344.2332\n",
      "Epoch 74/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 287.3021 - mae: 287.9939 - val_loss: 337.4766 - val_mae: 338.1696\n",
      "Epoch 75/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 300.3160 - mae: 301.0089 - val_loss: 327.8988 - val_mae: 328.5864\n",
      "Epoch 76/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 268.8806 - mae: 269.5732 - val_loss: 330.7068 - val_mae: 331.3953\n",
      "Epoch 77/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 284.5963 - mae: 285.2881 - val_loss: 324.5501 - val_mae: 325.2398\n",
      "Epoch 78/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 261.1231 - mae: 261.8158 - val_loss: 321.8340 - val_mae: 322.5250\n",
      "Epoch 79/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 262.7823 - mae: 263.4741 - val_loss: 322.8671 - val_mae: 323.5586\n",
      "Epoch 80/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 257.3134 - mae: 258.0034 - val_loss: 331.4068 - val_mae: 332.0969\n",
      "Epoch 81/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 258.4724 - mae: 259.1630 - val_loss: 329.3125 - val_mae: 330.0051\n",
      "Epoch 82/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 46ms/step - loss: 254.6470 - mae: 255.3392 - val_loss: 310.6159 - val_mae: 311.3069\n",
      "Epoch 83/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 242.6675 - mae: 243.3583 - val_loss: 311.0243 - val_mae: 311.7135\n",
      "Epoch 84/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 266.1529 - mae: 266.8459 - val_loss: 312.0739 - val_mae: 312.7639\n",
      "Epoch 85/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - loss: 246.1544 - mae: 246.8453 - val_loss: 308.2042 - val_mae: 308.8958\n",
      "Epoch 86/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 256.0413 - mae: 256.7313 - val_loss: 314.2111 - val_mae: 314.9032\n",
      "Epoch 87/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 243.3414 - mae: 244.0343 - val_loss: 317.9086 - val_mae: 318.6012\n",
      "Epoch 88/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 251.2880 - mae: 251.9799 - val_loss: 299.9706 - val_mae: 300.6636\n",
      "Epoch 89/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 233.0579 - mae: 233.7489 - val_loss: 297.8601 - val_mae: 298.5532\n",
      "Epoch 90/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 228.5655 - mae: 229.2566 - val_loss: 305.4671 - val_mae: 306.1569\n",
      "Epoch 91/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 231.2182 - mae: 231.9098 - val_loss: 293.5282 - val_mae: 294.2200\n",
      "Epoch 92/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 242.2585 - mae: 242.9476 - val_loss: 293.8363 - val_mae: 294.5279\n",
      "Epoch 93/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 237.5211 - mae: 238.2135 - val_loss: 292.6031 - val_mae: 293.2950\n",
      "Epoch 94/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 249.6198 - mae: 250.3122 - val_loss: 308.3093 - val_mae: 309.0010\n",
      "Epoch 95/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 233.8445 - mae: 234.5369 - val_loss: 293.2855 - val_mae: 293.9785\n",
      "Epoch 96/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 223.4929 - mae: 224.1854 - val_loss: 293.8762 - val_mae: 294.5690\n",
      "Epoch 97/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 219.0763 - mae: 219.7686 - val_loss: 290.2314 - val_mae: 290.9210\n",
      "Epoch 98/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 226.3918 - mae: 227.0847 - val_loss: 300.3449 - val_mae: 301.0374\n",
      "Epoch 99/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 230.4368 - mae: 231.1287 - val_loss: 307.6685 - val_mae: 308.3616\n",
      "Epoch 100/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 243.3341 - mae: 244.0267 - val_loss: 287.8191 - val_mae: 288.5121\n",
      "Epoch 101/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 214.1192 - mae: 214.8086 - val_loss: 336.7897 - val_mae: 337.4818\n",
      "Epoch 102/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 231.1223 - mae: 231.8150 - val_loss: 294.0543 - val_mae: 294.7448\n",
      "Epoch 103/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 231.4585 - mae: 232.1508 - val_loss: 286.4378 - val_mae: 287.1283\n",
      "Epoch 104/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 220.9746 - mae: 221.6639 - val_loss: 290.4980 - val_mae: 291.1912\n",
      "Epoch 105/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 224.4441 - mae: 225.1360 - val_loss: 286.4709 - val_mae: 287.1628\n",
      "Epoch 106/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 213.5557 - mae: 214.2470 - val_loss: 282.7464 - val_mae: 283.4396\n",
      "Epoch 107/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 226.5979 - mae: 227.2910 - val_loss: 310.2227 - val_mae: 310.9156\n",
      "Epoch 108/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 220.1700 - mae: 220.8601 - val_loss: 283.7372 - val_mae: 284.4274\n",
      "Epoch 109/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 218.4346 - mae: 219.1272 - val_loss: 283.0705 - val_mae: 283.7629\n",
      "Epoch 110/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 212.1442 - mae: 212.8371 - val_loss: 278.6718 - val_mae: 279.3622\n",
      "Epoch 111/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 217.3313 - mae: 218.0228 - val_loss: 298.8239 - val_mae: 299.5122\n",
      "Epoch 112/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 214.0692 - mae: 214.7623 - val_loss: 293.4846 - val_mae: 294.1763\n",
      "Epoch 113/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 225.2211 - mae: 225.9129 - val_loss: 286.4542 - val_mae: 287.1474\n",
      "Epoch 114/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 211.2345 - mae: 211.9274 - val_loss: 282.0108 - val_mae: 282.7039\n",
      "Epoch 115/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 210.6749 - mae: 211.3671 - val_loss: 288.5558 - val_mae: 289.2489\n",
      "Epoch 116/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 224.9816 - mae: 225.6736 - val_loss: 284.1752 - val_mae: 284.8678\n",
      "Epoch 117/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 221.4720 - mae: 222.1631 - val_loss: 276.5422 - val_mae: 277.2345\n",
      "Epoch 118/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 218.0435 - mae: 218.7353 - val_loss: 282.2545 - val_mae: 282.9475\n",
      "Epoch 119/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 44ms/step - loss: 214.1715 - mae: 214.8639 - val_loss: 276.5287 - val_mae: 277.2208\n",
      "Epoch 120/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 200.3972 - mae: 201.0878 - val_loss: 277.8513 - val_mae: 278.5433\n",
      "Epoch 121/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 203.1855 - mae: 203.8764 - val_loss: 278.0513 - val_mae: 278.7402\n",
      "Epoch 122/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 210.0740 - mae: 210.7655 - val_loss: 275.1267 - val_mae: 275.8197\n",
      "Epoch 123/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 190.2275 - mae: 190.9194 - val_loss: 274.9388 - val_mae: 275.6282\n",
      "Epoch 124/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 206.5726 - mae: 207.2617 - val_loss: 288.2817 - val_mae: 288.9748\n",
      "Epoch 125/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 215.9060 - mae: 216.5971 - val_loss: 274.2136 - val_mae: 274.9066\n",
      "Epoch 126/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 203.7277 - mae: 204.4192 - val_loss: 271.9207 - val_mae: 272.6096\n",
      "Epoch 127/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 205.9839 - mae: 206.6756 - val_loss: 277.5090 - val_mae: 278.2019\n",
      "Epoch 128/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 199.1232 - mae: 199.8145 - val_loss: 269.0479 - val_mae: 269.7410\n",
      "Epoch 129/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 219.6239 - mae: 220.3168 - val_loss: 283.7170 - val_mae: 284.4100\n",
      "Epoch 130/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 203.0387 - mae: 203.7307 - val_loss: 275.5544 - val_mae: 276.2462\n",
      "Epoch 131/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 221.2772 - mae: 221.9682 - val_loss: 268.4523 - val_mae: 269.1447\n",
      "Epoch 132/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 199.1165 - mae: 199.8095 - val_loss: 278.8805 - val_mae: 279.5736\n",
      "Epoch 133/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 205.1691 - mae: 205.8616 - val_loss: 271.2309 - val_mae: 271.9241\n",
      "Epoch 134/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 209.2669 - mae: 209.9577 - val_loss: 270.7352 - val_mae: 271.4267\n",
      "Epoch 135/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 197.9172 - mae: 198.6091 - val_loss: 264.5137 - val_mae: 265.2009\n",
      "Epoch 136/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 201.3172 - mae: 202.0075 - val_loss: 265.8801 - val_mae: 266.5694\n",
      "Epoch 137/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 196.5063 - mae: 197.1989 - val_loss: 266.5729 - val_mae: 267.2644\n",
      "Epoch 138/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 197.0022 - mae: 197.6941 - val_loss: 265.6463 - val_mae: 266.3394\n",
      "Epoch 139/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 197.0131 - mae: 197.7049 - val_loss: 281.5637 - val_mae: 282.2505\n",
      "Epoch 140/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 205.2861 - mae: 205.9790 - val_loss: 268.2682 - val_mae: 268.9610\n",
      "Epoch 141/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 188.5866 - mae: 189.2783 - val_loss: 265.5388 - val_mae: 266.2299\n",
      "Epoch 142/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 210.9588 - mae: 211.6482 - val_loss: 264.1315 - val_mae: 264.8231\n",
      "Epoch 143/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 190.9655 - mae: 191.6569 - val_loss: 266.2893 - val_mae: 266.9818\n",
      "Epoch 144/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 202.9751 - mae: 203.6637 - val_loss: 273.6819 - val_mae: 274.3750\n",
      "Epoch 145/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.2069 - mae: 191.8938 - val_loss: 274.5334 - val_mae: 275.2232\n",
      "Epoch 146/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 206.7568 - mae: 207.4481 - val_loss: 261.8573 - val_mae: 262.5490\n",
      "Epoch 147/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 204.6863 - mae: 205.3791 - val_loss: 264.8159 - val_mae: 265.5058\n",
      "Epoch 148/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 195.6794 - mae: 196.3708 - val_loss: 263.5046 - val_mae: 264.1975\n",
      "Epoch 149/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 191.4418 - mae: 192.1335 - val_loss: 311.9146 - val_mae: 312.6074\n",
      "Epoch 150/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 219.4594 - mae: 220.1504 - val_loss: 271.6408 - val_mae: 272.3340\n",
      "Epoch 151/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 191.3090 - mae: 192.0011 - val_loss: 260.8582 - val_mae: 261.5491\n",
      "Epoch 152/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 185.1606 - mae: 185.8503 - val_loss: 259.3271 - val_mae: 260.0163\n",
      "Epoch 153/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 201.4813 - mae: 202.1703 - val_loss: 270.5955 - val_mae: 271.2866\n",
      "Epoch 154/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 195.7213 - mae: 196.4135 - val_loss: 262.8850 - val_mae: 263.5775\n",
      "Epoch 155/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 192.5110 - mae: 193.2028 - val_loss: 262.6697 - val_mae: 263.3606\n",
      "Epoch 156/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 197.8043 - mae: 198.4955 - val_loss: 264.6759 - val_mae: 265.3678\n",
      "Epoch 157/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 183.0792 - mae: 183.7709 - val_loss: 259.1441 - val_mae: 259.8341\n",
      "Epoch 158/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 196.7306 - mae: 197.4218 - val_loss: 269.1324 - val_mae: 269.8254\n",
      "Epoch 159/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 204.9541 - mae: 205.6440 - val_loss: 269.2572 - val_mae: 269.9503\n",
      "Epoch 160/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 196.9715 - mae: 197.6627 - val_loss: 258.7984 - val_mae: 259.4891\n",
      "Epoch 161/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 190.1215 - mae: 190.8128 - val_loss: 262.0003 - val_mae: 262.6933\n",
      "Epoch 162/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.5097 - mae: 189.2009 - val_loss: 262.4263 - val_mae: 263.1148\n",
      "Epoch 163/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 181.7594 - mae: 182.4520 - val_loss: 263.1808 - val_mae: 263.8714\n",
      "Epoch 164/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 187.0987 - mae: 187.7905 - val_loss: 260.4253 - val_mae: 261.1184\n",
      "Epoch 165/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.2547 - mae: 185.9476 - val_loss: 266.8928 - val_mae: 267.5844\n",
      "Epoch 166/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 189.8546 - mae: 190.5474 - val_loss: 258.9935 - val_mae: 259.6850\n",
      "Epoch 167/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 209.0268 - mae: 209.7157 - val_loss: 257.3334 - val_mae: 258.0227\n",
      "Epoch 168/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 190.7725 - mae: 191.4637 - val_loss: 263.9745 - val_mae: 264.6672\n",
      "Epoch 169/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.5060 - mae: 192.1977 - val_loss: 258.6411 - val_mae: 259.3338\n",
      "Epoch 170/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.5306 - mae: 187.2206 - val_loss: 257.5342 - val_mae: 258.2269\n",
      "Epoch 171/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 195.0628 - mae: 195.7545 - val_loss: 257.5426 - val_mae: 258.2341\n",
      "Epoch 172/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.7691 - mae: 183.4619 - val_loss: 259.5759 - val_mae: 260.2635\n",
      "Epoch 173/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 197.5358 - mae: 198.2278 - val_loss: 255.2271 - val_mae: 255.9160\n",
      "Epoch 174/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 182.3682 - mae: 183.0585 - val_loss: 257.7231 - val_mae: 258.4133\n",
      "Epoch 175/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 193.4229 - mae: 194.1142 - val_loss: 280.7556 - val_mae: 281.4488\n",
      "Epoch 176/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 203.6933 - mae: 204.3859 - val_loss: 254.0073 - val_mae: 254.6992\n",
      "Epoch 177/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 171.6631 - mae: 172.3499 - val_loss: 261.0164 - val_mae: 261.7050\n",
      "Epoch 178/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 190.3741 - mae: 191.0638 - val_loss: 255.6410 - val_mae: 256.3334\n",
      "Epoch 179/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 195.0926 - mae: 195.7825 - val_loss: 256.0295 - val_mae: 256.7190\n",
      "Epoch 180/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.7805 - mae: 185.4698 - val_loss: 256.6499 - val_mae: 257.3399\n",
      "Epoch 181/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 178.9369 - mae: 179.6288 - val_loss: 265.4869 - val_mae: 266.1800\n",
      "Epoch 182/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 179.8826 - mae: 180.5721 - val_loss: 252.3963 - val_mae: 253.0860\n",
      "Epoch 183/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 186.6330 - mae: 187.3226 - val_loss: 260.7353 - val_mae: 261.4275\n",
      "Epoch 184/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 191.1054 - mae: 191.7957 - val_loss: 252.2143 - val_mae: 252.8962\n",
      "Epoch 185/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 201.5103 - mae: 202.2025 - val_loss: 253.3454 - val_mae: 254.0353\n",
      "Epoch 186/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 182.1983 - mae: 182.8880 - val_loss: 261.6392 - val_mae: 262.3320\n",
      "Epoch 187/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.1462 - mae: 181.8348 - val_loss: 270.0733 - val_mae: 270.7663\n",
      "Epoch 188/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.1834 - mae: 182.8754 - val_loss: 259.4014 - val_mae: 260.0917\n",
      "Epoch 189/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.2934 - mae: 183.9852 - val_loss: 253.2072 - val_mae: 253.9002\n",
      "Epoch 190/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 184.6264 - mae: 185.3190 - val_loss: 254.4727 - val_mae: 255.1648\n",
      "Epoch 191/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 185.6292 - mae: 186.3184 - val_loss: 251.1998 - val_mae: 251.8905\n",
      "Epoch 192/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 185.2736 - mae: 185.9656 - val_loss: 251.9576 - val_mae: 252.6504\n",
      "Epoch 193/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 182.2032 - mae: 182.8955 - val_loss: 251.6230 - val_mae: 252.3161\n",
      "Epoch 194/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 183.4854 - mae: 184.1761 - val_loss: 251.6329 - val_mae: 252.3260\n",
      "Epoch 195/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 181.6767 - mae: 182.3681 - val_loss: 260.0282 - val_mae: 260.7213\n",
      "Epoch 196/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 189.4346 - mae: 190.1266 - val_loss: 256.1566 - val_mae: 256.8481\n",
      "Epoch 197/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.6777 - mae: 180.3682 - val_loss: 270.1140 - val_mae: 270.7989\n",
      "Epoch 198/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 189.0577 - mae: 189.7474 - val_loss: 258.1964 - val_mae: 258.8892\n",
      "Epoch 199/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 188.5224 - mae: 189.2132 - val_loss: 250.9324 - val_mae: 251.6240\n",
      "Epoch 200/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.7164 - mae: 172.4084 - val_loss: 251.5527 - val_mae: 252.2438\n",
      "Epoch 201/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 193.3467 - mae: 194.0375 - val_loss: 251.4503 - val_mae: 252.1387\n",
      "Epoch 202/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.2499 - mae: 189.9429 - val_loss: 257.5442 - val_mae: 258.2325\n",
      "Epoch 203/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 191.0993 - mae: 191.7916 - val_loss: 259.7939 - val_mae: 260.4849\n",
      "Epoch 204/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.2141 - mae: 173.9066 - val_loss: 251.7422 - val_mae: 252.4330\n",
      "Epoch 205/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 183.0948 - mae: 183.7872 - val_loss: 258.6145 - val_mae: 259.3077\n",
      "Epoch 206/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 188.2492 - mae: 188.9404 - val_loss: 270.2716 - val_mae: 270.9647\n",
      "Epoch 207/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 194.3625 - mae: 195.0529 - val_loss: 274.7447 - val_mae: 275.4377\n",
      "Epoch 208/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 193.6782 - mae: 194.3708 - val_loss: 250.7715 - val_mae: 251.4623\n",
      "Epoch 209/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 196.7502 - mae: 197.4429 - val_loss: 250.7866 - val_mae: 251.4777\n",
      "Epoch 210/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 194.7545 - mae: 195.4446 - val_loss: 255.0363 - val_mae: 255.7292\n",
      "Epoch 211/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 183.9082 - mae: 184.5957 - val_loss: 250.2535 - val_mae: 250.9458\n",
      "Epoch 212/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 175.8047 - mae: 176.4927 - val_loss: 249.5841 - val_mae: 250.2759\n",
      "Epoch 213/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 185.4535 - mae: 186.1413 - val_loss: 265.1207 - val_mae: 265.8111\n",
      "Epoch 214/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 183.1678 - mae: 183.8586 - val_loss: 251.7267 - val_mae: 252.4182\n",
      "Epoch 215/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 184.3044 - mae: 184.9921 - val_loss: 250.3072 - val_mae: 250.9954\n",
      "Epoch 216/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 208.5193 - mae: 209.2095 - val_loss: 258.6968 - val_mae: 259.3896\n",
      "Epoch 217/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 195.1124 - mae: 195.8034 - val_loss: 255.2701 - val_mae: 255.9608\n",
      "Epoch 218/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 195.1320 - mae: 195.8232 - val_loss: 273.4258 - val_mae: 274.1187\n",
      "Epoch 219/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 187.6290 - mae: 188.3189 - val_loss: 250.8036 - val_mae: 251.4965\n",
      "Epoch 220/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 191.1164 - mae: 191.8086 - val_loss: 249.4843 - val_mae: 250.1741\n",
      "Epoch 221/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 185.0619 - mae: 185.7546 - val_loss: 249.1138 - val_mae: 249.8066\n",
      "Epoch 222/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.0891 - mae: 180.7772 - val_loss: 250.2607 - val_mae: 250.9531\n",
      "Epoch 223/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 168.0318 - mae: 168.7228 - val_loss: 250.0108 - val_mae: 250.6989\n",
      "Epoch 224/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 171.7597 - mae: 172.4498 - val_loss: 257.6235 - val_mae: 258.3138\n",
      "Epoch 225/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.0628 - mae: 180.7548 - val_loss: 255.8275 - val_mae: 256.5202\n",
      "Epoch 226/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 194.0826 - mae: 194.7746 - val_loss: 248.8985 - val_mae: 249.5855\n",
      "Epoch 227/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.5801 - mae: 192.2728 - val_loss: 252.2127 - val_mae: 252.8997\n",
      "Epoch 228/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.6227 - mae: 177.3124 - val_loss: 249.8385 - val_mae: 250.5309\n",
      "Epoch 229/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.6552 - mae: 173.3457 - val_loss: 257.7388 - val_mae: 258.4285\n",
      "Epoch 230/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.2489 - mae: 183.9406 - val_loss: 250.3002 - val_mae: 250.9923\n",
      "Epoch 231/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.7189 - mae: 175.4112 - val_loss: 257.7867 - val_mae: 258.4778\n",
      "Epoch 232/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 179.4655 - mae: 180.1551 - val_loss: 248.1834 - val_mae: 248.8727\n",
      "Epoch 233/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 180.2237 - mae: 180.9146 - val_loss: 289.8922 - val_mae: 290.5851\n",
      "Epoch 234/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 205.1065 - mae: 205.7988 - val_loss: 259.0582 - val_mae: 259.7458\n",
      "Epoch 235/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.1137 - mae: 179.8033 - val_loss: 256.3394 - val_mae: 257.0321\n",
      "Epoch 236/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.8699 - mae: 179.5626 - val_loss: 254.5654 - val_mae: 255.2568\n",
      "Epoch 237/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 178.4392 - mae: 179.1269 - val_loss: 252.3224 - val_mae: 253.0155\n",
      "Epoch 238/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.0471 - mae: 188.7371 - val_loss: 255.9804 - val_mae: 256.6721\n",
      "Epoch 239/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 180.5028 - mae: 181.1940 - val_loss: 249.3322 - val_mae: 250.0249\n",
      "Epoch 240/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 178.3664 - mae: 179.0584 - val_loss: 257.5005 - val_mae: 258.1923\n",
      "Epoch 241/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.9502 - mae: 184.6395 - val_loss: 257.9222 - val_mae: 258.6154\n",
      "Epoch 242/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.3155 - mae: 173.0070 - val_loss: 255.9802 - val_mae: 256.6733\n",
      "Epoch 243/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 182.7688 - mae: 183.4586 - val_loss: 249.9681 - val_mae: 250.6595\n",
      "Epoch 244/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 188.7467 - mae: 189.4388 - val_loss: 250.5768 - val_mae: 251.2658\n",
      "Epoch 245/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.4174 - mae: 180.1074 - val_loss: 248.1982 - val_mae: 248.8884\n",
      "Epoch 246/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.1222 - mae: 188.8116 - val_loss: 254.0871 - val_mae: 254.7793\n",
      "Epoch 247/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 179.6086 - mae: 180.2991 - val_loss: 247.4830 - val_mae: 248.1751\n",
      "Epoch 248/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.7323 - mae: 178.4223 - val_loss: 248.0866 - val_mae: 248.7751\n",
      "Epoch 249/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.0281 - mae: 181.7200 - val_loss: 247.8334 - val_mae: 248.5248\n",
      "Epoch 250/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.1152 - mae: 188.8076 - val_loss: 247.7505 - val_mae: 248.4401\n",
      "Epoch 251/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.2804 - mae: 175.9729 - val_loss: 247.9665 - val_mae: 248.6578\n",
      "Epoch 252/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.7365 - mae: 176.4288 - val_loss: 248.7661 - val_mae: 249.4549\n",
      "Epoch 253/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 180.1853 - mae: 180.8768 - val_loss: 253.1205 - val_mae: 253.8132\n",
      "Epoch 254/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 177.7411 - mae: 178.4302 - val_loss: 250.2316 - val_mae: 250.9182\n",
      "Epoch 255/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 184.9760 - mae: 185.6682 - val_loss: 287.9176 - val_mae: 288.6106\n",
      "Epoch 256/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.9342 - mae: 182.6269 - val_loss: 251.5273 - val_mae: 252.2099\n",
      "Epoch 257/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 186.7563 - mae: 187.4454 - val_loss: 250.8371 - val_mae: 251.5246\n",
      "Epoch 258/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.7888 - mae: 179.4755 - val_loss: 250.2437 - val_mae: 250.9366\n",
      "Epoch 259/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.9415 - mae: 189.6340 - val_loss: 254.1597 - val_mae: 254.8474\n",
      "Epoch 260/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 190.8926 - mae: 191.5845 - val_loss: 254.0745 - val_mae: 254.7643\n",
      "Epoch 261/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.4785 - mae: 182.1708 - val_loss: 250.8160 - val_mae: 251.5030\n",
      "Epoch 262/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.0866 - mae: 172.7749 - val_loss: 264.0890 - val_mae: 264.7797\n",
      "Epoch 263/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 178.0016 - mae: 178.6929 - val_loss: 247.3597 - val_mae: 248.0503\n",
      "Epoch 264/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 197.2431 - mae: 197.9315 - val_loss: 252.5601 - val_mae: 253.2532\n",
      "Epoch 265/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.2819 - mae: 178.9715 - val_loss: 260.0765 - val_mae: 260.7690\n",
      "Epoch 266/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.6352 - mae: 178.3275 - val_loss: 248.7138 - val_mae: 249.3969\n",
      "Epoch 267/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.6686 - mae: 173.3598 - val_loss: 248.3926 - val_mae: 249.0793\n",
      "Epoch 268/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 169.1799 - mae: 169.8721 - val_loss: 246.1697 - val_mae: 246.8623\n",
      "Epoch 269/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.0509 - mae: 186.7413 - val_loss: 270.1668 - val_mae: 270.8592\n",
      "Epoch 270/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.9539 - mae: 175.6467 - val_loss: 264.9135 - val_mae: 265.6048\n",
      "Epoch 271/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.8667 - mae: 187.5590 - val_loss: 251.0534 - val_mae: 251.7460\n",
      "Epoch 272/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.8456 - mae: 181.5377 - val_loss: 248.8258 - val_mae: 249.5184\n",
      "Epoch 273/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.6898 - mae: 182.3801 - val_loss: 250.0300 - val_mae: 250.7231\n",
      "Epoch 274/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 168.3095 - mae: 169.0000 - val_loss: 248.2028 - val_mae: 248.8933\n",
      "Epoch 275/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 182.5056 - mae: 183.1975 - val_loss: 248.0846 - val_mae: 248.7675\n",
      "Epoch 276/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.2927 - mae: 176.9809 - val_loss: 250.4420 - val_mae: 251.1320\n",
      "Epoch 277/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 180.6707 - mae: 181.3598 - val_loss: 246.7320 - val_mae: 247.4236\n",
      "Epoch 278/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.1510 - mae: 185.8429 - val_loss: 249.0880 - val_mae: 249.7791\n",
      "Epoch 279/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.6542 - mae: 177.3448 - val_loss: 254.5016 - val_mae: 255.1897\n",
      "Epoch 280/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 198.2461 - mae: 198.9364 - val_loss: 251.2999 - val_mae: 251.9895\n",
      "Epoch 281/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.7034 - mae: 176.3946 - val_loss: 247.3805 - val_mae: 248.0736\n",
      "Epoch 282/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.9918 - mae: 174.6811 - val_loss: 252.8300 - val_mae: 253.5176\n",
      "Epoch 283/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.4590 - mae: 181.1495 - val_loss: 250.7957 - val_mae: 251.4875\n",
      "Epoch 284/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 175.0057 - mae: 175.6957 - val_loss: 259.3068 - val_mae: 259.9961\n",
      "Epoch 285/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 171.9046 - mae: 172.5925 - val_loss: 248.4894 - val_mae: 249.1816\n",
      "Epoch 286/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 174.3623 - mae: 175.0552 - val_loss: 247.5879 - val_mae: 248.2793\n",
      "Epoch 287/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 179.5506 - mae: 180.2403 - val_loss: 245.9832 - val_mae: 246.6760\n",
      "Epoch 288/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 29ms/step - loss: 177.0298 - mae: 177.7193 - val_loss: 245.0731 - val_mae: 245.7644\n",
      "Epoch 289/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 175.1493 - mae: 175.8405 - val_loss: 255.7710 - val_mae: 256.4634\n",
      "Epoch 290/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.8871 - mae: 184.5770 - val_loss: 245.2357 - val_mae: 245.9288\n",
      "Epoch 291/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 169.3848 - mae: 170.0760 - val_loss: 245.8201 - val_mae: 246.5108\n",
      "Epoch 292/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.2199 - mae: 180.9117 - val_loss: 252.8678 - val_mae: 253.5595\n",
      "Epoch 293/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.1572 - mae: 180.8488 - val_loss: 251.6449 - val_mae: 252.3330\n",
      "Epoch 294/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 182.5197 - mae: 183.2127 - val_loss: 245.5871 - val_mae: 246.2802\n",
      "Epoch 295/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 187.7184 - mae: 188.4103 - val_loss: 248.8472 - val_mae: 249.5356\n",
      "Epoch 296/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 181.9648 - mae: 182.6529 - val_loss: 285.7206 - val_mae: 286.4134\n",
      "Epoch 297/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.8673 - mae: 190.5572 - val_loss: 247.7965 - val_mae: 248.4869\n",
      "Epoch 298/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 179.3437 - mae: 180.0322 - val_loss: 248.8291 - val_mae: 249.5209\n",
      "Epoch 299/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.1294 - mae: 174.8223 - val_loss: 249.1295 - val_mae: 249.8190\n",
      "Epoch 300/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.9687 - mae: 183.6606 - val_loss: 262.0532 - val_mae: 262.7464\n",
      "Epoch 301/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 197.3228 - mae: 198.0142 - val_loss: 244.7626 - val_mae: 245.4547\n",
      "Epoch 302/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.3980 - mae: 184.0900 - val_loss: 267.0041 - val_mae: 267.6967\n",
      "Epoch 303/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 177.9885 - mae: 178.6752 - val_loss: 251.2066 - val_mae: 251.8988\n",
      "Epoch 304/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 177.2856 - mae: 177.9765 - val_loss: 243.6621 - val_mae: 244.3530\n",
      "Epoch 305/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.1959 - mae: 191.8883 - val_loss: 246.5240 - val_mae: 247.2160\n",
      "Epoch 306/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 194.2403 - mae: 194.9314 - val_loss: 246.6110 - val_mae: 247.3011\n",
      "Epoch 307/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 173.2401 - mae: 173.9325 - val_loss: 248.6402 - val_mae: 249.3295\n",
      "Epoch 308/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.3653 - mae: 187.0564 - val_loss: 245.8328 - val_mae: 246.5251\n",
      "Epoch 309/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 180.3687 - mae: 181.0605 - val_loss: 247.2798 - val_mae: 247.9661\n",
      "Epoch 310/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.3386 - mae: 175.0271 - val_loss: 287.3696 - val_mae: 288.0627\n",
      "Epoch 311/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 199.9207 - mae: 200.6123 - val_loss: 246.5597 - val_mae: 247.2528\n",
      "Epoch 312/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.7084 - mae: 184.3977 - val_loss: 257.6216 - val_mae: 258.3112\n",
      "Epoch 313/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 191.6244 - mae: 192.3157 - val_loss: 244.8785 - val_mae: 245.5693\n",
      "Epoch 314/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 183.6291 - mae: 184.3183 - val_loss: 268.8338 - val_mae: 269.5261\n",
      "Epoch 315/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 193.1883 - mae: 193.8784 - val_loss: 247.3610 - val_mae: 248.0520\n",
      "Epoch 316/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 162.5944 - mae: 163.2826 - val_loss: 246.0112 - val_mae: 246.7012\n",
      "Epoch 317/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.8755 - mae: 182.5646 - val_loss: 245.5210 - val_mae: 246.2141\n",
      "Epoch 318/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 163.6096 - mae: 164.3010 - val_loss: 252.6322 - val_mae: 253.3226\n",
      "Epoch 319/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.1880 - mae: 172.8787 - val_loss: 247.4159 - val_mae: 248.1081\n",
      "Epoch 320/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.5813 - mae: 172.2709 - val_loss: 256.6530 - val_mae: 257.3443\n",
      "Epoch 321/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.9488 - mae: 173.6405 - val_loss: 252.5328 - val_mae: 253.2154\n",
      "Epoch 322/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.6508 - mae: 181.3396 - val_loss: 246.7098 - val_mae: 247.4027\n",
      "Epoch 323/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 192.5738 - mae: 193.2643 - val_loss: 246.7562 - val_mae: 247.4488\n",
      "Epoch 324/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 183.9389 - mae: 184.6280 - val_loss: 264.5488 - val_mae: 265.2416\n",
      "Epoch 325/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 179.6334 - mae: 180.3235 - val_loss: 247.7700 - val_mae: 248.4613\n",
      "Epoch 326/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.9040 - mae: 183.5925 - val_loss: 246.3151 - val_mae: 247.0043\n",
      "Epoch 327/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 171.1073 - mae: 171.7969 - val_loss: 251.3523 - val_mae: 252.0412\n",
      "Epoch 328/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.4597 - mae: 189.1525 - val_loss: 244.0959 - val_mae: 244.7888\n",
      "Epoch 329/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.5013 - mae: 172.1933 - val_loss: 254.7464 - val_mae: 255.4376\n",
      "Epoch 330/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 178.9976 - mae: 179.6846 - val_loss: 244.9517 - val_mae: 245.6387\n",
      "Epoch 331/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.2058 - mae: 178.8951 - val_loss: 250.6476 - val_mae: 251.3349\n",
      "Epoch 332/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 184.0558 - mae: 184.7478 - val_loss: 250.2461 - val_mae: 250.9347\n",
      "Epoch 333/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 179.5278 - mae: 180.2200 - val_loss: 249.2155 - val_mae: 249.9077\n",
      "Epoch 334/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 172.8457 - mae: 173.5384 - val_loss: 246.5859 - val_mae: 247.2757\n",
      "Epoch 335/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 180.6899 - mae: 181.3796 - val_loss: 244.4190 - val_mae: 245.1043\n",
      "Epoch 336/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.4904 - mae: 186.1809 - val_loss: 252.1446 - val_mae: 252.8378\n",
      "Epoch 337/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 176.6025 - mae: 177.2907 - val_loss: 244.8199 - val_mae: 245.5128\n",
      "Epoch 338/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.9763 - mae: 175.6673 - val_loss: 246.2935 - val_mae: 246.9823\n",
      "Epoch 339/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.3909 - mae: 185.0808 - val_loss: 245.8099 - val_mae: 246.5026\n",
      "Epoch 340/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.5288 - mae: 178.2203 - val_loss: 244.8436 - val_mae: 245.5360\n",
      "Epoch 341/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 171.7985 - mae: 172.4883 - val_loss: 246.5390 - val_mae: 247.2297\n",
      "Epoch 342/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.4799 - mae: 189.1675 - val_loss: 250.6161 - val_mae: 251.3087\n",
      "Epoch 343/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.9743 - mae: 165.6658 - val_loss: 245.1135 - val_mae: 245.8064\n",
      "Epoch 344/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 175.4357 - mae: 176.1269 - val_loss: 242.8209 - val_mae: 243.5117\n",
      "Epoch 345/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 198.7881 - mae: 199.4758 - val_loss: 245.3105 - val_mae: 245.9994\n",
      "Epoch 346/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 165.4622 - mae: 166.1536 - val_loss: 244.0637 - val_mae: 244.7501\n",
      "Epoch 347/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.2007 - mae: 176.8893 - val_loss: 244.4174 - val_mae: 245.1081\n",
      "Epoch 348/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.1952 - mae: 186.8858 - val_loss: 245.7591 - val_mae: 246.4470\n",
      "Epoch 349/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 166.1561 - mae: 166.8456 - val_loss: 244.0602 - val_mae: 244.7499\n",
      "Epoch 350/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 193.8600 - mae: 194.5514 - val_loss: 252.3236 - val_mae: 253.0147\n",
      "Epoch 351/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 180.1263 - mae: 180.8182 - val_loss: 257.6485 - val_mae: 258.3392\n",
      "Epoch 352/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.9796 - mae: 176.6708 - val_loss: 244.2691 - val_mae: 244.9606\n",
      "Epoch 353/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 182.2184 - mae: 182.9095 - val_loss: 244.8659 - val_mae: 245.5520\n",
      "Epoch 354/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.2396 - mae: 176.9321 - val_loss: 255.1661 - val_mae: 255.8567\n",
      "Epoch 355/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 191.0732 - mae: 191.7654 - val_loss: 245.2013 - val_mae: 245.8937\n",
      "Epoch 356/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.7168 - mae: 173.4084 - val_loss: 245.5389 - val_mae: 246.2308\n",
      "Epoch 357/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.5545 - mae: 179.2425 - val_loss: 243.5965 - val_mae: 244.2841\n",
      "Epoch 358/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 170.5872 - mae: 171.2791 - val_loss: 244.1035 - val_mae: 244.7966\n",
      "Epoch 359/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.6145 - mae: 178.3047 - val_loss: 252.3805 - val_mae: 253.0737\n",
      "Epoch 360/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 185.3978 - mae: 186.0867 - val_loss: 255.6144 - val_mae: 256.3040\n",
      "Epoch 361/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.5184 - mae: 171.2096 - val_loss: 245.0933 - val_mae: 245.7837\n",
      "Epoch 362/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 169.9764 - mae: 170.6644 - val_loss: 247.4533 - val_mae: 248.1377\n",
      "Epoch 363/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.7555 - mae: 179.4473 - val_loss: 252.4769 - val_mae: 253.1677\n",
      "Epoch 364/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.0817 - mae: 171.7736 - val_loss: 245.0767 - val_mae: 245.7689\n",
      "Epoch 365/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 169.3792 - mae: 170.0681 - val_loss: 248.0179 - val_mae: 248.7090\n",
      "Epoch 366/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 173.5896 - mae: 174.2817 - val_loss: 258.7398 - val_mae: 259.4323\n",
      "Epoch 367/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.1543 - mae: 174.8458 - val_loss: 253.5109 - val_mae: 254.2022\n",
      "Epoch 368/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.4277 - mae: 192.1187 - val_loss: 254.9756 - val_mae: 255.6687\n",
      "Epoch 369/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.7108 - mae: 177.4026 - val_loss: 243.0474 - val_mae: 243.7387\n",
      "Epoch 370/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 161.2141 - mae: 161.9067 - val_loss: 242.4576 - val_mae: 243.1493\n",
      "Epoch 371/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.4590 - mae: 177.1492 - val_loss: 252.6258 - val_mae: 253.3164\n",
      "Epoch 372/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.7153 - mae: 182.4059 - val_loss: 247.9621 - val_mae: 248.6489\n",
      "Epoch 373/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.3988 - mae: 171.0875 - val_loss: 244.4430 - val_mae: 245.1353\n",
      "Epoch 374/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.9860 - mae: 169.6769 - val_loss: 244.8100 - val_mae: 245.4947\n",
      "Epoch 375/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 168.7231 - mae: 169.4113 - val_loss: 248.9499 - val_mae: 249.6373\n",
      "Epoch 376/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 178.3787 - mae: 179.0681 - val_loss: 242.9638 - val_mae: 243.6492\n",
      "Epoch 377/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 161.3465 - mae: 162.0343 - val_loss: 247.1530 - val_mae: 247.8429\n",
      "Epoch 378/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.6456 - mae: 168.3368 - val_loss: 244.2955 - val_mae: 244.9848\n",
      "Epoch 379/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 163.2891 - mae: 163.9815 - val_loss: 244.2240 - val_mae: 244.9147\n",
      "Epoch 380/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.9715 - mae: 174.6614 - val_loss: 243.2787 - val_mae: 243.9648\n",
      "Epoch 381/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 184.2202 - mae: 184.9095 - val_loss: 251.6120 - val_mae: 252.3017\n",
      "Epoch 382/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.3234 - mae: 177.0138 - val_loss: 246.9168 - val_mae: 247.6042\n",
      "Epoch 383/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.5769 - mae: 168.2675 - val_loss: 260.3200 - val_mae: 261.0126\n",
      "Epoch 384/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.1950 - mae: 184.8870 - val_loss: 261.4267 - val_mae: 262.1198\n",
      "Epoch 385/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 184.2887 - mae: 184.9802 - val_loss: 244.0286 - val_mae: 244.7205\n",
      "Epoch 386/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 170.3386 - mae: 171.0275 - val_loss: 243.2931 - val_mae: 243.9847\n",
      "Epoch 387/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.2953 - mae: 177.9863 - val_loss: 244.7182 - val_mae: 245.4094\n",
      "Epoch 388/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 177.1271 - mae: 177.8199 - val_loss: 328.3993 - val_mae: 329.0912\n",
      "Epoch 389/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 217.5326 - mae: 218.2257 - val_loss: 252.2638 - val_mae: 252.9534\n",
      "Epoch 390/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.5477 - mae: 186.2403 - val_loss: 245.9426 - val_mae: 246.6320\n",
      "Epoch 391/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.9301 - mae: 172.6193 - val_loss: 244.3274 - val_mae: 245.0183\n",
      "Epoch 392/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.4244 - mae: 171.1155 - val_loss: 249.0056 - val_mae: 249.6915\n",
      "Epoch 393/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.6565 - mae: 168.3472 - val_loss: 256.2694 - val_mae: 256.9588\n",
      "Epoch 394/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.4031 - mae: 178.0935 - val_loss: 244.1840 - val_mae: 244.8712\n",
      "Epoch 395/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 167.6373 - mae: 168.3295 - val_loss: 244.2583 - val_mae: 244.9514\n",
      "Epoch 396/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 185.2377 - mae: 185.9293 - val_loss: 253.4882 - val_mae: 254.1805\n",
      "Epoch 397/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.4353 - mae: 169.1257 - val_loss: 245.6574 - val_mae: 246.3477\n",
      "Epoch 398/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.8764 - mae: 187.5685 - val_loss: 243.6701 - val_mae: 244.3604\n",
      "Epoch 399/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.5515 - mae: 183.2404 - val_loss: 260.1966 - val_mae: 260.8897\n",
      "Epoch 400/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 173.6428 - mae: 174.3345 - val_loss: 248.0416 - val_mae: 248.7341\n",
      "Epoch 401/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 183.0607 - mae: 183.7519 - val_loss: 241.2628 - val_mae: 241.9556\n",
      "Epoch 402/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.5675 - mae: 177.2586 - val_loss: 243.6323 - val_mae: 244.3244\n",
      "Epoch 403/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.9232 - mae: 177.6154 - val_loss: 250.8355 - val_mae: 251.5236\n",
      "Epoch 404/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.8662 - mae: 181.5581 - val_loss: 246.5054 - val_mae: 247.1982\n",
      "Epoch 405/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 175.9178 - mae: 176.6091 - val_loss: 242.5489 - val_mae: 243.2384\n",
      "Epoch 406/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 184.0691 - mae: 184.7601 - val_loss: 249.2236 - val_mae: 249.9138\n",
      "Epoch 407/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 187.5744 - mae: 188.2641 - val_loss: 242.1881 - val_mae: 242.8767\n",
      "Epoch 408/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.8599 - mae: 178.5507 - val_loss: 260.1234 - val_mae: 260.8142\n",
      "Epoch 409/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 166.9749 - mae: 167.6657 - val_loss: 248.0995 - val_mae: 248.7894\n",
      "Epoch 410/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.9580 - mae: 168.6462 - val_loss: 248.6350 - val_mae: 249.3281\n",
      "Epoch 411/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.7167 - mae: 169.4055 - val_loss: 242.6147 - val_mae: 243.3008\n",
      "Epoch 412/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 169.9355 - mae: 170.6277 - val_loss: 243.1626 - val_mae: 243.8557\n",
      "Epoch 413/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.5883 - mae: 173.2778 - val_loss: 242.5572 - val_mae: 243.2479\n",
      "Epoch 414/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.2749 - mae: 171.9615 - val_loss: 261.1371 - val_mae: 261.8271\n",
      "Epoch 415/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 192.9970 - mae: 193.6892 - val_loss: 245.1830 - val_mae: 245.8751\n",
      "Epoch 416/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 186.0314 - mae: 186.7234 - val_loss: 243.5968 - val_mae: 244.2881\n",
      "Epoch 417/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 164.8500 - mae: 165.5395 - val_loss: 249.5190 - val_mae: 250.2121\n",
      "Epoch 418/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.8457 - mae: 176.5348 - val_loss: 242.2509 - val_mae: 242.9419\n",
      "Epoch 419/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.3034 - mae: 168.9958 - val_loss: 255.6645 - val_mae: 256.3571\n",
      "Epoch 420/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 183.0439 - mae: 183.7336 - val_loss: 251.5316 - val_mae: 252.2241\n",
      "Epoch 421/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 175.0390 - mae: 175.7278 - val_loss: 261.0450 - val_mae: 261.7370\n",
      "Epoch 422/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.5851 - mae: 172.2739 - val_loss: 243.6255 - val_mae: 244.3186\n",
      "Epoch 423/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.6698 - mae: 176.3572 - val_loss: 245.6305 - val_mae: 246.3160\n",
      "Epoch 424/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.5227 - mae: 179.2151 - val_loss: 244.9448 - val_mae: 245.6378\n",
      "Epoch 425/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.4836 - mae: 179.1699 - val_loss: 253.1631 - val_mae: 253.8545\n",
      "Epoch 426/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 191.8311 - mae: 192.5232 - val_loss: 265.9508 - val_mae: 266.6439\n",
      "Epoch 427/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 172.6237 - mae: 173.3154 - val_loss: 250.1988 - val_mae: 250.8919\n",
      "Epoch 428/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.0075 - mae: 176.7001 - val_loss: 251.1766 - val_mae: 251.8661\n",
      "Epoch 429/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 173.4805 - mae: 174.1714 - val_loss: 256.7422 - val_mae: 257.4342\n",
      "Epoch 430/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 188.3847 - mae: 189.0755 - val_loss: 274.3336 - val_mae: 275.0266\n",
      "Epoch 431/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.7099 - mae: 185.4019 - val_loss: 254.7571 - val_mae: 255.4470\n",
      "Epoch 432/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.9756 - mae: 185.6650 - val_loss: 242.6257 - val_mae: 243.3143\n",
      "Epoch 433/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.1188 - mae: 184.8088 - val_loss: 251.4478 - val_mae: 252.1400\n",
      "Epoch 434/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 162.1350 - mae: 162.8240 - val_loss: 241.9003 - val_mae: 242.5905\n",
      "Epoch 435/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.4368 - mae: 171.1223 - val_loss: 245.9616 - val_mae: 246.6505\n",
      "Epoch 436/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.5057 - mae: 189.1979 - val_loss: 252.2913 - val_mae: 252.9844\n",
      "Epoch 437/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 185.8519 - mae: 186.5427 - val_loss: 251.7885 - val_mae: 252.4800\n",
      "Epoch 438/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.5138 - mae: 176.2036 - val_loss: 248.4264 - val_mae: 249.1161\n",
      "Epoch 439/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.7814 - mae: 181.4683 - val_loss: 249.9590 - val_mae: 250.6521\n",
      "Epoch 440/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.2398 - mae: 177.9311 - val_loss: 265.4540 - val_mae: 266.1438\n",
      "Epoch 441/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.0623 - mae: 186.7535 - val_loss: 244.5225 - val_mae: 245.2137\n",
      "Epoch 442/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.4052 - mae: 174.0957 - val_loss: 242.0491 - val_mae: 242.7418\n",
      "Epoch 443/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.9102 - mae: 185.5990 - val_loss: 248.5386 - val_mae: 249.2315\n",
      "Epoch 444/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.4040 - mae: 171.0951 - val_loss: 241.7595 - val_mae: 242.4482\n",
      "Epoch 445/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.2435 - mae: 167.9340 - val_loss: 242.1441 - val_mae: 242.8351\n",
      "Epoch 446/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 31ms/step - loss: 170.0192 - mae: 170.7079 - val_loss: 240.3359 - val_mae: 241.0277\n",
      "Epoch 447/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 174.1297 - mae: 174.8188 - val_loss: 241.7234 - val_mae: 242.4132\n",
      "Epoch 448/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 178.4225 - mae: 179.1127 - val_loss: 241.3762 - val_mae: 242.0641\n",
      "Epoch 449/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.4438 - mae: 174.1343 - val_loss: 241.8648 - val_mae: 242.5574\n",
      "Epoch 450/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.3690 - mae: 178.0612 - val_loss: 242.9940 - val_mae: 243.6840\n",
      "Epoch 451/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.4869 - mae: 181.1763 - val_loss: 243.7209 - val_mae: 244.4140\n",
      "Epoch 452/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 161.2554 - mae: 161.9471 - val_loss: 243.6630 - val_mae: 244.3555\n",
      "Epoch 453/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 168.5757 - mae: 169.2670 - val_loss: 256.2953 - val_mae: 256.9882\n",
      "Epoch 454/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 169.6221 - mae: 170.3106 - val_loss: 240.9246 - val_mae: 241.6138\n",
      "Epoch 455/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.8134 - mae: 184.5009 - val_loss: 242.5557 - val_mae: 243.2473\n",
      "Epoch 456/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 169.6871 - mae: 170.3774 - val_loss: 240.6493 - val_mae: 241.3268\n",
      "Epoch 457/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 182.1499 - mae: 182.8361 - val_loss: 258.5210 - val_mae: 259.2093\n",
      "Epoch 458/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 178.0323 - mae: 178.7206 - val_loss: 249.4332 - val_mae: 250.1260\n",
      "Epoch 459/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.1219 - mae: 164.8139 - val_loss: 247.2941 - val_mae: 247.9859\n",
      "Epoch 460/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 177.9385 - mae: 178.6302 - val_loss: 252.5075 - val_mae: 253.2002\n",
      "Epoch 461/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 195.8747 - mae: 196.5654 - val_loss: 243.9252 - val_mae: 244.6136\n",
      "Epoch 462/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.3677 - mae: 172.0569 - val_loss: 243.8556 - val_mae: 244.5434\n",
      "Epoch 463/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 173.5734 - mae: 174.2641 - val_loss: 254.9469 - val_mae: 255.6382\n",
      "Epoch 464/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 180.8223 - mae: 181.5136 - val_loss: 248.9339 - val_mae: 249.6250\n",
      "Epoch 465/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.5597 - mae: 182.2507 - val_loss: 240.4707 - val_mae: 241.1572\n",
      "Epoch 466/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.8803 - mae: 181.5696 - val_loss: 248.0367 - val_mae: 248.7250\n",
      "Epoch 467/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.0389 - mae: 191.7304 - val_loss: 244.1734 - val_mae: 244.8660\n",
      "Epoch 468/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 174.6832 - mae: 175.3743 - val_loss: 242.2712 - val_mae: 242.9622\n",
      "Epoch 469/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.6226 - mae: 174.3121 - val_loss: 272.2171 - val_mae: 272.9102\n",
      "Epoch 470/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.5495 - mae: 171.2401 - val_loss: 245.4774 - val_mae: 246.1703\n",
      "Epoch 471/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.5810 - mae: 182.2720 - val_loss: 248.8658 - val_mae: 249.5580\n",
      "Epoch 472/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 161.4025 - mae: 162.0914 - val_loss: 242.3671 - val_mae: 243.0585\n",
      "Epoch 473/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.1839 - mae: 176.8702 - val_loss: 251.5878 - val_mae: 252.2791\n",
      "Epoch 474/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 166.8429 - mae: 167.5327 - val_loss: 241.2066 - val_mae: 241.8930\n",
      "Epoch 475/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.3033 - mae: 178.9956 - val_loss: 253.7086 - val_mae: 254.3981\n",
      "Epoch 476/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.8755 - mae: 169.5681 - val_loss: 246.8733 - val_mae: 247.5634\n",
      "Epoch 477/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 179.3199 - mae: 180.0115 - val_loss: 242.7745 - val_mae: 243.4601\n",
      "Epoch 478/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 162.9556 - mae: 163.6453 - val_loss: 243.8862 - val_mae: 244.5768\n",
      "Epoch 479/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.3650 - mae: 180.0571 - val_loss: 240.8076 - val_mae: 241.5004\n",
      "Epoch 480/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 165.7104 - mae: 166.3999 - val_loss: 245.7562 - val_mae: 246.4463\n",
      "Epoch 481/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.1585 - mae: 176.8504 - val_loss: 242.1776 - val_mae: 242.8681\n",
      "Epoch 482/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 165.0456 - mae: 165.7351 - val_loss: 250.6860 - val_mae: 251.3791\n",
      "Epoch 483/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.4229 - mae: 179.1133 - val_loss: 252.4396 - val_mae: 253.1308\n",
      "Epoch 484/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 188.4199 - mae: 189.1116 - val_loss: 246.1598 - val_mae: 246.8461\n",
      "Epoch 485/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.7823 - mae: 176.4736 - val_loss: 243.3687 - val_mae: 244.0599\n",
      "Epoch 486/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.0676 - mae: 178.7593 - val_loss: 244.4393 - val_mae: 245.1297\n",
      "Epoch 487/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.1893 - mae: 186.8806 - val_loss: 249.3086 - val_mae: 250.0015\n",
      "Epoch 488/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 171.4998 - mae: 172.1898 - val_loss: 244.4001 - val_mae: 245.0910\n",
      "Epoch 489/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 169.6678 - mae: 170.3530 - val_loss: 247.3123 - val_mae: 248.0053\n",
      "Epoch 490/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 166.8275 - mae: 167.5180 - val_loss: 265.7672 - val_mae: 266.4603\n",
      "Epoch 491/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.4289 - mae: 179.1202 - val_loss: 242.4007 - val_mae: 243.0925\n",
      "Epoch 492/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 169.3507 - mae: 170.0414 - val_loss: 241.7505 - val_mae: 242.4431\n",
      "Epoch 493/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 170.8601 - mae: 171.5510 - val_loss: 240.6856 - val_mae: 241.3769\n",
      "Epoch 494/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.1667 - mae: 167.8569 - val_loss: 241.1195 - val_mae: 241.8125\n",
      "Epoch 495/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.3768 - mae: 182.0682 - val_loss: 241.0325 - val_mae: 241.7174\n",
      "Epoch 496/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 179.0955 - mae: 179.7862 - val_loss: 253.0383 - val_mae: 253.7267\n",
      "Epoch 497/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 30ms/step - loss: 177.6908 - mae: 178.3827 - val_loss: 239.0548 - val_mae: 239.7431\n",
      "Epoch 498/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 176.6224 - mae: 177.3126 - val_loss: 241.9585 - val_mae: 242.6490\n",
      "Epoch 499/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 169.1135 - mae: 169.8018 - val_loss: 246.5581 - val_mae: 247.2442\n",
      "Epoch 500/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.6320 - mae: 181.3237 - val_loss: 255.4127 - val_mae: 256.1031\n",
      "Epoch 501/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.6224 - mae: 181.3130 - val_loss: 247.2083 - val_mae: 247.9014\n",
      "Epoch 502/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 160.4695 - mae: 161.1616 - val_loss: 239.7983 - val_mae: 240.4902\n",
      "Epoch 503/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 177.2018 - mae: 177.8913 - val_loss: 242.5378 - val_mae: 243.2283\n",
      "Epoch 504/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 171.4757 - mae: 172.1675 - val_loss: 243.2535 - val_mae: 243.9411\n",
      "Epoch 505/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 172.6334 - mae: 173.3243 - val_loss: 241.4828 - val_mae: 242.1724\n",
      "Epoch 506/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.2003 - mae: 172.8885 - val_loss: 239.4736 - val_mae: 240.1642\n",
      "Epoch 507/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.9771 - mae: 168.6697 - val_loss: 243.7749 - val_mae: 244.4622\n",
      "Epoch 508/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 169.6813 - mae: 170.3725 - val_loss: 255.8217 - val_mae: 256.5123\n",
      "Epoch 509/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 187.7747 - mae: 188.4676 - val_loss: 241.9386 - val_mae: 242.6310\n",
      "Epoch 510/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 180.0934 - mae: 180.7847 - val_loss: 240.4229 - val_mae: 241.1157\n",
      "Epoch 511/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.8676 - mae: 184.5587 - val_loss: 241.0473 - val_mae: 241.7401\n",
      "Epoch 512/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 166.2635 - mae: 166.9521 - val_loss: 240.3155 - val_mae: 241.0078\n",
      "Epoch 513/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.1988 - mae: 172.8894 - val_loss: 266.2130 - val_mae: 266.9058\n",
      "Epoch 514/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.6101 - mae: 178.3018 - val_loss: 258.2422 - val_mae: 258.9330\n",
      "Epoch 515/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.6576 - mae: 178.3461 - val_loss: 243.3630 - val_mae: 244.0552\n",
      "Epoch 516/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 173.6224 - mae: 174.3123 - val_loss: 268.4274 - val_mae: 269.1142\n",
      "Epoch 517/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 208.9816 - mae: 209.6745 - val_loss: 256.7932 - val_mae: 257.4862\n",
      "Epoch 518/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.9207 - mae: 178.6096 - val_loss: 242.9064 - val_mae: 243.5931\n",
      "Epoch 519/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 171.1529 - mae: 171.8441 - val_loss: 244.9225 - val_mae: 245.6136\n",
      "Epoch 520/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.9759 - mae: 168.6666 - val_loss: 244.9120 - val_mae: 245.6014\n",
      "Epoch 521/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.7004 - mae: 173.3914 - val_loss: 242.9262 - val_mae: 243.6169\n",
      "Epoch 522/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.7759 - mae: 181.4684 - val_loss: 245.9358 - val_mae: 246.6269\n",
      "Epoch 523/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.0888 - mae: 186.7784 - val_loss: 274.6832 - val_mae: 275.3756\n",
      "Epoch 524/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 178.1671 - mae: 178.8571 - val_loss: 241.3927 - val_mae: 242.0849\n",
      "Epoch 525/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 183.6883 - mae: 184.3739 - val_loss: 246.5634 - val_mae: 247.2564\n",
      "Epoch 526/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 180.1622 - mae: 180.8524 - val_loss: 239.8338 - val_mae: 240.5238\n",
      "Epoch 527/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 187.2497 - mae: 187.9417 - val_loss: 244.1028 - val_mae: 244.7890\n",
      "Epoch 528/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 173.0476 - mae: 173.7353 - val_loss: 243.0069 - val_mae: 243.6989\n",
      "Epoch 529/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 159.4416 - mae: 160.1317 - val_loss: 242.1395 - val_mae: 242.8240\n",
      "Epoch 530/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 182.2282 - mae: 182.9190 - val_loss: 292.1881 - val_mae: 292.8811\n",
      "Epoch 531/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 192.6195 - mae: 193.3090 - val_loss: 242.6052 - val_mae: 243.2981\n",
      "Epoch 532/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.6615 - mae: 169.3502 - val_loss: 253.6501 - val_mae: 254.3429\n",
      "Epoch 533/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.1954 - mae: 178.8868 - val_loss: 241.2722 - val_mae: 241.9652\n",
      "Epoch 534/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.5222 - mae: 177.2136 - val_loss: 241.2000 - val_mae: 241.8893\n",
      "Epoch 535/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.4426 - mae: 183.1352 - val_loss: 242.7004 - val_mae: 243.3916\n",
      "Epoch 536/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 174.0762 - mae: 174.7683 - val_loss: 251.1312 - val_mae: 251.8244\n",
      "Epoch 537/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.6030 - mae: 169.2948 - val_loss: 240.7195 - val_mae: 241.4082\n",
      "Epoch 538/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 161.4052 - mae: 162.0950 - val_loss: 240.2922 - val_mae: 240.9844\n",
      "Epoch 539/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 183.5223 - mae: 184.2137 - val_loss: 240.4318 - val_mae: 241.1230\n",
      "Epoch 540/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 175.9983 - mae: 176.6907 - val_loss: 247.1983 - val_mae: 247.8915\n",
      "Epoch 541/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 177.7220 - mae: 178.4108 - val_loss: 242.1767 - val_mae: 242.8676\n",
      "Epoch 542/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 191.1961 - mae: 191.8888 - val_loss: 240.2230 - val_mae: 240.9136\n",
      "Epoch 543/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.5300 - mae: 165.2219 - val_loss: 240.7032 - val_mae: 241.3925\n",
      "Epoch 544/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.0312 - mae: 172.7197 - val_loss: 240.3723 - val_mae: 241.0638\n",
      "Epoch 545/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 171.5140 - mae: 172.2039 - val_loss: 250.7873 - val_mae: 251.4801\n",
      "Epoch 546/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 163.6510 - mae: 164.3433 - val_loss: 242.9832 - val_mae: 243.6695\n",
      "Epoch 547/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 164.7459 - mae: 165.4379 - val_loss: 247.3896 - val_mae: 248.0820\n",
      "Epoch 548/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.4048 - mae: 187.0969 - val_loss: 254.6752 - val_mae: 255.3676\n",
      "Epoch 549/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.3460 - mae: 188.0360 - val_loss: 240.7645 - val_mae: 241.4537\n",
      "Epoch 550/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 33ms/step - loss: 168.0121 - mae: 168.7019 - val_loss: 238.9510 - val_mae: 239.6384\n",
      "Epoch 551/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 163.9739 - mae: 164.6657 - val_loss: 247.6641 - val_mae: 248.3563\n",
      "Epoch 552/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 162.6782 - mae: 163.3666 - val_loss: 250.0410 - val_mae: 250.7331\n",
      "Epoch 553/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.8664 - mae: 173.5577 - val_loss: 242.4296 - val_mae: 243.1213\n",
      "Epoch 554/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 169.5005 - mae: 170.1904 - val_loss: 243.8371 - val_mae: 244.5277\n",
      "Epoch 555/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 170.4651 - mae: 171.1544 - val_loss: 242.6183 - val_mae: 243.3040\n",
      "Epoch 556/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.8513 - mae: 178.5425 - val_loss: 239.9101 - val_mae: 240.5994\n",
      "Epoch 557/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 169.9709 - mae: 170.6603 - val_loss: 255.2302 - val_mae: 255.9231\n",
      "Epoch 558/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 186.4834 - mae: 187.1742 - val_loss: 247.8096 - val_mae: 248.5000\n",
      "Epoch 559/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 164.0554 - mae: 164.7477 - val_loss: 240.6633 - val_mae: 241.3526\n",
      "Epoch 560/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 175.3619 - mae: 176.0522 - val_loss: 256.3667 - val_mae: 257.0569\n",
      "Epoch 561/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 163.3615 - mae: 164.0507 - val_loss: 244.2237 - val_mae: 244.9161\n",
      "Epoch 562/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 167.3289 - mae: 168.0180 - val_loss: 239.7869 - val_mae: 240.4770\n",
      "Epoch 563/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 32ms/step - loss: 170.5409 - mae: 171.2285 - val_loss: 238.2867 - val_mae: 238.9787\n",
      "Epoch 564/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 166.6842 - mae: 167.3759 - val_loss: 244.7875 - val_mae: 245.4806\n",
      "Epoch 565/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 181.2298 - mae: 181.9183 - val_loss: 245.0740 - val_mae: 245.7625\n",
      "Epoch 566/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.2175 - mae: 174.9098 - val_loss: 241.5029 - val_mae: 242.1940\n",
      "Epoch 567/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 191.2119 - mae: 191.9009 - val_loss: 252.0822 - val_mae: 252.7675\n",
      "Epoch 568/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.5516 - mae: 188.2432 - val_loss: 245.0883 - val_mae: 245.7770\n",
      "Epoch 569/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 178.9131 - mae: 179.6051 - val_loss: 242.9864 - val_mae: 243.6737\n",
      "Epoch 570/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 173.7948 - mae: 174.4863 - val_loss: 242.2181 - val_mae: 242.9108\n",
      "Epoch 571/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.8831 - mae: 186.5755 - val_loss: 242.7853 - val_mae: 243.4760\n",
      "Epoch 572/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 169.3998 - mae: 170.0920 - val_loss: 242.3136 - val_mae: 243.0037\n",
      "Epoch 573/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.9608 - mae: 175.6522 - val_loss: 240.3732 - val_mae: 241.0662\n",
      "Epoch 574/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 165.2585 - mae: 165.9503 - val_loss: 262.3872 - val_mae: 263.0798\n",
      "Epoch 575/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 200.3829 - mae: 201.0746 - val_loss: 241.5405 - val_mae: 242.2278\n",
      "Epoch 576/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 166.0681 - mae: 166.7602 - val_loss: 245.6461 - val_mae: 246.3376\n",
      "Epoch 577/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.5791 - mae: 168.2718 - val_loss: 247.4454 - val_mae: 248.1369\n",
      "Epoch 578/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 175.9698 - mae: 176.6623 - val_loss: 239.4854 - val_mae: 240.1733\n",
      "Epoch 579/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 182.5175 - mae: 183.2089 - val_loss: 239.1882 - val_mae: 239.8806\n",
      "Epoch 580/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 174.1923 - mae: 174.8832 - val_loss: 242.8348 - val_mae: 243.5238\n",
      "Epoch 581/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 176.5374 - mae: 177.2269 - val_loss: 240.3085 - val_mae: 241.0007\n",
      "Epoch 582/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 183.5128 - mae: 184.2021 - val_loss: 240.0144 - val_mae: 240.7063\n",
      "Epoch 583/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 176.7209 - mae: 177.4136 - val_loss: 245.1915 - val_mae: 245.8823\n",
      "Epoch 584/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 186.7884 - mae: 187.4808 - val_loss: 250.1573 - val_mae: 250.8482\n",
      "Epoch 585/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 170.5113 - mae: 171.1976 - val_loss: 255.3084 - val_mae: 256.0013\n",
      "Epoch 586/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 179.5825 - mae: 180.2732 - val_loss: 258.2176 - val_mae: 258.9089\n",
      "Epoch 587/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 188.5892 - mae: 189.2798 - val_loss: 240.6797 - val_mae: 241.3685\n",
      "Epoch 588/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 161.6270 - mae: 162.3197 - val_loss: 262.3932 - val_mae: 263.0838\n",
      "Epoch 589/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 192.5240 - mae: 193.2137 - val_loss: 249.0134 - val_mae: 249.7058\n",
      "Epoch 590/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 175.4425 - mae: 176.1351 - val_loss: 240.3871 - val_mae: 241.0747\n",
      "Epoch 591/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.4127 - mae: 168.1042 - val_loss: 248.2514 - val_mae: 248.9446\n",
      "Epoch 592/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 171.6561 - mae: 172.3490 - val_loss: 238.3742 - val_mae: 239.0652\n",
      "Epoch 593/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 162.3699 - mae: 163.0611 - val_loss: 267.3149 - val_mae: 268.0054\n",
      "Epoch 594/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 174.3203 - mae: 175.0116 - val_loss: 258.7306 - val_mae: 259.4238\n",
      "Epoch 595/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 178.6682 - mae: 179.3605 - val_loss: 245.6835 - val_mae: 246.3748\n",
      "Epoch 596/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 159.4729 - mae: 160.1637 - val_loss: 239.7226 - val_mae: 240.4147\n",
      "Epoch 597/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 159.9592 - mae: 160.6511 - val_loss: 241.3702 - val_mae: 242.0587\n",
      "Epoch 598/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 177.6586 - mae: 178.3493 - val_loss: 240.5266 - val_mae: 241.2125\n",
      "Epoch 599/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 169.1036 - mae: 169.7908 - val_loss: 240.3424 - val_mae: 241.0310\n",
      "Epoch 600/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 173.4249 - mae: 174.1171 - val_loss: 262.9866 - val_mae: 263.6739\n",
      "Epoch 601/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 184.4145 - mae: 185.1042 - val_loss: 241.8946 - val_mae: 242.5830\n",
      "Epoch 602/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 165.2137 - mae: 165.9057 - val_loss: 251.3892 - val_mae: 252.0821\n",
      "Epoch 603/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 178.5495 - mae: 179.2398 - val_loss: 238.3453 - val_mae: 239.0362\n",
      "Epoch 604/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 171.5197 - mae: 172.2111 - val_loss: 244.7798 - val_mae: 245.4717\n",
      "Epoch 605/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 170.5612 - mae: 171.2533 - val_loss: 247.5789 - val_mae: 248.2713\n",
      "Epoch 606/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 178.6382 - mae: 179.3298 - val_loss: 245.0899 - val_mae: 245.7824\n",
      "Epoch 607/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 173.4740 - mae: 174.1631 - val_loss: 282.4737 - val_mae: 283.1650\n",
      "Epoch 608/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 175.7460 - mae: 176.4387 - val_loss: 240.3020 - val_mae: 240.9899\n",
      "Epoch 609/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 175.7217 - mae: 176.4121 - val_loss: 254.0563 - val_mae: 254.7492\n",
      "Epoch 610/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 176.5118 - mae: 177.2035 - val_loss: 240.8121 - val_mae: 241.5033\n",
      "Epoch 611/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 179.5091 - mae: 180.2005 - val_loss: 240.7546 - val_mae: 241.4441\n",
      "Epoch 612/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 178.9304 - mae: 179.6213 - val_loss: 241.2681 - val_mae: 241.9612\n",
      "Epoch 613/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 173.6675 - mae: 174.3578 - val_loss: 254.8528 - val_mae: 255.5453\n",
      "Epoch 614/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 166.2380 - mae: 166.9291 - val_loss: 242.2364 - val_mae: 242.9286\n",
      "Epoch 615/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 184.1582 - mae: 184.8493 - val_loss: 247.8293 - val_mae: 248.5199\n",
      "Epoch 616/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 174.4712 - mae: 175.1625 - val_loss: 255.8074 - val_mae: 256.5004\n",
      "Epoch 617/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 181.6052 - mae: 182.2935 - val_loss: 238.9442 - val_mae: 239.6373\n",
      "Epoch 618/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 180.1288 - mae: 180.8189 - val_loss: 248.4185 - val_mae: 249.1116\n",
      "Epoch 619/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 183.8985 - mae: 184.5903 - val_loss: 240.7125 - val_mae: 241.4031\n",
      "Epoch 620/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 174.9354 - mae: 175.6255 - val_loss: 260.5006 - val_mae: 261.1898\n",
      "Epoch 621/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 184.3573 - mae: 185.0491 - val_loss: 240.9202 - val_mae: 241.6037\n",
      "Epoch 622/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 164.4402 - mae: 165.1312 - val_loss: 242.0228 - val_mae: 242.7141\n",
      "Epoch 623/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 166.0193 - mae: 166.7089 - val_loss: 240.0406 - val_mae: 240.7307\n",
      "Epoch 624/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 171.0802 - mae: 171.7727 - val_loss: 244.8565 - val_mae: 245.5464\n",
      "Epoch 625/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 176.4458 - mae: 177.1382 - val_loss: 239.0982 - val_mae: 239.7888\n",
      "Epoch 626/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.7861 - mae: 176.4756 - val_loss: 240.3798 - val_mae: 241.0693\n",
      "Epoch 627/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 171.2372 - mae: 171.9265 - val_loss: 240.7582 - val_mae: 241.4483\n",
      "Epoch 628/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 166.8116 - mae: 167.5027 - val_loss: 249.1805 - val_mae: 249.8708\n",
      "Epoch 629/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 176.7047 - mae: 177.3917 - val_loss: 240.6595 - val_mae: 241.3512\n",
      "Epoch 630/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.5594 - mae: 171.2501 - val_loss: 247.6784 - val_mae: 248.3662\n",
      "Epoch 631/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.8967 - mae: 168.5863 - val_loss: 239.8266 - val_mae: 240.5119\n",
      "Epoch 632/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.1539 - mae: 164.8461 - val_loss: 239.4869 - val_mae: 240.1788\n",
      "Epoch 633/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.6694 - mae: 172.3606 - val_loss: 244.8286 - val_mae: 245.5170\n",
      "Epoch 634/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 167.3402 - mae: 168.0322 - val_loss: 245.1850 - val_mae: 245.8782\n",
      "Epoch 635/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.1507 - mae: 179.8419 - val_loss: 241.4053 - val_mae: 242.0934\n",
      "Epoch 636/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.2942 - mae: 185.9859 - val_loss: 242.0979 - val_mae: 242.7909\n",
      "Epoch 637/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.0991 - mae: 173.7894 - val_loss: 242.5354 - val_mae: 243.2245\n",
      "Epoch 638/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 168.8184 - mae: 169.5064 - val_loss: 237.8989 - val_mae: 238.5876\n",
      "Epoch 639/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.4440 - mae: 165.1343 - val_loss: 239.3011 - val_mae: 239.9930\n",
      "Epoch 640/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 185.7684 - mae: 186.4575 - val_loss: 239.6817 - val_mae: 240.3684\n",
      "Epoch 641/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 163.8315 - mae: 164.5206 - val_loss: 239.0493 - val_mae: 239.7406\n",
      "Epoch 642/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 192.9926 - mae: 193.6833 - val_loss: 259.7201 - val_mae: 260.4131\n",
      "Epoch 643/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 182.2528 - mae: 182.9437 - val_loss: 251.3152 - val_mae: 252.0081\n",
      "Epoch 644/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.2009 - mae: 173.8903 - val_loss: 241.3164 - val_mae: 242.0016\n",
      "Epoch 645/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.1219 - mae: 181.8143 - val_loss: 245.2858 - val_mae: 245.9769\n",
      "Epoch 646/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.5230 - mae: 177.2133 - val_loss: 239.3594 - val_mae: 240.0487\n",
      "Epoch 647/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.9642 - mae: 175.6547 - val_loss: 241.6951 - val_mae: 242.3851\n",
      "Epoch 648/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 165.1904 - mae: 165.8818 - val_loss: 242.9202 - val_mae: 243.6086\n",
      "Epoch 649/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 174.4607 - mae: 175.1526 - val_loss: 240.5908 - val_mae: 241.2778\n",
      "Epoch 650/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 189.6981 - mae: 190.3901 - val_loss: 239.4967 - val_mae: 240.1865\n",
      "Epoch 651/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.4832 - mae: 183.1754 - val_loss: 244.3942 - val_mae: 245.0859\n",
      "Epoch 652/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.6194 - mae: 173.3092 - val_loss: 251.1835 - val_mae: 251.8714\n",
      "Epoch 653/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.2299 - mae: 177.9179 - val_loss: 246.7022 - val_mae: 247.3926\n",
      "Epoch 654/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.6571 - mae: 178.3465 - val_loss: 263.6273 - val_mae: 264.3203\n",
      "Epoch 655/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.1304 - mae: 173.8217 - val_loss: 243.5940 - val_mae: 244.2869\n",
      "Epoch 656/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 175.1069 - mae: 175.7990 - val_loss: 245.7715 - val_mae: 246.4559\n",
      "Epoch 657/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 153.3221 - mae: 154.0119 - val_loss: 239.7743 - val_mae: 240.4669\n",
      "Epoch 658/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 165.7788 - mae: 166.4668 - val_loss: 239.0078 - val_mae: 239.7008\n",
      "Epoch 659/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 174.0625 - mae: 174.7548 - val_loss: 244.7526 - val_mae: 245.4457\n",
      "Epoch 660/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 180.1193 - mae: 180.8086 - val_loss: 239.3336 - val_mae: 240.0212\n",
      "Epoch 661/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 178.5343 - mae: 179.2262 - val_loss: 239.1213 - val_mae: 239.8139\n",
      "Epoch 662/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 169.9661 - mae: 170.6569 - val_loss: 240.7537 - val_mae: 241.4442\n",
      "Epoch 663/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.7304 - mae: 179.4180 - val_loss: 244.0576 - val_mae: 244.7483\n",
      "Epoch 664/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.0928 - mae: 168.7801 - val_loss: 238.1867 - val_mae: 238.8766\n",
      "Epoch 665/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 166.3920 - mae: 167.0830 - val_loss: 239.2605 - val_mae: 239.9500\n",
      "Epoch 666/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.5636 - mae: 185.2529 - val_loss: 240.0764 - val_mae: 240.7639\n",
      "Epoch 667/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.0367 - mae: 164.7292 - val_loss: 248.3491 - val_mae: 249.0354\n",
      "Epoch 668/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.1457 - mae: 174.8361 - val_loss: 242.7185 - val_mae: 243.4100\n",
      "Epoch 669/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 166.6172 - mae: 167.3091 - val_loss: 247.3736 - val_mae: 248.0632\n",
      "Epoch 670/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.8266 - mae: 174.5189 - val_loss: 280.2468 - val_mae: 280.9394\n",
      "Epoch 671/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 167.9544 - mae: 168.6461 - val_loss: 244.5683 - val_mae: 245.2603\n",
      "Epoch 672/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 169.3518 - mae: 170.0432 - val_loss: 249.6623 - val_mae: 250.3531\n",
      "Epoch 673/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 172.9718 - mae: 173.6636 - val_loss: 238.6349 - val_mae: 239.3242\n",
      "Epoch 674/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.3911 - mae: 165.0833 - val_loss: 251.0198 - val_mae: 251.7129\n",
      "Epoch 675/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 166.6983 - mae: 167.3898 - val_loss: 273.2697 - val_mae: 273.9620\n",
      "Epoch 676/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 187.0561 - mae: 187.7482 - val_loss: 246.4985 - val_mae: 247.1900\n",
      "Epoch 677/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.8389 - mae: 177.5307 - val_loss: 239.7309 - val_mae: 240.4238\n",
      "Epoch 678/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 181.4490 - mae: 182.1407 - val_loss: 240.1918 - val_mae: 240.8802\n",
      "Epoch 679/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 176.0402 - mae: 176.7288 - val_loss: 264.9995 - val_mae: 265.6924\n",
      "Epoch 680/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 182.1327 - mae: 182.8239 - val_loss: 249.9459 - val_mae: 250.6391\n",
      "Epoch 681/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 169.1879 - mae: 169.8788 - val_loss: 240.2004 - val_mae: 240.8898\n",
      "Epoch 682/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.3680 - mae: 179.0580 - val_loss: 238.5254 - val_mae: 239.2126\n",
      "Epoch 683/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.5279 - mae: 171.2191 - val_loss: 240.0096 - val_mae: 240.6999\n",
      "Epoch 684/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 166.8271 - mae: 167.5167 - val_loss: 240.3350 - val_mae: 241.0281\n",
      "Epoch 685/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 181.7033 - mae: 182.3947 - val_loss: 239.4146 - val_mae: 240.1060\n",
      "Epoch 686/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 195.1183 - mae: 195.8069 - val_loss: 241.7786 - val_mae: 242.4715\n",
      "Epoch 687/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 174.2135 - mae: 174.9050 - val_loss: 240.7397 - val_mae: 241.4320\n",
      "Epoch 688/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 195.9179 - mae: 196.6103 - val_loss: 241.9021 - val_mae: 242.5946\n",
      "Epoch 689/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 160.0808 - mae: 160.7711 - val_loss: 240.0780 - val_mae: 240.7660\n",
      "Epoch 690/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 180.5919 - mae: 181.2822 - val_loss: 239.5649 - val_mae: 240.2572\n",
      "Epoch 691/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.0319 - mae: 164.7242 - val_loss: 240.9397 - val_mae: 241.6315\n",
      "Epoch 692/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 161.5284 - mae: 162.2186 - val_loss: 242.9675 - val_mae: 243.6590\n",
      "Epoch 693/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 155.2241 - mae: 155.9156 - val_loss: 238.5348 - val_mae: 239.2259\n",
      "Epoch 694/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 164.1758 - mae: 164.8636 - val_loss: 241.3070 - val_mae: 241.9927\n",
      "Epoch 695/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.8623 - mae: 180.5521 - val_loss: 238.4438 - val_mae: 239.1323\n",
      "Epoch 696/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.5730 - mae: 175.2634 - val_loss: 263.6047 - val_mae: 264.2978\n",
      "Epoch 697/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 179.2351 - mae: 179.9271 - val_loss: 248.9369 - val_mae: 249.6298\n",
      "Epoch 698/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 176.0717 - mae: 176.7596 - val_loss: 244.4730 - val_mae: 245.1662\n",
      "Epoch 699/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 27ms/step - loss: 161.4682 - mae: 162.1611 - val_loss: 238.9323 - val_mae: 239.6240\n",
      "Epoch 700/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 158.7559 - mae: 159.4478 - val_loss: 247.2106 - val_mae: 247.9027\n",
      "Epoch 701/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.1070 - mae: 178.7988 - val_loss: 246.3232 - val_mae: 247.0149\n",
      "Epoch 702/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 170.4590 - mae: 171.1509 - val_loss: 236.8084 - val_mae: 237.5009\n",
      "Epoch 703/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 183.7457 - mae: 184.4349 - val_loss: 245.8775 - val_mae: 246.5676\n",
      "Epoch 704/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 181.0635 - mae: 181.7532 - val_loss: 239.5700 - val_mae: 240.2627\n",
      "Epoch 705/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 159.0862 - mae: 159.7786 - val_loss: 237.7731 - val_mae: 238.4592\n",
      "Epoch 706/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.6393 - mae: 179.3277 - val_loss: 238.4045 - val_mae: 239.0888\n",
      "Epoch 707/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.3099 - mae: 170.9991 - val_loss: 242.9502 - val_mae: 243.6432\n",
      "Epoch 708/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 169.3798 - mae: 170.0712 - val_loss: 236.7518 - val_mae: 237.4433\n",
      "Epoch 709/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 168.0259 - mae: 168.7186 - val_loss: 237.6057 - val_mae: 238.2947\n",
      "Epoch 710/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.4802 - mae: 174.1721 - val_loss: 239.1119 - val_mae: 239.8018\n",
      "Epoch 711/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 162.2175 - mae: 162.9083 - val_loss: 247.9577 - val_mae: 248.6483\n",
      "Epoch 712/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 164.8807 - mae: 165.5717 - val_loss: 241.8234 - val_mae: 242.5129\n",
      "Epoch 713/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 172.2081 - mae: 172.9000 - val_loss: 238.6634 - val_mae: 239.3529\n",
      "Epoch 714/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.7806 - mae: 179.4674 - val_loss: 240.1326 - val_mae: 240.8221\n",
      "Epoch 715/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 165.2253 - mae: 165.9179 - val_loss: 249.5731 - val_mae: 250.2650\n",
      "Epoch 716/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 177.0453 - mae: 177.7355 - val_loss: 242.8437 - val_mae: 243.5347\n",
      "Epoch 717/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.6990 - mae: 173.3874 - val_loss: 279.5859 - val_mae: 280.2791\n",
      "Epoch 718/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 189.8337 - mae: 190.5259 - val_loss: 247.3725 - val_mae: 248.0635\n",
      "Epoch 719/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.2306 - mae: 177.9208 - val_loss: 249.9616 - val_mae: 250.6511\n",
      "Epoch 720/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 176.2924 - mae: 176.9841 - val_loss: 252.1258 - val_mae: 252.8187\n",
      "Epoch 721/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 182.0150 - mae: 182.7047 - val_loss: 237.6031 - val_mae: 238.2919\n",
      "Epoch 722/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 174.1995 - mae: 174.8919 - val_loss: 251.9567 - val_mae: 252.6484\n",
      "Epoch 723/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 158.3444 - mae: 159.0345 - val_loss: 246.9514 - val_mae: 247.6435\n",
      "Epoch 724/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 173.2574 - mae: 173.9481 - val_loss: 251.8658 - val_mae: 252.5590\n",
      "Epoch 725/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 179.9963 - mae: 180.6880 - val_loss: 268.2963 - val_mae: 268.9863\n",
      "Epoch 726/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 165.8993 - mae: 166.5905 - val_loss: 251.4977 - val_mae: 252.1893\n",
      "Epoch 727/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 173.8315 - mae: 174.5230 - val_loss: 250.7846 - val_mae: 251.4749\n",
      "Epoch 728/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 158.7731 - mae: 159.4633 - val_loss: 238.0132 - val_mae: 238.6993\n",
      "Epoch 729/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.3171 - mae: 172.0084 - val_loss: 283.9421 - val_mae: 284.6349\n",
      "Epoch 730/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 180.8501 - mae: 181.5410 - val_loss: 238.0220 - val_mae: 238.7136\n",
      "Epoch 731/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 168.3421 - mae: 169.0303 - val_loss: 245.4433 - val_mae: 246.1355\n",
      "Epoch 732/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 164.9262 - mae: 165.6144 - val_loss: 250.5233 - val_mae: 251.2148\n",
      "Epoch 733/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 158.1239 - mae: 158.8167 - val_loss: 252.3101 - val_mae: 253.0032\n",
      "Epoch 734/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 168.3312 - mae: 169.0222 - val_loss: 242.5220 - val_mae: 243.2133\n",
      "Epoch 735/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 182.7458 - mae: 183.4361 - val_loss: 251.6543 - val_mae: 252.3471\n",
      "Epoch 736/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 24ms/step - loss: 186.8413 - mae: 187.5331 - val_loss: 238.1204 - val_mae: 238.8070\n",
      "Epoch 737/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 178.6861 - mae: 179.3779 - val_loss: 241.8525 - val_mae: 242.5441\n",
      "Epoch 738/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 172.6036 - mae: 173.2944 - val_loss: 248.5355 - val_mae: 249.2287\n",
      "Epoch 739/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 180.8416 - mae: 181.5319 - val_loss: 245.3157 - val_mae: 246.0077\n",
      "Epoch 740/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.1640 - mae: 184.8568 - val_loss: 239.4047 - val_mae: 240.0936\n",
      "Epoch 741/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.1391 - mae: 174.8299 - val_loss: 241.9884 - val_mae: 242.6791\n",
      "Epoch 742/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 168.1026 - mae: 168.7930 - val_loss: 242.8970 - val_mae: 243.5894\n",
      "Epoch 743/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 169.0094 - mae: 169.7006 - val_loss: 243.7664 - val_mae: 244.4588\n",
      "Epoch 744/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 165.3061 - mae: 165.9953 - val_loss: 254.9528 - val_mae: 255.6456\n",
      "Epoch 745/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 165.2547 - mae: 165.9461 - val_loss: 244.1990 - val_mae: 244.8920\n",
      "Epoch 746/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 173.2397 - mae: 173.9291 - val_loss: 261.7936 - val_mae: 262.4836\n",
      "Epoch 747/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 193.0606 - mae: 193.7496 - val_loss: 258.9910 - val_mae: 259.6841\n",
      "Epoch 748/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 180.6979 - mae: 181.3886 - val_loss: 247.3419 - val_mae: 248.0293\n",
      "Epoch 749/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 166.8445 - mae: 167.5365 - val_loss: 238.4460 - val_mae: 239.1389\n",
      "Epoch 750/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 169.2520 - mae: 169.9373 - val_loss: 257.4291 - val_mae: 258.1222\n",
      "Epoch 751/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 183.0831 - mae: 183.7741 - val_loss: 239.3183 - val_mae: 240.0035\n",
      "Epoch 752/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 165.8308 - mae: 166.5223 - val_loss: 258.0927 - val_mae: 258.7856\n",
      "Epoch 753/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 162.4580 - mae: 163.1499 - val_loss: 242.6892 - val_mae: 243.3802\n",
      "Epoch 754/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 181.2231 - mae: 181.9140 - val_loss: 238.3021 - val_mae: 238.9927\n",
      "Epoch 755/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 162.4677 - mae: 163.1598 - val_loss: 239.0178 - val_mae: 239.7086\n",
      "Epoch 756/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 169.5327 - mae: 170.2222 - val_loss: 240.5144 - val_mae: 241.2066\n",
      "Epoch 757/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 174.4143 - mae: 175.1058 - val_loss: 238.9359 - val_mae: 239.6231\n",
      "Epoch 758/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 169.9233 - mae: 170.6151 - val_loss: 244.5358 - val_mae: 245.2251\n",
      "Epoch 759/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.0690 - mae: 167.7559 - val_loss: 239.9222 - val_mae: 240.6150\n",
      "Epoch 760/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 163.7146 - mae: 164.4060 - val_loss: 240.4697 - val_mae: 241.1590\n",
      "Epoch 761/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 171.5870 - mae: 172.2786 - val_loss: 238.7535 - val_mae: 239.4429\n",
      "Epoch 762/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 23ms/step - loss: 187.1947 - mae: 187.8864 - val_loss: 255.6312 - val_mae: 256.3233\n",
      "Epoch 763/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 165.6200 - mae: 166.3123 - val_loss: 238.6242 - val_mae: 239.3145\n",
      "Epoch 764/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 167.5893 - mae: 168.2780 - val_loss: 239.7447 - val_mae: 240.4351\n",
      "Epoch 765/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 170.3680 - mae: 171.0572 - val_loss: 238.5020 - val_mae: 239.1948\n",
      "Epoch 766/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 169.0405 - mae: 169.7286 - val_loss: 262.3287 - val_mae: 263.0217\n",
      "Epoch 767/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.9796 - mae: 171.6717 - val_loss: 240.1705 - val_mae: 240.8565\n",
      "Epoch 768/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 159.2584 - mae: 159.9443 - val_loss: 252.8105 - val_mae: 253.5016\n",
      "Epoch 769/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.0284 - mae: 172.7204 - val_loss: 238.7448 - val_mae: 239.4348\n",
      "Epoch 770/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 167.7256 - mae: 168.4180 - val_loss: 243.8650 - val_mae: 244.5572\n",
      "Epoch 771/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 169.2238 - mae: 169.9124 - val_loss: 242.0889 - val_mae: 242.7775\n",
      "Epoch 772/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 178.1830 - mae: 178.8750 - val_loss: 241.1665 - val_mae: 241.8589\n",
      "Epoch 773/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 25ms/step - loss: 166.6613 - mae: 167.3508 - val_loss: 248.2759 - val_mae: 248.9624\n",
      "Epoch 774/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.6895 - mae: 171.3794 - val_loss: 243.1817 - val_mae: 243.8739\n",
      "Epoch 775/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 184.6775 - mae: 185.3696 - val_loss: 241.0211 - val_mae: 241.7139\n",
      "Epoch 776/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 177.9198 - mae: 178.6102 - val_loss: 245.0064 - val_mae: 245.6963\n",
      "Epoch 777/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 166.2286 - mae: 166.9194 - val_loss: 250.8222 - val_mae: 251.5148\n",
      "Epoch 778/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 191.0108 - mae: 191.7036 - val_loss: 241.1704 - val_mae: 241.8600\n",
      "Epoch 779/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 164.8415 - mae: 165.5300 - val_loss: 250.3722 - val_mae: 251.0642\n",
      "Epoch 780/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 169.8116 - mae: 170.5038 - val_loss: 243.9890 - val_mae: 244.6819\n",
      "Epoch 781/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 179.2558 - mae: 179.9476 - val_loss: 241.5036 - val_mae: 242.1934\n",
      "Epoch 782/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 185.4577 - mae: 186.1467 - val_loss: 239.0487 - val_mae: 239.7410\n",
      "Epoch 783/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 188.9919 - mae: 189.6840 - val_loss: 240.7211 - val_mae: 241.4143\n",
      "Epoch 784/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 175.3596 - mae: 176.0488 - val_loss: 246.3499 - val_mae: 247.0409\n",
      "Epoch 785/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 174.6144 - mae: 175.3021 - val_loss: 254.3215 - val_mae: 255.0134\n",
      "Epoch 786/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 173.5054 - mae: 174.1978 - val_loss: 242.8371 - val_mae: 243.5242\n",
      "Epoch 787/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 177.7396 - mae: 178.4316 - val_loss: 238.5378 - val_mae: 239.2287\n",
      "Epoch 788/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 165.3432 - mae: 166.0338 - val_loss: 243.6889 - val_mae: 244.3797\n",
      "Epoch 789/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 168.2730 - mae: 168.9657 - val_loss: 247.1671 - val_mae: 247.8600\n",
      "Epoch 790/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 151.6518 - mae: 152.3422 - val_loss: 238.1680 - val_mae: 238.8603\n",
      "Epoch 791/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 172.1987 - mae: 172.8889 - val_loss: 239.9758 - val_mae: 240.6666\n",
      "Epoch 792/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 168.1167 - mae: 168.8085 - val_loss: 238.2673 - val_mae: 238.9596\n",
      "Epoch 793/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 174.2862 - mae: 174.9759 - val_loss: 238.6223 - val_mae: 239.3094\n",
      "Epoch 794/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 22ms/step - loss: 167.2360 - mae: 167.9282 - val_loss: 302.2163 - val_mae: 302.9040\n",
      "Epoch 795/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 195.3863 - mae: 196.0786 - val_loss: 239.0771 - val_mae: 239.7700\n",
      "Epoch 796/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 168.6019 - mae: 169.2924 - val_loss: 244.3105 - val_mae: 245.0036\n",
      "Epoch 797/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 170.6033 - mae: 171.2930 - val_loss: 243.5384 - val_mae: 244.2316\n",
      "Epoch 798/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 183.6318 - mae: 184.3234 - val_loss: 242.1722 - val_mae: 242.8625\n",
      "Epoch 799/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 177.1563 - mae: 177.8467 - val_loss: 243.4214 - val_mae: 244.1121\n",
      "Epoch 800/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 163.6384 - mae: 164.3254 - val_loss: 248.5261 - val_mae: 249.2193\n",
      "Epoch 801/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 158.5699 - mae: 159.2599 - val_loss: 238.9301 - val_mae: 239.6201\n",
      "Epoch 802/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 171.0144 - mae: 171.7046 - val_loss: 237.9636 - val_mae: 238.6564\n",
      "Epoch 803/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 170.8058 - mae: 171.4954 - val_loss: 238.8281 - val_mae: 239.5173\n",
      "Epoch 804/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 178.8325 - mae: 179.5227 - val_loss: 249.9200 - val_mae: 250.6131\n",
      "Epoch 805/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 162.0710 - mae: 162.7618 - val_loss: 257.3153 - val_mae: 258.0061\n",
      "Epoch 806/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 182.3374 - mae: 183.0296 - val_loss: 238.7166 - val_mae: 239.4085\n",
      "Epoch 807/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 172.4746 - mae: 173.1656 - val_loss: 239.6466 - val_mae: 240.3381\n",
      "Epoch 808/5000\n",
      "\u001B[1m22/22\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 20ms/step - loss: 173.4364 - mae: 174.1283 - val_loss: 237.8287 - val_mae: 238.5215\n",
      "Epoch 808: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2279f1f7ca0>"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 246
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LRZ1nHe0Gjy5"
   },
   "source": [
    "# **Testing Model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyAUCY0FGwsM",
    "ExecuteTime": {
     "end_time": "2024-04-15T15:48:58.670576Z",
     "start_time": "2024-04-15T15:48:58.302408Z"
    }
   },
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "prediction_model = load_model('model/LSTM_reg_seven_new.keras',compile=False)"
   ],
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A total of 2 objects could not be loaded. Example error message for object <LSTMCell name=lstm_cell, built=True>:\n\nLayer 'lstm_cell' expected 3 variables, but received 0 variables during loading. Expected: ['kernel', 'recurrent_kernel', 'bias']\n\nList of objects that could not be loaded:\n[<LSTMCell name=lstm_cell, built=True>, <LSTMCell name=lstm_cell, built=True>]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[200], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_model\n\u001B[1;32m----> 2\u001B[0m prediction_model \u001B[38;5;241m=\u001B[39m \u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel/LSTM_reg_seven_new.keras\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\DS440proj\\BTCpred\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:176\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[0;32m    173\u001B[0m         is_keras_zip \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_keras_zip:\n\u001B[1;32m--> 176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msaving_lib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilepath\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    178\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    179\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    180\u001B[0m \u001B[43m        \u001B[49m\u001B[43msafe_mode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msafe_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    181\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(filepath)\u001B[38;5;241m.\u001B[39mendswith((\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.h5\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.hdf5\u001B[39m\u001B[38;5;124m\"\u001B[39m)):\n\u001B[0;32m    183\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m legacy_h5_format\u001B[38;5;241m.\u001B[39mload_model_from_hdf5(filepath)\n",
      "File \u001B[1;32mE:\\DS440proj\\BTCpred\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:152\u001B[0m, in \u001B[0;36mload_model\u001B[1;34m(filepath, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[0;32m    147\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    148\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid filename: expected a `.keras` extension. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    149\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived: filepath=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfilepath\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    150\u001B[0m     )\n\u001B[0;32m    151\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(filepath, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m--> 152\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_load_model_from_fileobj\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    153\u001B[0m \u001B[43m        \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcustom_objects\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mcompile\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msafe_mode\u001B[49m\n\u001B[0;32m    154\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mE:\\DS440proj\\BTCpred\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:207\u001B[0m, in \u001B[0;36m_load_model_from_fileobj\u001B[1;34m(fileobj, custom_objects, compile, safe_mode)\u001B[0m\n\u001B[0;32m    204\u001B[0m         asset_store\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m    206\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m failed_trackables:\n\u001B[1;32m--> 207\u001B[0m         \u001B[43m_raise_loading_failure\u001B[49m\u001B[43m(\u001B[49m\u001B[43merror_msgs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    208\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model\n",
      "File \u001B[1;32mE:\\DS440proj\\BTCpred\\.venv\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:295\u001B[0m, in \u001B[0;36m_raise_loading_failure\u001B[1;34m(error_msgs, warn_only)\u001B[0m\n\u001B[0;32m    293\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(msg)\n\u001B[0;32m    294\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 295\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n",
      "\u001B[1;31mValueError\u001B[0m: A total of 2 objects could not be loaded. Example error message for object <LSTMCell name=lstm_cell, built=True>:\n\nLayer 'lstm_cell' expected 3 variables, but received 0 variables during loading. Expected: ['kernel', 'recurrent_kernel', 'bias']\n\nList of objects that could not be loaded:\n[<LSTMCell name=lstm_cell, built=True>, <LSTMCell name=lstm_cell, built=True>]"
     ]
    }
   ],
   "execution_count": 200
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "lT71_QwcHEof",
    "outputId": "674692de-7a3b-4e60-addc-39ce1d9a328d",
    "ExecuteTime": {
     "end_time": "2024-04-15T17:28:10.022389Z",
     "start_time": "2024-04-15T17:28:09.514495Z"
    }
   },
   "source": "y_pred = np.ravel(model.predict(X_test))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m6/6\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n"
     ]
    }
   ],
   "execution_count": 247
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:28:10.994871Z",
     "start_time": "2024-04-15T17:28:10.979867Z"
    }
   },
   "source": [
    "y_test=np.ravel(y_test)"
   ],
   "outputs": [],
   "execution_count": 248
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:28:12.012867Z",
     "start_time": "2024-04-15T17:28:11.993673Z"
    }
   },
   "source": [
    "r2=r2_score(y_test,y_pred) #testing score/ r^2\n",
    "r2"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7650239534493695"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 249
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:28:13.262258Z",
     "start_time": "2024-04-15T17:28:13.249338Z"
    }
   },
   "source": [
    "mae=mean_absolute_error(y_test,y_pred) #mae\n",
    "mae"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238.52154190238866"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 250
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:28:14.278748Z",
     "start_time": "2024-04-15T17:28:14.271242Z"
    }
   },
   "source": [
    "rmse=np.sqrt(mean_squared_error(y_test,y_pred)) #rmse\n",
    "rmse"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "906.149469033331"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 251
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:28:15.080263Z",
     "start_time": "2024-04-15T17:28:15.065765Z"
    }
   },
   "source": [
    "mape=mean_absolute_percentage_error(y_test,y_pred) #mape\n",
    "mape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6569.479838507135"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 252
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:28:16.146846Z",
     "start_time": "2024-04-15T17:28:16.135845Z"
    }
   },
   "source": [
    "pd.DataFrame(zip(['MAE','RMSE','MAPE','R^2'],[mae,rmse,mape,r2])).transpose()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            0           1            2         3\n",
       "0         MAE        RMSE         MAPE       R^2\n",
       "1  238.521542  906.149469  6569.479839  0.765024"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>MAPE</td>\n",
       "      <td>R^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238.521542</td>\n",
       "      <td>906.149469</td>\n",
       "      <td>6569.479839</td>\n",
       "      <td>0.765024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 253
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-15T17:28:21.556382Z",
     "start_time": "2024-04-15T17:28:21.546732Z"
    }
   },
   "source": [
    "pd.DataFrame([y_test,y_pred]).transpose()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           0             1\n",
       "0     8706.0   8748.635742\n",
       "1     9565.0   9546.569336\n",
       "2    10164.0  10100.013672\n",
       "3     7085.0   7082.275391\n",
       "4     6454.0   6416.238281\n",
       "..       ...           ...\n",
       "169   7983.0   8274.499023\n",
       "170   6167.0   6239.161133\n",
       "171  11372.0  11603.534180\n",
       "172   9233.0   9319.017578\n",
       "173      1.0  11428.336914\n",
       "\n",
       "[174 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8706.0</td>\n",
       "      <td>8748.635742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9565.0</td>\n",
       "      <td>9546.569336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10164.0</td>\n",
       "      <td>10100.013672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7085.0</td>\n",
       "      <td>7082.275391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6454.0</td>\n",
       "      <td>6416.238281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>7983.0</td>\n",
       "      <td>8274.499023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>6167.0</td>\n",
       "      <td>6239.161133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>11372.0</td>\n",
       "      <td>11603.534180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>9233.0</td>\n",
       "      <td>9319.017578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>1.0</td>\n",
       "      <td>11428.336914</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 254
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market Predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
