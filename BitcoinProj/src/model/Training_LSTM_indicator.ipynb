{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TKAxbUFku8lD"
   },
   "source": [
    "# **Dependancies**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFJOnSzBk_uB",
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:48.942929Z",
     "start_time": "2024-04-25T06:23:48.938427Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import *\n",
    "from keras.callbacks import *\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from commons import mean_absolute_percentage_error\n",
    "from keras.layers import *\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.losses import LogCosh"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22PseW2xqQET"
   },
   "source": [
    "# **Loading Data**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0HH_FAAlRXx",
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.112664Z",
     "start_time": "2024-04-25T06:23:49.105967Z"
    }
   },
   "source": [
    "PATH_TO_DATA = \"data/reg_interval20-23wma.csv\"\n",
    "data = pd.read_csv(PATH_TO_DATA)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.143101Z",
     "start_time": "2024-04-25T06:23:49.130017Z"
    }
   },
   "source": [
    "data.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   difficulty3rsi  mediantransactionvalue30trxUSD  mining_profitability90trx  \\\n",
       "0           100.0                          -0.214                     -0.320   \n",
       "1           100.0                          -0.184                     -0.321   \n",
       "2           100.0                          -0.157                     -0.321   \n",
       "3           100.0                          -0.128                     -0.321   \n",
       "4           100.0                          -0.108                     -0.321   \n",
       "\n",
       "   price30momUSD  price30varUSD  price3momUSD  price3varUSD  price90momUSD  \\\n",
       "0         1477.0       185824.0       484.627       46350.0        523.430   \n",
       "1         1694.0       231148.0       632.769       70029.0        721.647   \n",
       "2         1840.0       253780.0       542.568        5019.0        713.823   \n",
       "3         2070.0       278575.0       263.765        5124.0        889.842   \n",
       "4         1729.0       316028.0       128.570        8649.0        876.998   \n",
       "\n",
       "   price90varUSD  top100cap3trx  transactionvalueUSD  price3wmaUSD  \n",
       "0       586279.0         -0.016              30967.0        8616.0  \n",
       "1       593953.0         -0.019              42231.0        8707.0  \n",
       "2       600131.0         -0.044              23647.0        8795.0  \n",
       "3       609381.0         -0.054              30527.0        8859.0  \n",
       "4       619179.0         -0.041              15636.0        8877.0  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty3rsi</th>\n",
       "      <th>mediantransactionvalue30trxUSD</th>\n",
       "      <th>mining_profitability90trx</th>\n",
       "      <th>price30momUSD</th>\n",
       "      <th>price30varUSD</th>\n",
       "      <th>price3momUSD</th>\n",
       "      <th>price3varUSD</th>\n",
       "      <th>price90momUSD</th>\n",
       "      <th>price90varUSD</th>\n",
       "      <th>top100cap3trx</th>\n",
       "      <th>transactionvalueUSD</th>\n",
       "      <th>price3wmaUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>1477.0</td>\n",
       "      <td>185824.0</td>\n",
       "      <td>484.627</td>\n",
       "      <td>46350.0</td>\n",
       "      <td>523.430</td>\n",
       "      <td>586279.0</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>30967.0</td>\n",
       "      <td>8616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>1694.0</td>\n",
       "      <td>231148.0</td>\n",
       "      <td>632.769</td>\n",
       "      <td>70029.0</td>\n",
       "      <td>721.647</td>\n",
       "      <td>593953.0</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>42231.0</td>\n",
       "      <td>8707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>1840.0</td>\n",
       "      <td>253780.0</td>\n",
       "      <td>542.568</td>\n",
       "      <td>5019.0</td>\n",
       "      <td>713.823</td>\n",
       "      <td>600131.0</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>23647.0</td>\n",
       "      <td>8795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>278575.0</td>\n",
       "      <td>263.765</td>\n",
       "      <td>5124.0</td>\n",
       "      <td>889.842</td>\n",
       "      <td>609381.0</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>30527.0</td>\n",
       "      <td>8859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>1729.0</td>\n",
       "      <td>316028.0</td>\n",
       "      <td>128.570</td>\n",
       "      <td>8649.0</td>\n",
       "      <td>876.998</td>\n",
       "      <td>619179.0</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>15636.0</td>\n",
       "      <td>8877.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.158251Z",
     "start_time": "2024-04-25T06:23:49.152245Z"
    }
   },
   "source": [
    "data.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(639, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.173582Z",
     "start_time": "2024-04-25T06:23:49.168582Z"
    }
   },
   "cell_type": "code",
   "source": "y = data['price3wmaUSD']",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.204233Z",
     "start_time": "2024-04-25T06:23:49.190599Z"
    }
   },
   "cell_type": "code",
   "source": "X = data",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.219614Z",
     "start_time": "2024-04-25T06:23:49.214543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X['price3wmaUSD'] = X['price3wmaUSD'].shift(1,fill_value=4000)\n",
    "#X=X[X['priceUSD']!=1]"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.250230Z",
     "start_time": "2024-04-25T06:23:49.236993Z"
    }
   },
   "cell_type": "code",
   "source": "X",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     difficulty3rsi  mediantransactionvalue30trxUSD  \\\n",
       "0           100.000                          -0.214   \n",
       "1           100.000                          -0.184   \n",
       "2           100.000                          -0.157   \n",
       "3           100.000                          -0.128   \n",
       "4           100.000                          -0.108   \n",
       "..              ...                             ...   \n",
       "634          99.043                          -0.085   \n",
       "635          99.043                          -0.087   \n",
       "636          99.043                          -0.090   \n",
       "637          99.043                          -0.094   \n",
       "638          99.043                          -0.100   \n",
       "\n",
       "     mining_profitability90trx  price30momUSD  price30varUSD  price3momUSD  \\\n",
       "0                       -0.320       1477.000       185824.0       484.627   \n",
       "1                       -0.321       1694.000       231148.0       632.769   \n",
       "2                       -0.321       1840.000       253780.0       542.568   \n",
       "3                       -0.321       2070.000       278575.0       263.765   \n",
       "4                       -0.321       1729.000       316028.0       128.570   \n",
       "..                         ...            ...            ...           ...   \n",
       "634                     -0.406        425.550        82135.0      -179.890   \n",
       "635                     -0.405        177.977        76543.0      -258.919   \n",
       "636                     -0.404       -347.725        82274.0      -257.127   \n",
       "637                     -0.403       -489.020        86919.0       -69.693   \n",
       "638                     -0.402       -403.656        91811.0       -32.908   \n",
       "\n",
       "     price3varUSD  price90momUSD  price90varUSD  top100cap3trx  \\\n",
       "0       46350.000        523.430       586279.0         -0.016   \n",
       "1       70029.000        721.647       593953.0         -0.019   \n",
       "2        5019.000        713.823       600131.0         -0.044   \n",
       "3        5124.000        889.842       609381.0         -0.054   \n",
       "4        8649.000        876.998       619179.0         -0.041   \n",
       "..            ...            ...            ...            ...   \n",
       "634      8243.000      -2758.000      2474152.0          0.031   \n",
       "635      8530.000      -2936.000      2479394.0          0.047   \n",
       "636      1350.000      -2778.000      2489811.0          0.027   \n",
       "637       287.999      -2661.000      2500289.0          0.030   \n",
       "638        68.577      -2751.000      2507215.0          0.048   \n",
       "\n",
       "     transactionvalueUSD  price3wmaUSD  \n",
       "0                30967.0        4000.0  \n",
       "1                42231.0        8616.0  \n",
       "2                23647.0        8707.0  \n",
       "3                30527.0        8795.0  \n",
       "4                15636.0        8859.0  \n",
       "..                   ...           ...  \n",
       "634              53190.0       16731.0  \n",
       "635              54195.0       16643.0  \n",
       "636              50405.0       16579.0  \n",
       "637              42790.0       16567.0  \n",
       "638              49147.0       16561.0  \n",
       "\n",
       "[639 rows x 12 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>difficulty3rsi</th>\n",
       "      <th>mediantransactionvalue30trxUSD</th>\n",
       "      <th>mining_profitability90trx</th>\n",
       "      <th>price30momUSD</th>\n",
       "      <th>price30varUSD</th>\n",
       "      <th>price3momUSD</th>\n",
       "      <th>price3varUSD</th>\n",
       "      <th>price90momUSD</th>\n",
       "      <th>price90varUSD</th>\n",
       "      <th>top100cap3trx</th>\n",
       "      <th>transactionvalueUSD</th>\n",
       "      <th>price3wmaUSD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-0.214</td>\n",
       "      <td>-0.320</td>\n",
       "      <td>1477.000</td>\n",
       "      <td>185824.0</td>\n",
       "      <td>484.627</td>\n",
       "      <td>46350.000</td>\n",
       "      <td>523.430</td>\n",
       "      <td>586279.0</td>\n",
       "      <td>-0.016</td>\n",
       "      <td>30967.0</td>\n",
       "      <td>4000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-0.184</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>1694.000</td>\n",
       "      <td>231148.0</td>\n",
       "      <td>632.769</td>\n",
       "      <td>70029.000</td>\n",
       "      <td>721.647</td>\n",
       "      <td>593953.0</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>42231.0</td>\n",
       "      <td>8616.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-0.157</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>1840.000</td>\n",
       "      <td>253780.0</td>\n",
       "      <td>542.568</td>\n",
       "      <td>5019.000</td>\n",
       "      <td>713.823</td>\n",
       "      <td>600131.0</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>23647.0</td>\n",
       "      <td>8707.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>2070.000</td>\n",
       "      <td>278575.0</td>\n",
       "      <td>263.765</td>\n",
       "      <td>5124.000</td>\n",
       "      <td>889.842</td>\n",
       "      <td>609381.0</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>30527.0</td>\n",
       "      <td>8795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.000</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.321</td>\n",
       "      <td>1729.000</td>\n",
       "      <td>316028.0</td>\n",
       "      <td>128.570</td>\n",
       "      <td>8649.000</td>\n",
       "      <td>876.998</td>\n",
       "      <td>619179.0</td>\n",
       "      <td>-0.041</td>\n",
       "      <td>15636.0</td>\n",
       "      <td>8859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>99.043</td>\n",
       "      <td>-0.085</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>425.550</td>\n",
       "      <td>82135.0</td>\n",
       "      <td>-179.890</td>\n",
       "      <td>8243.000</td>\n",
       "      <td>-2758.000</td>\n",
       "      <td>2474152.0</td>\n",
       "      <td>0.031</td>\n",
       "      <td>53190.0</td>\n",
       "      <td>16731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>99.043</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>177.977</td>\n",
       "      <td>76543.0</td>\n",
       "      <td>-258.919</td>\n",
       "      <td>8530.000</td>\n",
       "      <td>-2936.000</td>\n",
       "      <td>2479394.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>54195.0</td>\n",
       "      <td>16643.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>99.043</td>\n",
       "      <td>-0.090</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>-347.725</td>\n",
       "      <td>82274.0</td>\n",
       "      <td>-257.127</td>\n",
       "      <td>1350.000</td>\n",
       "      <td>-2778.000</td>\n",
       "      <td>2489811.0</td>\n",
       "      <td>0.027</td>\n",
       "      <td>50405.0</td>\n",
       "      <td>16579.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>99.043</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.403</td>\n",
       "      <td>-489.020</td>\n",
       "      <td>86919.0</td>\n",
       "      <td>-69.693</td>\n",
       "      <td>287.999</td>\n",
       "      <td>-2661.000</td>\n",
       "      <td>2500289.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>42790.0</td>\n",
       "      <td>16567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>99.043</td>\n",
       "      <td>-0.100</td>\n",
       "      <td>-0.402</td>\n",
       "      <td>-403.656</td>\n",
       "      <td>91811.0</td>\n",
       "      <td>-32.908</td>\n",
       "      <td>68.577</td>\n",
       "      <td>-2751.000</td>\n",
       "      <td>2507215.0</td>\n",
       "      <td>0.048</td>\n",
       "      <td>49147.0</td>\n",
       "      <td>16561.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>639 rows × 12 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.342916Z",
     "start_time": "2024-04-25T06:23:49.340914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#X1 = data\n",
    "#X1['target'] = X1['priceUSD'].shift(-1)\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.389300Z",
     "start_time": "2024-04-25T06:23:49.379227Z"
    }
   },
   "cell_type": "code",
   "source": "#X1.dropna(subset=['target'], inplace=True)",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hSzHTpuzmScU",
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.420214Z",
     "start_time": "2024-04-25T06:23:49.405182Z"
    }
   },
   "source": "#X = data.iloc[:,:-1]",
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.466884Z",
     "start_time": "2024-04-25T06:23:49.454868Z"
    }
   },
   "source": "#y=data.iloc[:,-1:]",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.544363Z",
     "start_time": "2024-04-25T06:23:49.527355Z"
    }
   },
   "cell_type": "code",
   "source": "#y = data['priceUSD'].shift(-1,fill_value=1)",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.576029Z",
     "start_time": "2024-04-25T06:23:49.573386Z"
    }
   },
   "cell_type": "code",
   "source": "#y = data['priceUSD']",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.606456Z",
     "start_time": "2024-04-25T06:23:49.590048Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8616.0\n",
       "1       8707.0\n",
       "2       8795.0\n",
       "3       8859.0\n",
       "4       8877.0\n",
       "        ...   \n",
       "634    16643.0\n",
       "635    16579.0\n",
       "636    16567.0\n",
       "637    16561.0\n",
       "638    16627.0\n",
       "Name: price3wmaUSD, Length: 639, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.637326Z",
     "start_time": "2024-04-25T06:23:49.622305Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX = []\n",
    "    datay = []\n",
    "    for i in range(len(dataset) - time_step):\n",
    "        a = dataset.iloc[i:(i + time_step), :].values  # Use .iloc for DataFrame\n",
    "        dataX.append(a)\n",
    "        datay.append(dataset.iloc[i + time_step, -1])\n",
    "    return np.array(dataX), np.array(datay)\n"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.668134Z",
     "start_time": "2024-04-25T06:23:49.652840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#time_step = 15\n",
    "#X2 ,y2 = create_dataset(X1, time_step)\n",
    "\n",
    "#print(\"X: \", X2.shape)\n",
    "#print(\"y: \", y2.shape)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.698638Z",
     "start_time": "2024-04-25T06:23:49.686627Z"
    }
   },
   "cell_type": "code",
   "source": "#X2",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.729705Z",
     "start_time": "2024-04-25T06:23:49.715186Z"
    }
   },
   "cell_type": "code",
   "source": "#y2",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.745280Z",
     "start_time": "2024-04-25T06:23:49.732271Z"
    }
   },
   "cell_type": "code",
   "source": "#y2_reshaped = y2.reshape(-1, 1, 1)",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.760798Z",
     "start_time": "2024-04-25T06:23:49.746790Z"
    }
   },
   "cell_type": "code",
   "source": "#y2_reshaped",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.791747Z",
     "start_time": "2024-04-25T06:23:49.777390Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.837632Z",
     "start_time": "2024-04-25T06:23:49.823979Z"
    }
   },
   "source": "X_train, X_test, y_train, y_test =train_test_split(X,y, test_size=0.2, train_size=0.8, shuffle=False, random_state=8)",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.852762Z",
     "start_time": "2024-04-25T06:23:49.843584Z"
    }
   },
   "source": [
    "X_train.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 12)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.883994Z",
     "start_time": "2024-04-25T06:23:49.869300Z"
    }
   },
   "source": [
    "estimators=[]"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.930148Z",
     "start_time": "2024-04-25T06:23:49.924194Z"
    }
   },
   "source": [
    "estimators.append(['robust',RobustScaler()])"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:49.976676Z",
     "start_time": "2024-04-25T06:23:49.963062Z"
    }
   },
   "source": [
    "estimators.append(['mixmax',MinMaxScaler()])"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.022931Z",
     "start_time": "2024-04-25T06:23:50.006925Z"
    }
   },
   "source": [
    "scale=Pipeline(estimators,verbose=True)"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CDojXgA7mpWa",
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.038232Z",
     "start_time": "2024-04-25T06:23:50.030344Z"
    }
   },
   "source": [
    "X_train=scale.fit_transform(X_train)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............ (step 1 of 2) Processing robust, total=   0.0s\n",
      "[Pipeline] ............ (step 2 of 2) Processing mixmax, total=   0.0s\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.053839Z",
     "start_time": "2024-04-25T06:23:50.040561Z"
    }
   },
   "source": [
    "X_test=scale.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.084756Z",
     "start_time": "2024-04-25T06:23:50.076749Z"
    }
   },
   "source": [
    "X_train=np.reshape(X_train,(X_train.shape[0],1,X_train.shape[1]))"
   ],
   "outputs": [],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.116422Z",
     "start_time": "2024-04-25T06:23:50.105053Z"
    }
   },
   "source": [
    "X_test=np.reshape(X_test,(X_test.shape[0],1,X_test.shape[1]))"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2wNcl2z_JKkM",
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.162182Z",
     "start_time": "2024-04-25T06:23:50.150297Z"
    }
   },
   "source": [
    "y_train=y_train.values"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.193073Z",
     "start_time": "2024-04-25T06:23:50.181694Z"
    }
   },
   "source": [
    "y_train=np.reshape(y_train, (y_train.shape[0],1,1))"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.208592Z",
     "start_time": "2024-04-25T06:23:50.198083Z"
    }
   },
   "source": [
    "y_test=y_test.values"
   ],
   "outputs": [],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.223921Z",
     "start_time": "2024-04-25T06:23:50.216421Z"
    }
   },
   "source": [
    "y_test=np.reshape(y_test,(y_test.shape[0],1,1))"
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.254707Z",
     "start_time": "2024-04-25T06:23:50.240889Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.270150Z",
     "start_time": "2024-04-25T06:23:50.262523Z"
    }
   },
   "source": "X_train.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 1, 12)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.301481Z",
     "start_time": "2024-04-25T06:23:50.283662Z"
    }
   },
   "cell_type": "code",
   "source": "X_train",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.0000000e+00, 2.0612398e-01, 8.4264830e-02, ...,\n",
       "         3.1855136e-01, 7.9214415e-03, 0.0000000e+00]],\n",
       "\n",
       "       [[1.0000000e+00, 2.2852875e-01, 8.3404988e-02, ...,\n",
       "         3.1633407e-01, 1.3735418e-02, 1.0250944e-01]],\n",
       "\n",
       "       [[1.0000000e+00, 2.4869305e-01, 8.3404988e-02, ...,\n",
       "         2.9785663e-01, 4.1431817e-03, 1.0453031e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[9.9999997e-06, 2.1732636e-01, 5.1590712e-03, ...,\n",
       "         3.2224685e-01, 2.0522813e-01, 3.7492782e-01]],\n",
       "\n",
       "       [[9.9999997e-06, 2.1433906e-01, 2.5795356e-03, ...,\n",
       "         3.5772356e-01, 1.6259265e-01, 3.6031535e-01]],\n",
       "\n",
       "       [[9.9999997e-06, 2.1359223e-01, 0.0000000e+00, ...,\n",
       "         3.5181078e-01, 2.3403892e-01, 3.5087720e-01]]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.316785Z",
     "start_time": "2024-04-25T06:23:50.304788Z"
    }
   },
   "cell_type": "code",
   "source": "y_train.shape",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511, 1, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.393947Z",
     "start_time": "2024-04-25T06:23:50.379387Z"
    }
   },
   "cell_type": "code",
   "source": "y_train",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 8616.]],\n",
       "\n",
       "       [[ 8707.]],\n",
       "\n",
       "       [[ 8795.]],\n",
       "\n",
       "       [[ 8859.]],\n",
       "\n",
       "       [[ 8877.]],\n",
       "\n",
       "       [[ 8773.]],\n",
       "\n",
       "       [[ 8703.]],\n",
       "\n",
       "       [[ 8682.]],\n",
       "\n",
       "       [[ 8577.]],\n",
       "\n",
       "       [[ 8477.]],\n",
       "\n",
       "       [[ 8586.]],\n",
       "\n",
       "       [[ 8850.]],\n",
       "\n",
       "       [[ 9148.]],\n",
       "\n",
       "       [[ 9322.]],\n",
       "\n",
       "       [[ 9373.]],\n",
       "\n",
       "       [[ 9384.]],\n",
       "\n",
       "       [[ 9391.]],\n",
       "\n",
       "       [[ 9376.]],\n",
       "\n",
       "       [[ 9301.]],\n",
       "\n",
       "       [[ 9347.]],\n",
       "\n",
       "       [[ 9532.]],\n",
       "\n",
       "       [[ 9704.]],\n",
       "\n",
       "       [[ 9795.]],\n",
       "\n",
       "       [[ 9948.]],\n",
       "\n",
       "       [[ 9964.]],\n",
       "\n",
       "       [[ 9975.]],\n",
       "\n",
       "       [[10143.]],\n",
       "\n",
       "       [[10249.]],\n",
       "\n",
       "       [[10287.]],\n",
       "\n",
       "       [[10215.]],\n",
       "\n",
       "       [[10054.]],\n",
       "\n",
       "       [[ 9859.]],\n",
       "\n",
       "       [[ 9814.]],\n",
       "\n",
       "       [[ 9946.]],\n",
       "\n",
       "       [[ 9810.]],\n",
       "\n",
       "       [[ 9730.]],\n",
       "\n",
       "       [[ 9664.]],\n",
       "\n",
       "       [[ 9761.]],\n",
       "\n",
       "       [[ 9772.]],\n",
       "\n",
       "       [[ 9653.]],\n",
       "\n",
       "       [[ 9332.]],\n",
       "\n",
       "       [[ 9010.]],\n",
       "\n",
       "       [[ 8798.]],\n",
       "\n",
       "       [[ 8714.]],\n",
       "\n",
       "       [[ 8634.]],\n",
       "\n",
       "       [[ 8683.]],\n",
       "\n",
       "       [[ 8742.]],\n",
       "\n",
       "       [[ 8773.]],\n",
       "\n",
       "       [[ 8900.]],\n",
       "\n",
       "       [[ 9019.]],\n",
       "\n",
       "       [[ 9062.]],\n",
       "\n",
       "       [[ 8828.]],\n",
       "\n",
       "       [[ 8462.]],\n",
       "\n",
       "       [[ 8716.]],\n",
       "\n",
       "       [[ 8833.]],\n",
       "\n",
       "       [[ 8901.]],\n",
       "\n",
       "       [[ 8857.]],\n",
       "\n",
       "       [[ 8874.]],\n",
       "\n",
       "       [[ 8986.]],\n",
       "\n",
       "       [[ 9243.]],\n",
       "\n",
       "       [[ 9625.]],\n",
       "\n",
       "       [[ 9742.]],\n",
       "\n",
       "       [[ 9242.]],\n",
       "\n",
       "       [[ 8872.]],\n",
       "\n",
       "       [[ 8738.]],\n",
       "\n",
       "       [[ 8895.]],\n",
       "\n",
       "       [[ 9237.]],\n",
       "\n",
       "       [[ 9441.]],\n",
       "\n",
       "       [[ 9464.]],\n",
       "\n",
       "       [[ 9534.]],\n",
       "\n",
       "       [[ 9640.]],\n",
       "\n",
       "       [[ 9687.]],\n",
       "\n",
       "       [[ 9687.]],\n",
       "\n",
       "       [[ 9490.]],\n",
       "\n",
       "       [[ 9282.]],\n",
       "\n",
       "       [[ 9204.]],\n",
       "\n",
       "       [[ 9165.]],\n",
       "\n",
       "       [[ 8997.]],\n",
       "\n",
       "       [[ 8902.]],\n",
       "\n",
       "       [[ 8945.]],\n",
       "\n",
       "       [[ 9150.]],\n",
       "\n",
       "       [[ 9344.]],\n",
       "\n",
       "       [[ 9463.]],\n",
       "\n",
       "       [[ 9526.]],\n",
       "\n",
       "       [[ 9561.]],\n",
       "\n",
       "       [[ 9733.]],\n",
       "\n",
       "       [[ 9675.]],\n",
       "\n",
       "       [[ 9691.]],\n",
       "\n",
       "       [[ 9710.]],\n",
       "\n",
       "       [[ 9700.]],\n",
       "\n",
       "       [[ 9668.]],\n",
       "\n",
       "       [[ 9691.]],\n",
       "\n",
       "       [[ 9711.]],\n",
       "\n",
       "       [[ 9759.]],\n",
       "\n",
       "       [[ 9714.]],\n",
       "\n",
       "       [[ 9565.]],\n",
       "\n",
       "       [[ 9474.]],\n",
       "\n",
       "       [[ 9432.]],\n",
       "\n",
       "       [[ 9346.]],\n",
       "\n",
       "       [[ 9408.]],\n",
       "\n",
       "       [[ 9441.]],\n",
       "\n",
       "       [[ 9452.]],\n",
       "\n",
       "       [[ 9398.]],\n",
       "\n",
       "       [[ 9355.]],\n",
       "\n",
       "       [[ 9355.]],\n",
       "\n",
       "       [[ 9424.]],\n",
       "\n",
       "       [[ 9550.]],\n",
       "\n",
       "       [[ 9532.]],\n",
       "\n",
       "       [[ 9395.]],\n",
       "\n",
       "       [[ 9275.]],\n",
       "\n",
       "       [[ 9188.]],\n",
       "\n",
       "       [[ 9128.]],\n",
       "\n",
       "       [[ 9128.]],\n",
       "\n",
       "       [[ 9155.]],\n",
       "\n",
       "       [[ 9198.]],\n",
       "\n",
       "       [[ 9206.]],\n",
       "\n",
       "       [[ 9167.]],\n",
       "\n",
       "       [[ 9144.]],\n",
       "\n",
       "       [[ 9122.]],\n",
       "\n",
       "       [[ 9181.]],\n",
       "\n",
       "       [[ 9250.]],\n",
       "\n",
       "       [[ 9327.]],\n",
       "\n",
       "       [[ 9356.]],\n",
       "\n",
       "       [[ 9301.]],\n",
       "\n",
       "       [[ 9279.]],\n",
       "\n",
       "       [[ 9278.]],\n",
       "\n",
       "       [[ 9302.]],\n",
       "\n",
       "       [[ 9280.]],\n",
       "\n",
       "       [[ 9266.]],\n",
       "\n",
       "       [[ 9213.]],\n",
       "\n",
       "       [[ 9184.]],\n",
       "\n",
       "       [[ 9185.]],\n",
       "\n",
       "       [[ 9194.]],\n",
       "\n",
       "       [[ 9209.]],\n",
       "\n",
       "       [[ 9277.]],\n",
       "\n",
       "       [[ 9349.]],\n",
       "\n",
       "       [[ 9470.]],\n",
       "\n",
       "       [[ 9536.]],\n",
       "\n",
       "       [[ 9595.]],\n",
       "\n",
       "       [[ 9721.]],\n",
       "\n",
       "       [[10095.]],\n",
       "\n",
       "       [[10608.]],\n",
       "\n",
       "       [[10949.]],\n",
       "\n",
       "       [[11050.]],\n",
       "\n",
       "       [[11129.]],\n",
       "\n",
       "       [[11370.]],\n",
       "\n",
       "       [[11402.]],\n",
       "\n",
       "       [[11342.]],\n",
       "\n",
       "       [[11269.]],\n",
       "\n",
       "       [[11358.]],\n",
       "\n",
       "       [[11574.]],\n",
       "\n",
       "       [[11689.]],\n",
       "\n",
       "       [[11707.]],\n",
       "\n",
       "       [[11685.]],\n",
       "\n",
       "       [[11730.]],\n",
       "\n",
       "       [[11595.]],\n",
       "\n",
       "       [[11538.]],\n",
       "\n",
       "       [[11640.]],\n",
       "\n",
       "       [[11666.]],\n",
       "\n",
       "       [[11627.]],\n",
       "\n",
       "       [[11673.]],\n",
       "\n",
       "       [[11612.]],\n",
       "\n",
       "       [[11502.]],\n",
       "\n",
       "       [[11401.]],\n",
       "\n",
       "       [[11409.]],\n",
       "\n",
       "       [[11464.]],\n",
       "\n",
       "       [[11552.]],\n",
       "\n",
       "       [[11635.]],\n",
       "\n",
       "       [[11699.]],\n",
       "\n",
       "       [[11370.]],\n",
       "\n",
       "       [[10814.]],\n",
       "\n",
       "       [[10447.]],\n",
       "\n",
       "       [[10261.]],\n",
       "\n",
       "       [[10197.]],\n",
       "\n",
       "       [[10167.]],\n",
       "\n",
       "       [[10174.]],\n",
       "\n",
       "       [[10261.]],\n",
       "\n",
       "       [[10301.]],\n",
       "\n",
       "       [[10350.]],\n",
       "\n",
       "       [[10380.]],\n",
       "\n",
       "       [[10454.]],\n",
       "\n",
       "       [[10627.]],\n",
       "\n",
       "       [[10794.]],\n",
       "\n",
       "       [[10879.]],\n",
       "\n",
       "       [[10915.]],\n",
       "\n",
       "       [[10970.]],\n",
       "\n",
       "       [[10959.]],\n",
       "\n",
       "       [[10825.]],\n",
       "\n",
       "       [[10623.]],\n",
       "\n",
       "       [[10496.]],\n",
       "\n",
       "       [[10451.]],\n",
       "\n",
       "       [[10563.]],\n",
       "\n",
       "       [[10663.]],\n",
       "\n",
       "       [[10717.]],\n",
       "\n",
       "       [[10806.]],\n",
       "\n",
       "       [[10785.]],\n",
       "\n",
       "       [[10769.]],\n",
       "\n",
       "       [[10756.]],\n",
       "\n",
       "       [[10648.]],\n",
       "\n",
       "       [[10584.]],\n",
       "\n",
       "       [[10580.]],\n",
       "\n",
       "       [[10651.]],\n",
       "\n",
       "       [[10698.]],\n",
       "\n",
       "       [[10670.]],\n",
       "\n",
       "       [[10697.]],\n",
       "\n",
       "       [[10843.]],\n",
       "\n",
       "       [[11119.]],\n",
       "\n",
       "       [[11292.]],\n",
       "\n",
       "       [[11402.]],\n",
       "\n",
       "       [[11438.]],\n",
       "\n",
       "       [[11431.]],\n",
       "\n",
       "       [[11421.]],\n",
       "\n",
       "       [[11392.]],\n",
       "\n",
       "       [[11367.]],\n",
       "\n",
       "       [[11395.]],\n",
       "\n",
       "       [[11494.]],\n",
       "\n",
       "       [[11690.]],\n",
       "\n",
       "       [[16657.]],\n",
       "\n",
       "       [[17358.]],\n",
       "\n",
       "       [[18643.]],\n",
       "\n",
       "       [[18888.]],\n",
       "\n",
       "       [[17478.]],\n",
       "\n",
       "       [[17225.]],\n",
       "\n",
       "       [[18938.]],\n",
       "\n",
       "       [[19051.]],\n",
       "\n",
       "       [[19170.]],\n",
       "\n",
       "       [[19152.]],\n",
       "\n",
       "       [[19091.]],\n",
       "\n",
       "       [[19098.]],\n",
       "\n",
       "       [[19154.]],\n",
       "\n",
       "       [[19072.]],\n",
       "\n",
       "       [[18656.]],\n",
       "\n",
       "       [[18707.]],\n",
       "\n",
       "       [[19035.]],\n",
       "\n",
       "       [[19252.]],\n",
       "\n",
       "       [[19674.]],\n",
       "\n",
       "       [[21210.]],\n",
       "\n",
       "       [[38380.]],\n",
       "\n",
       "       [[39797.]],\n",
       "\n",
       "       [[39960.]],\n",
       "\n",
       "       [[37133.]],\n",
       "\n",
       "       [[36609.]],\n",
       "\n",
       "       [[37355.]],\n",
       "\n",
       "       [[37346.]],\n",
       "\n",
       "       [[36375.]],\n",
       "\n",
       "       [[36395.]],\n",
       "\n",
       "       [[36730.]],\n",
       "\n",
       "       [[37405.]],\n",
       "\n",
       "       [[38692.]],\n",
       "\n",
       "       [[38888.]],\n",
       "\n",
       "       [[39995.]],\n",
       "\n",
       "       [[43432.]],\n",
       "\n",
       "       [[46156.]],\n",
       "\n",
       "       [[46836.]],\n",
       "\n",
       "       [[47204.]],\n",
       "\n",
       "       [[47973.]],\n",
       "\n",
       "       [[47995.]],\n",
       "\n",
       "       [[48469.]],\n",
       "\n",
       "       [[48286.]],\n",
       "\n",
       "       [[47444.]],\n",
       "\n",
       "       [[45894.]],\n",
       "\n",
       "       [[46586.]],\n",
       "\n",
       "       [[47647.]],\n",
       "\n",
       "       [[48728.]],\n",
       "\n",
       "       [[48435.]],\n",
       "\n",
       "       [[48525.]],\n",
       "\n",
       "       [[46227.]],\n",
       "\n",
       "       [[41693.]],\n",
       "\n",
       "       [[40327.]],\n",
       "\n",
       "       [[39368.]],\n",
       "\n",
       "       [[38441.]],\n",
       "\n",
       "       [[36572.]],\n",
       "\n",
       "       [[36454.]],\n",
       "\n",
       "       [[37227.]],\n",
       "\n",
       "       [[38488.]],\n",
       "\n",
       "       [[38837.]],\n",
       "\n",
       "       [[37791.]],\n",
       "\n",
       "       [[36309.]],\n",
       "\n",
       "       [[36264.]],\n",
       "\n",
       "       [[36873.]],\n",
       "\n",
       "       [[37801.]],\n",
       "\n",
       "       [[37621.]],\n",
       "\n",
       "       [[37099.]],\n",
       "\n",
       "       [[36365.]],\n",
       "\n",
       "       [[36630.]],\n",
       "\n",
       "       [[36359.]],\n",
       "\n",
       "       [[36257.]],\n",
       "\n",
       "       [[37907.]],\n",
       "\n",
       "       [[39383.]],\n",
       "\n",
       "       [[39722.]],\n",
       "\n",
       "       [[39145.]],\n",
       "\n",
       "       [[37942.]],\n",
       "\n",
       "       [[36648.]],\n",
       "\n",
       "       [[36233.]],\n",
       "\n",
       "       [[37317.]],\n",
       "\n",
       "       [[38860.]],\n",
       "\n",
       "       [[39486.]],\n",
       "\n",
       "       [[39731.]],\n",
       "\n",
       "       [[40656.]],\n",
       "\n",
       "       [[41233.]],\n",
       "\n",
       "       [[40570.]],\n",
       "\n",
       "       [[39352.]],\n",
       "\n",
       "       [[38778.]],\n",
       "\n",
       "       [[39023.]],\n",
       "\n",
       "       [[40256.]],\n",
       "\n",
       "       [[42109.]],\n",
       "\n",
       "       [[43559.]],\n",
       "\n",
       "       [[45711.]],\n",
       "\n",
       "       [[45722.]],\n",
       "\n",
       "       [[46413.]],\n",
       "\n",
       "       [[46594.]],\n",
       "\n",
       "       [[46777.]],\n",
       "\n",
       "       [[46355.]],\n",
       "\n",
       "       [[45703.]],\n",
       "\n",
       "       [[46463.]],\n",
       "\n",
       "       [[47958.]],\n",
       "\n",
       "       [[48731.]],\n",
       "\n",
       "       [[48736.]],\n",
       "\n",
       "       [[47907.]],\n",
       "\n",
       "       [[47679.]],\n",
       "\n",
       "       [[48233.]],\n",
       "\n",
       "       [[48561.]],\n",
       "\n",
       "       [[48395.]],\n",
       "\n",
       "       [[47778.]],\n",
       "\n",
       "       [[47613.]],\n",
       "\n",
       "       [[48595.]],\n",
       "\n",
       "       [[48439.]],\n",
       "\n",
       "       [[46967.]],\n",
       "\n",
       "       [[46148.]],\n",
       "\n",
       "       [[45727.]],\n",
       "\n",
       "       [[46588.]],\n",
       "\n",
       "       [[47470.]],\n",
       "\n",
       "       [[47677.]],\n",
       "\n",
       "       [[47945.]],\n",
       "\n",
       "       [[47864.]],\n",
       "\n",
       "       [[46278.]],\n",
       "\n",
       "       [[42865.]],\n",
       "\n",
       "       [[43288.]],\n",
       "\n",
       "       [[43348.]],\n",
       "\n",
       "       [[43010.]],\n",
       "\n",
       "       [[42776.]],\n",
       "\n",
       "       [[43126.]],\n",
       "\n",
       "       [[42622.]],\n",
       "\n",
       "       [[42176.]],\n",
       "\n",
       "       [[42579.]],\n",
       "\n",
       "       [[46454.]],\n",
       "\n",
       "       [[47614.]],\n",
       "\n",
       "       [[48027.]],\n",
       "\n",
       "       [[49030.]],\n",
       "\n",
       "       [[48944.]],\n",
       "\n",
       "       [[48869.]],\n",
       "\n",
       "       [[48486.]],\n",
       "\n",
       "       [[48957.]],\n",
       "\n",
       "       [[48705.]],\n",
       "\n",
       "       [[47925.]],\n",
       "\n",
       "       [[47829.]],\n",
       "\n",
       "       [[48200.]],\n",
       "\n",
       "       [[47757.]],\n",
       "\n",
       "       [[47097.]],\n",
       "\n",
       "       [[46980.]],\n",
       "\n",
       "       [[46711.]],\n",
       "\n",
       "       [[47538.]],\n",
       "\n",
       "       [[48358.]],\n",
       "\n",
       "       [[48924.]],\n",
       "\n",
       "       [[48603.]],\n",
       "\n",
       "       [[47559.]],\n",
       "\n",
       "       [[47279.]],\n",
       "\n",
       "       [[47166.]],\n",
       "\n",
       "       [[47203.]],\n",
       "\n",
       "       [[47011.]],\n",
       "\n",
       "       [[46702.]],\n",
       "\n",
       "       [[46242.]],\n",
       "\n",
       "       [[43031.]],\n",
       "\n",
       "       [[42044.]],\n",
       "\n",
       "       [[41857.]],\n",
       "\n",
       "       [[41721.]],\n",
       "\n",
       "       [[41946.]],\n",
       "\n",
       "       [[42584.]],\n",
       "\n",
       "       [[43139.]],\n",
       "\n",
       "       [[43046.]],\n",
       "\n",
       "       [[43051.]],\n",
       "\n",
       "       [[43046.]],\n",
       "\n",
       "       [[42825.]],\n",
       "\n",
       "       [[42329.]],\n",
       "\n",
       "       [[42025.]],\n",
       "\n",
       "       [[42068.]],\n",
       "\n",
       "       [[40406.]],\n",
       "\n",
       "       [[37694.]],\n",
       "\n",
       "       [[36766.]],\n",
       "\n",
       "       [[36759.]],\n",
       "\n",
       "       [[36885.]],\n",
       "\n",
       "       [[37313.]],\n",
       "\n",
       "       [[37755.]],\n",
       "\n",
       "       [[37732.]],\n",
       "\n",
       "       [[38122.]],\n",
       "\n",
       "       [[38141.]],\n",
       "\n",
       "       [[37514.]],\n",
       "\n",
       "       [[37926.]],\n",
       "\n",
       "       [[39772.]],\n",
       "\n",
       "       [[41076.]],\n",
       "\n",
       "       [[42331.]],\n",
       "\n",
       "       [[43223.]],\n",
       "\n",
       "       [[43761.]],\n",
       "\n",
       "       [[42950.]],\n",
       "\n",
       "       [[42477.]],\n",
       "\n",
       "       [[42284.]],\n",
       "\n",
       "       [[43067.]],\n",
       "\n",
       "       [[43660.]],\n",
       "\n",
       "       [[43310.]],\n",
       "\n",
       "       [[41761.]],\n",
       "\n",
       "       [[40614.]],\n",
       "\n",
       "       [[39474.]],\n",
       "\n",
       "       [[38853.]],\n",
       "\n",
       "       [[37997.]],\n",
       "\n",
       "       [[37995.]],\n",
       "\n",
       "       [[37032.]],\n",
       "\n",
       "       [[37816.]],\n",
       "\n",
       "       [[38566.]],\n",
       "\n",
       "       [[38898.]],\n",
       "\n",
       "       [[39110.]],\n",
       "\n",
       "       [[41381.]],\n",
       "\n",
       "       [[43128.]],\n",
       "\n",
       "       [[43522.]],\n",
       "\n",
       "       [[42174.]],\n",
       "\n",
       "       [[40353.]],\n",
       "\n",
       "       [[39285.]],\n",
       "\n",
       "       [[38592.]],\n",
       "\n",
       "       [[38519.]],\n",
       "\n",
       "       [[39892.]],\n",
       "\n",
       "       [[39976.]],\n",
       "\n",
       "       [[39519.]],\n",
       "\n",
       "       [[39056.]],\n",
       "\n",
       "       [[38870.]],\n",
       "\n",
       "       [[38752.]],\n",
       "\n",
       "       [[38814.]],\n",
       "\n",
       "       [[39469.]],\n",
       "\n",
       "       [[40216.]],\n",
       "\n",
       "       [[40596.]],\n",
       "\n",
       "       [[41093.]],\n",
       "\n",
       "       [[41317.]],\n",
       "\n",
       "       [[41270.]],\n",
       "\n",
       "       [[41818.]],\n",
       "\n",
       "       [[42117.]],\n",
       "\n",
       "       [[42816.]],\n",
       "\n",
       "       [[43620.]],\n",
       "\n",
       "       [[46026.]],\n",
       "\n",
       "       [[47028.]],\n",
       "\n",
       "       [[47352.]],\n",
       "\n",
       "       [[47007.]],\n",
       "\n",
       "       [[46193.]],\n",
       "\n",
       "       [[46179.]],\n",
       "\n",
       "       [[46231.]],\n",
       "\n",
       "       [[46203.]],\n",
       "\n",
       "       [[46240.]],\n",
       "\n",
       "       [[43576.]],\n",
       "\n",
       "       [[42904.]],\n",
       "\n",
       "       [[42746.]],\n",
       "\n",
       "       [[41946.]],\n",
       "\n",
       "       [[40837.]],\n",
       "\n",
       "       [[40413.]],\n",
       "\n",
       "       [[40494.]],\n",
       "\n",
       "       [[40424.]],\n",
       "\n",
       "       [[40392.]],\n",
       "\n",
       "       [[40330.]],\n",
       "\n",
       "       [[40003.]],\n",
       "\n",
       "       [[40465.]],\n",
       "\n",
       "       [[41024.]],\n",
       "\n",
       "       [[41515.]],\n",
       "\n",
       "       [[40887.]],\n",
       "\n",
       "       [[40176.]],\n",
       "\n",
       "       [[39742.]],\n",
       "\n",
       "       [[39442.]],\n",
       "\n",
       "       [[39530.]],\n",
       "\n",
       "       [[39174.]],\n",
       "\n",
       "       [[39360.]],\n",
       "\n",
       "       [[39224.]],\n",
       "\n",
       "       [[38891.]],\n",
       "\n",
       "       [[38383.]],\n",
       "\n",
       "       [[38447.]],\n",
       "\n",
       "       [[38370.]],\n",
       "\n",
       "       [[38606.]],\n",
       "\n",
       "       [[38539.]],\n",
       "\n",
       "       [[37365.]],\n",
       "\n",
       "       [[36400.]],\n",
       "\n",
       "       [[21039.]],\n",
       "\n",
       "       [[20136.]],\n",
       "\n",
       "       [[19525.]],\n",
       "\n",
       "       [[19791.]],\n",
       "\n",
       "       [[20475.]],\n",
       "\n",
       "       [[20537.]],\n",
       "\n",
       "       [[20526.]],\n",
       "\n",
       "       [[20765.]],\n",
       "\n",
       "       [[21075.]],\n",
       "\n",
       "       [[21281.]],\n",
       "\n",
       "       [[21186.]],\n",
       "\n",
       "       [[20925.]],\n",
       "\n",
       "       [[20475.]],\n",
       "\n",
       "       [[19833.]],\n",
       "\n",
       "       [[19565.]],\n",
       "\n",
       "       [[19342.]],\n",
       "\n",
       "       [[19237.]],\n",
       "\n",
       "       [[19336.]],\n",
       "\n",
       "       [[19689.]],\n",
       "\n",
       "       [[19999.]],\n",
       "\n",
       "       [[20439.]],\n",
       "\n",
       "       [[21160.]],\n",
       "\n",
       "       [[21398.]],\n",
       "\n",
       "       [[20883.]],\n",
       "\n",
       "       [[20225.]],\n",
       "\n",
       "       [[19800.]],\n",
       "\n",
       "       [[19914.]]], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.409493Z",
     "start_time": "2024-04-25T06:23:50.399705Z"
    }
   },
   "cell_type": "code",
   "source": "#X_train, X_test, y_train, y_test =train_test_split(X2,y2_reshaped, test_size=0.2, train_size=0.8, shuffle=False, random_state=8)",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.471350Z",
     "start_time": "2024-04-25T06:23:50.458343Z"
    }
   },
   "cell_type": "code",
   "source": "#X_train.shape[2]",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.548817Z",
     "start_time": "2024-04-25T06:23:50.534958Z"
    }
   },
   "cell_type": "code",
   "source": "#y_train.shape",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.579464Z",
     "start_time": "2024-04-25T06:23:50.573455Z"
    }
   },
   "cell_type": "code",
   "source": "#X_test.shape",
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MVCJxdebqmOr"
   },
   "source": [
    "# **Model Architecture + Training**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.672359Z",
     "start_time": "2024-04-25T06:23:50.656887Z"
    }
   },
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "NBZ9JgDTrHwV",
    "outputId": "40d0a5ca-682d-42d1-e08b-fd28df246868",
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.733809Z",
     "start_time": "2024-04-25T06:23:50.689236Z"
    }
   },
   "source": [
    "\n",
    "adam = optimizers.Adam(learning_rate=lr_schedule(0), amsgrad=True)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:50.764836Z",
     "start_time": "2024-04-25T06:23:50.753326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ],
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:51.043640Z",
     "start_time": "2024-04-25T06:23:50.780356Z"
    }
   },
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu'), input_shape=(1, X_train.shape[2])))\n",
    "model.add(Bidirectional(LSTM(350, return_sequences=True, activation='relu')))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss=\"log_cosh\", optimizer=adam, metrics=['mae'])"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\DS440proj\\BTCpred\\.venv\\lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0WWSdc7AxKV6",
    "ExecuteTime": {
     "end_time": "2024-04-25T06:23:51.059010Z",
     "start_time": "2024-04-25T06:23:51.045140Z"
    }
   },
   "source": [
    "mcp_save = ModelCheckpoint('LSTM_reg_18-21rmse355.keras', save_best_only=True, monitor='val_loss', mode='auto')\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=100, verbose=1, mode='auto')"
   ],
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bIJPsArMr8cs",
    "outputId": "91137564-8bb8-496c-c827-829e240a789a",
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:12.863661Z",
     "start_time": "2024-04-25T06:23:51.060506Z"
    }
   },
   "source": [
    "#model.compile(optimizer='adam', loss='log_cosh', metrics=['accuracy'])\n",
    "model.fit(X_train,y_train, epochs=5000, batch_size=32, validation_data=(X_test,y_test), callbacks=[mcp_save,earlyStopping])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 56ms/step - loss: 26910.4492 - mae: 26911.1406 - val_loss: 18850.5273 - val_mae: 18851.2227\n",
      "Epoch 2/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 27350.0781 - mae: 27350.7695 - val_loss: 18843.4746 - val_mae: 18844.1680\n",
      "Epoch 3/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 25879.0762 - mae: 25879.7676 - val_loss: 18793.9590 - val_mae: 18794.6523\n",
      "Epoch 4/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 26135.6816 - mae: 26136.3711 - val_loss: 18635.7109 - val_mae: 18636.4043\n",
      "Epoch 5/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 26689.5352 - mae: 26690.2246 - val_loss: 18312.5918 - val_mae: 18313.2832\n",
      "Epoch 6/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 37ms/step - loss: 26901.8750 - mae: 26902.5645 - val_loss: 17698.9844 - val_mae: 17699.6797\n",
      "Epoch 7/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step - loss: 24866.5098 - mae: 24867.2031 - val_loss: 16624.5879 - val_mae: 16625.2832\n",
      "Epoch 8/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 56ms/step - loss: 22780.8359 - mae: 22781.5273 - val_loss: 14875.5703 - val_mae: 14876.2637\n",
      "Epoch 9/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - loss: 20382.1250 - mae: 20382.8184 - val_loss: 12214.1846 - val_mae: 12214.8760\n",
      "Epoch 10/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 54ms/step - loss: 16187.7549 - mae: 16188.4492 - val_loss: 8678.3799 - val_mae: 8679.0732\n",
      "Epoch 11/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 56ms/step - loss: 12224.5811 - mae: 12225.2734 - val_loss: 5551.6123 - val_mae: 5552.3057\n",
      "Epoch 12/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step - loss: 10983.1025 - mae: 10983.7949 - val_loss: 3374.2678 - val_mae: 3374.9612\n",
      "Epoch 13/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 50ms/step - loss: 9908.5605 - mae: 9909.2539 - val_loss: 2725.8047 - val_mae: 2726.4976\n",
      "Epoch 14/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 9788.3887 - mae: 9789.0811 - val_loss: 2641.7861 - val_mae: 2642.4795\n",
      "Epoch 15/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 9344.6260 - mae: 9345.3184 - val_loss: 2464.7546 - val_mae: 2465.4480\n",
      "Epoch 16/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 8520.9355 - mae: 8521.6289 - val_loss: 2400.9604 - val_mae: 2401.6536\n",
      "Epoch 17/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 47ms/step - loss: 8310.5947 - mae: 8311.2881 - val_loss: 2264.9697 - val_mae: 2265.6631\n",
      "Epoch 18/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 8160.1772 - mae: 8160.8711 - val_loss: 2352.0156 - val_mae: 2352.7087\n",
      "Epoch 19/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 7317.1470 - mae: 7317.8403 - val_loss: 2434.1194 - val_mae: 2434.8127\n",
      "Epoch 20/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 6809.7134 - mae: 6810.4067 - val_loss: 2361.6265 - val_mae: 2362.3198\n",
      "Epoch 21/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 6558.6748 - mae: 6559.3677 - val_loss: 2782.1565 - val_mae: 2782.8499\n",
      "Epoch 22/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 5817.6187 - mae: 5818.3115 - val_loss: 3302.2578 - val_mae: 3302.9509\n",
      "Epoch 23/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 5702.2158 - mae: 5702.9097 - val_loss: 3450.1270 - val_mae: 3450.8198\n",
      "Epoch 24/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 5576.5146 - mae: 5577.2085 - val_loss: 3781.3179 - val_mae: 3782.0110\n",
      "Epoch 25/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 5148.3169 - mae: 5149.0098 - val_loss: 3834.8635 - val_mae: 3835.5569\n",
      "Epoch 26/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4799.1270 - mae: 4799.8198 - val_loss: 4076.0103 - val_mae: 4076.7034\n",
      "Epoch 27/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 4780.4102 - mae: 4781.1035 - val_loss: 4080.8806 - val_mae: 4081.5740\n",
      "Epoch 28/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 4550.8154 - mae: 4551.5088 - val_loss: 4121.9946 - val_mae: 4122.6880\n",
      "Epoch 29/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 4223.0029 - mae: 4223.6958 - val_loss: 3977.2229 - val_mae: 3977.9163\n",
      "Epoch 30/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 4411.2666 - mae: 4411.9600 - val_loss: 4303.6221 - val_mae: 4304.3154\n",
      "Epoch 31/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 3958.8696 - mae: 3959.5627 - val_loss: 4401.2217 - val_mae: 4401.9150\n",
      "Epoch 32/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 3842.3577 - mae: 3843.0508 - val_loss: 4245.8521 - val_mae: 4246.5449\n",
      "Epoch 33/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 3636.0781 - mae: 3636.7715 - val_loss: 4284.5547 - val_mae: 4285.2476\n",
      "Epoch 34/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 3360.1372 - mae: 3360.8308 - val_loss: 4317.6045 - val_mae: 4318.2979\n",
      "Epoch 35/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 3685.3303 - mae: 3686.0232 - val_loss: 4079.7458 - val_mae: 4080.4392\n",
      "Epoch 36/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 3329.9407 - mae: 3330.6338 - val_loss: 4084.8374 - val_mae: 4085.5308\n",
      "Epoch 37/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 3088.7761 - mae: 3089.4692 - val_loss: 4184.7100 - val_mae: 4185.4028\n",
      "Epoch 38/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 3383.9402 - mae: 3384.6338 - val_loss: 4095.9661 - val_mae: 4096.6592\n",
      "Epoch 39/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 3040.1516 - mae: 3040.8450 - val_loss: 3921.2764 - val_mae: 3921.9697\n",
      "Epoch 40/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 2695.3953 - mae: 2696.0886 - val_loss: 4091.0579 - val_mae: 4091.7512\n",
      "Epoch 41/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 2685.3450 - mae: 2686.0383 - val_loss: 3710.8025 - val_mae: 3711.4956\n",
      "Epoch 42/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 2542.1492 - mae: 2542.8428 - val_loss: 3729.1064 - val_mae: 3729.7998\n",
      "Epoch 43/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 2662.5994 - mae: 2663.2927 - val_loss: 3683.6372 - val_mae: 3684.3306\n",
      "Epoch 44/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 2462.8350 - mae: 2463.5281 - val_loss: 3577.4060 - val_mae: 3578.0994\n",
      "Epoch 45/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 2349.3198 - mae: 2350.0122 - val_loss: 3348.2705 - val_mae: 3348.9639\n",
      "Epoch 46/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 2300.7366 - mae: 2301.4297 - val_loss: 3514.7031 - val_mae: 3515.3965\n",
      "Epoch 47/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 2391.2195 - mae: 2391.9124 - val_loss: 3411.3010 - val_mae: 3411.9944\n",
      "Epoch 48/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 2122.2349 - mae: 2122.9280 - val_loss: 3229.2744 - val_mae: 3229.9673\n",
      "Epoch 49/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 2132.3853 - mae: 2133.0784 - val_loss: 3393.8640 - val_mae: 3394.5574\n",
      "Epoch 50/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 2258.1125 - mae: 2258.8054 - val_loss: 3046.8035 - val_mae: 3047.4966\n",
      "Epoch 51/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 2291.5825 - mae: 2292.2759 - val_loss: 3005.2454 - val_mae: 3005.9385\n",
      "Epoch 52/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 2093.7341 - mae: 2094.4268 - val_loss: 3088.8228 - val_mae: 3089.5161\n",
      "Epoch 53/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 1915.9431 - mae: 1916.6362 - val_loss: 3219.2588 - val_mae: 3219.9519\n",
      "Epoch 54/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1947.3630 - mae: 1948.0563 - val_loss: 3031.3960 - val_mae: 3032.0891\n",
      "Epoch 55/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 2035.8599 - mae: 2036.5531 - val_loss: 2855.8315 - val_mae: 2856.5249\n",
      "Epoch 56/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1808.2161 - mae: 1808.9092 - val_loss: 2954.9690 - val_mae: 2955.6621\n",
      "Epoch 57/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1934.5262 - mae: 1935.2191 - val_loss: 2949.9375 - val_mae: 2950.6309\n",
      "Epoch 58/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1910.8259 - mae: 1911.5193 - val_loss: 2763.6255 - val_mae: 2764.3188\n",
      "Epoch 59/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1858.2870 - mae: 1858.9803 - val_loss: 2928.6504 - val_mae: 2929.3438\n",
      "Epoch 60/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1711.9775 - mae: 1712.6708 - val_loss: 2913.4482 - val_mae: 2914.1414\n",
      "Epoch 61/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1774.1417 - mae: 1774.8350 - val_loss: 2871.8606 - val_mae: 2872.5537\n",
      "Epoch 62/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1707.5728 - mae: 1708.2661 - val_loss: 2819.4680 - val_mae: 2820.1611\n",
      "Epoch 63/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 1695.0448 - mae: 1695.7377 - val_loss: 2821.1929 - val_mae: 2821.8862\n",
      "Epoch 64/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1699.9604 - mae: 1700.6536 - val_loss: 2733.9187 - val_mae: 2734.6121\n",
      "Epoch 65/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1723.6537 - mae: 1724.3458 - val_loss: 2900.5889 - val_mae: 2901.2820\n",
      "Epoch 66/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1650.1046 - mae: 1650.7977 - val_loss: 2993.7402 - val_mae: 2994.4336\n",
      "Epoch 67/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1687.5431 - mae: 1688.2363 - val_loss: 2858.9102 - val_mae: 2859.6033\n",
      "Epoch 68/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 1471.8872 - mae: 1472.5803 - val_loss: 2938.2485 - val_mae: 2938.9417\n",
      "Epoch 69/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1501.4004 - mae: 1502.0927 - val_loss: 2645.5264 - val_mae: 2646.2192\n",
      "Epoch 70/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1595.4928 - mae: 1596.1854 - val_loss: 2755.3135 - val_mae: 2756.0063\n",
      "Epoch 71/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1555.4631 - mae: 1556.1525 - val_loss: 2848.9380 - val_mae: 2849.6311\n",
      "Epoch 72/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1383.0140 - mae: 1383.7069 - val_loss: 2655.8774 - val_mae: 2656.5703\n",
      "Epoch 73/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 1564.0314 - mae: 1564.7240 - val_loss: 2724.3179 - val_mae: 2725.0110\n",
      "Epoch 74/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 1558.7573 - mae: 1559.4506 - val_loss: 2689.8279 - val_mae: 2690.5210\n",
      "Epoch 75/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1403.5712 - mae: 1404.2643 - val_loss: 2792.6416 - val_mae: 2793.3345\n",
      "Epoch 76/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 1331.0109 - mae: 1331.7040 - val_loss: 2789.1162 - val_mae: 2789.8096\n",
      "Epoch 77/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1511.8746 - mae: 1512.5677 - val_loss: 2514.2668 - val_mae: 2514.9597\n",
      "Epoch 78/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1445.7826 - mae: 1446.4756 - val_loss: 2632.6108 - val_mae: 2633.3040\n",
      "Epoch 79/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1323.8843 - mae: 1324.5758 - val_loss: 2698.0830 - val_mae: 2698.7759\n",
      "Epoch 80/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1400.7189 - mae: 1401.4119 - val_loss: 2765.2715 - val_mae: 2765.9644\n",
      "Epoch 81/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1444.9028 - mae: 1445.5959 - val_loss: 2777.6047 - val_mae: 2778.2979\n",
      "Epoch 82/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1394.3154 - mae: 1395.0077 - val_loss: 2432.3647 - val_mae: 2433.0581\n",
      "Epoch 83/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1418.4756 - mae: 1419.1688 - val_loss: 2351.1987 - val_mae: 2351.8916\n",
      "Epoch 84/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1413.4147 - mae: 1414.1072 - val_loss: 2534.2896 - val_mae: 2534.9827\n",
      "Epoch 85/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1334.0197 - mae: 1334.7119 - val_loss: 2636.9453 - val_mae: 2637.6384\n",
      "Epoch 86/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1368.3634 - mae: 1369.0562 - val_loss: 2549.7358 - val_mae: 2550.4287\n",
      "Epoch 87/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1206.5038 - mae: 1207.1968 - val_loss: 2422.1951 - val_mae: 2422.8879\n",
      "Epoch 88/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 1241.3043 - mae: 1241.9974 - val_loss: 2438.1006 - val_mae: 2438.7937\n",
      "Epoch 89/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1182.8682 - mae: 1183.5614 - val_loss: 2500.0020 - val_mae: 2500.6953\n",
      "Epoch 90/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 1221.5566 - mae: 1222.2496 - val_loss: 2592.4785 - val_mae: 2593.1714\n",
      "Epoch 91/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1294.5958 - mae: 1295.2889 - val_loss: 2453.7610 - val_mae: 2454.4541\n",
      "Epoch 92/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1149.9685 - mae: 1150.6613 - val_loss: 2478.3608 - val_mae: 2479.0540\n",
      "Epoch 93/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1176.6436 - mae: 1177.3367 - val_loss: 2397.2405 - val_mae: 2397.9336\n",
      "Epoch 94/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1279.2253 - mae: 1279.9172 - val_loss: 2539.1348 - val_mae: 2539.8279\n",
      "Epoch 95/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1287.9880 - mae: 1288.6808 - val_loss: 2355.8608 - val_mae: 2356.5537\n",
      "Epoch 96/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 39ms/step - loss: 1137.4645 - mae: 1138.1575 - val_loss: 2018.5103 - val_mae: 2019.2036\n",
      "Epoch 97/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1348.3110 - mae: 1349.0042 - val_loss: 2419.8145 - val_mae: 2420.5073\n",
      "Epoch 98/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1166.2318 - mae: 1166.9242 - val_loss: 2525.1958 - val_mae: 2525.8892\n",
      "Epoch 99/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1143.4011 - mae: 1144.0942 - val_loss: 2273.8870 - val_mae: 2274.5801\n",
      "Epoch 100/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 1094.4222 - mae: 1095.1155 - val_loss: 2321.3391 - val_mae: 2322.0322\n",
      "Epoch 101/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1112.2264 - mae: 1112.9186 - val_loss: 2138.8198 - val_mae: 2139.5129\n",
      "Epoch 102/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1082.1342 - mae: 1082.8270 - val_loss: 2380.9570 - val_mae: 2381.6499\n",
      "Epoch 103/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1110.3365 - mae: 1111.0297 - val_loss: 2320.5811 - val_mae: 2321.2744\n",
      "Epoch 104/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1037.1407 - mae: 1037.8334 - val_loss: 2365.1448 - val_mae: 2365.8381\n",
      "Epoch 105/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1103.0311 - mae: 1103.7239 - val_loss: 2461.4756 - val_mae: 2462.1687\n",
      "Epoch 106/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1133.9554 - mae: 1134.6486 - val_loss: 2329.3486 - val_mae: 2330.0415\n",
      "Epoch 107/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 1095.2657 - mae: 1095.9565 - val_loss: 2186.3242 - val_mae: 2187.0173\n",
      "Epoch 108/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1144.0872 - mae: 1144.7798 - val_loss: 2144.0129 - val_mae: 2144.7061\n",
      "Epoch 109/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1097.8757 - mae: 1098.5688 - val_loss: 2202.4985 - val_mae: 2203.1914\n",
      "Epoch 110/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1203.0243 - mae: 1203.7166 - val_loss: 2019.5796 - val_mae: 2020.2726\n",
      "Epoch 111/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1010.8219 - mae: 1011.5151 - val_loss: 2376.2151 - val_mae: 2376.9084\n",
      "Epoch 112/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1036.1744 - mae: 1036.8676 - val_loss: 2024.7878 - val_mae: 2025.4810\n",
      "Epoch 113/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 1008.2739 - mae: 1008.9669 - val_loss: 2261.9712 - val_mae: 2262.6643\n",
      "Epoch 114/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1010.5703 - mae: 1011.2623 - val_loss: 2184.5742 - val_mae: 2185.2671\n",
      "Epoch 115/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 1006.9377 - mae: 1007.6288 - val_loss: 2083.2690 - val_mae: 2083.9619\n",
      "Epoch 116/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 861.6693 - mae: 862.3624 - val_loss: 2189.5405 - val_mae: 2190.2336\n",
      "Epoch 117/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 903.9413 - mae: 904.6339 - val_loss: 2238.4675 - val_mae: 2239.1606\n",
      "Epoch 118/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 977.6323 - mae: 978.3251 - val_loss: 2130.9771 - val_mae: 2131.6699\n",
      "Epoch 119/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 883.8658 - mae: 884.5575 - val_loss: 2216.9438 - val_mae: 2217.6370\n",
      "Epoch 120/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 806.6443 - mae: 807.3366 - val_loss: 2167.4602 - val_mae: 2168.1533\n",
      "Epoch 121/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 844.9822 - mae: 845.6753 - val_loss: 2218.0710 - val_mae: 2218.7642\n",
      "Epoch 122/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 920.2394 - mae: 920.9305 - val_loss: 2221.3882 - val_mae: 2222.0815\n",
      "Epoch 123/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 853.7178 - mae: 854.4102 - val_loss: 2107.6040 - val_mae: 2108.2974\n",
      "Epoch 124/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 920.7746 - mae: 921.4663 - val_loss: 2021.0046 - val_mae: 2021.6976\n",
      "Epoch 125/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 796.9089 - mae: 797.6017 - val_loss: 2011.9961 - val_mae: 2012.6887\n",
      "Epoch 126/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 985.7128 - mae: 986.4058 - val_loss: 2073.4387 - val_mae: 2074.1318\n",
      "Epoch 127/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 819.0224 - mae: 819.7151 - val_loss: 2050.9985 - val_mae: 2051.6919\n",
      "Epoch 128/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 879.9720 - mae: 880.6628 - val_loss: 2053.3806 - val_mae: 2054.0737\n",
      "Epoch 129/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 891.2522 - mae: 891.9448 - val_loss: 1955.4164 - val_mae: 1956.1096\n",
      "Epoch 130/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 937.6446 - mae: 938.3359 - val_loss: 2010.7010 - val_mae: 2011.3940\n",
      "Epoch 131/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 790.7413 - mae: 791.4341 - val_loss: 1982.3588 - val_mae: 1983.0519\n",
      "Epoch 132/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 799.8981 - mae: 800.5905 - val_loss: 1871.2039 - val_mae: 1871.8970\n",
      "Epoch 133/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 763.0521 - mae: 763.7427 - val_loss: 2002.1377 - val_mae: 2002.8309\n",
      "Epoch 134/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 897.0817 - mae: 897.7731 - val_loss: 1890.4437 - val_mae: 1891.1368\n",
      "Epoch 135/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 798.6404 - mae: 799.3333 - val_loss: 1856.5905 - val_mae: 1857.2837\n",
      "Epoch 136/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 765.1544 - mae: 765.8475 - val_loss: 2128.2727 - val_mae: 2128.9658\n",
      "Epoch 137/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 758.8696 - mae: 759.5623 - val_loss: 1865.2621 - val_mae: 1865.9551\n",
      "Epoch 138/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step - loss: 877.9491 - mae: 878.6419 - val_loss: 1820.5636 - val_mae: 1821.2566\n",
      "Epoch 139/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 67ms/step - loss: 776.4741 - mae: 777.1672 - val_loss: 1753.0239 - val_mae: 1753.7169\n",
      "Epoch 140/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 60ms/step - loss: 740.3812 - mae: 741.0733 - val_loss: 1691.9031 - val_mae: 1692.5961\n",
      "Epoch 141/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step - loss: 816.8271 - mae: 817.5201 - val_loss: 1587.4629 - val_mae: 1588.1560\n",
      "Epoch 142/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 681.7817 - mae: 682.4730 - val_loss: 1700.5984 - val_mae: 1701.2915\n",
      "Epoch 143/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 60ms/step - loss: 677.1822 - mae: 677.8750 - val_loss: 1579.6465 - val_mae: 1580.3396\n",
      "Epoch 144/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 747.9861 - mae: 748.6792 - val_loss: 1626.1425 - val_mae: 1626.8357\n",
      "Epoch 145/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 60ms/step - loss: 614.0091 - mae: 614.7007 - val_loss: 1578.1786 - val_mae: 1578.8716\n",
      "Epoch 146/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 58ms/step - loss: 696.2703 - mae: 696.9634 - val_loss: 1388.3281 - val_mae: 1389.0212\n",
      "Epoch 147/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 698.5015 - mae: 699.1939 - val_loss: 1519.5345 - val_mae: 1520.2275\n",
      "Epoch 148/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 712.2681 - mae: 712.9612 - val_loss: 1401.5793 - val_mae: 1402.2714\n",
      "Epoch 149/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 688.9492 - mae: 689.6373 - val_loss: 1349.4568 - val_mae: 1350.1499\n",
      "Epoch 150/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 58ms/step - loss: 634.8860 - mae: 635.5751 - val_loss: 1207.8999 - val_mae: 1208.5930\n",
      "Epoch 151/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 580.6207 - mae: 581.3131 - val_loss: 1329.1541 - val_mae: 1329.8472\n",
      "Epoch 152/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 644.2429 - mae: 644.9354 - val_loss: 1406.8408 - val_mae: 1407.5339\n",
      "Epoch 153/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 621.0649 - mae: 621.7579 - val_loss: 1310.3042 - val_mae: 1310.9973\n",
      "Epoch 154/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 60ms/step - loss: 559.3431 - mae: 560.0361 - val_loss: 1133.0437 - val_mae: 1133.7368\n",
      "Epoch 155/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 583.3130 - mae: 584.0052 - val_loss: 1213.0693 - val_mae: 1213.7625\n",
      "Epoch 156/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 546.4358 - mae: 547.1282 - val_loss: 1162.8496 - val_mae: 1163.5427\n",
      "Epoch 157/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 531.9600 - mae: 532.6520 - val_loss: 1184.6796 - val_mae: 1185.3728\n",
      "Epoch 158/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - loss: 573.2331 - mae: 573.9243 - val_loss: 1078.7678 - val_mae: 1079.4609\n",
      "Epoch 159/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 542.8424 - mae: 543.5346 - val_loss: 1138.5232 - val_mae: 1139.2163\n",
      "Epoch 160/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 56ms/step - loss: 573.9743 - mae: 574.6674 - val_loss: 994.4199 - val_mae: 995.1131\n",
      "Epoch 161/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 43ms/step - loss: 500.0110 - mae: 500.7039 - val_loss: 892.4537 - val_mae: 893.1467\n",
      "Epoch 162/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 41ms/step - loss: 569.8990 - mae: 570.5920 - val_loss: 856.9448 - val_mae: 857.6379\n",
      "Epoch 163/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 654.2097 - mae: 654.9026 - val_loss: 952.6020 - val_mae: 953.2950\n",
      "Epoch 164/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 543.3920 - mae: 544.0844 - val_loss: 761.9697 - val_mae: 762.6627\n",
      "Epoch 165/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 481.1992 - mae: 481.8923 - val_loss: 792.0695 - val_mae: 792.7626\n",
      "Epoch 166/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 592.8141 - mae: 593.5070 - val_loss: 793.2139 - val_mae: 793.9070\n",
      "Epoch 167/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 548.3282 - mae: 549.0183 - val_loss: 705.6365 - val_mae: 706.3297\n",
      "Epoch 168/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 55ms/step - loss: 481.5352 - mae: 482.2254 - val_loss: 606.5337 - val_mae: 607.2236\n",
      "Epoch 169/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 536.6293 - mae: 537.3210 - val_loss: 766.7946 - val_mae: 767.4877\n",
      "Epoch 170/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 480.2350 - mae: 480.9277 - val_loss: 693.5722 - val_mae: 694.2654\n",
      "Epoch 171/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 483.2305 - mae: 483.9236 - val_loss: 672.7429 - val_mae: 673.4360\n",
      "Epoch 172/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 486.7857 - mae: 487.4785 - val_loss: 693.4971 - val_mae: 694.1902\n",
      "Epoch 173/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 532.7098 - mae: 533.4015 - val_loss: 731.7559 - val_mae: 732.4491\n",
      "Epoch 174/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 534.7942 - mae: 535.4840 - val_loss: 664.7325 - val_mae: 665.4245\n",
      "Epoch 175/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 64ms/step - loss: 481.3115 - mae: 482.0014 - val_loss: 568.5010 - val_mae: 569.1942\n",
      "Epoch 176/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 481.6764 - mae: 482.3693 - val_loss: 662.8640 - val_mae: 663.5573\n",
      "Epoch 177/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 577.9420 - mae: 578.6350 - val_loss: 613.2656 - val_mae: 613.9587\n",
      "Epoch 178/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step - loss: 443.0409 - mae: 443.7321 - val_loss: 558.8109 - val_mae: 559.5042\n",
      "Epoch 179/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 57ms/step - loss: 447.1552 - mae: 447.8440 - val_loss: 552.3862 - val_mae: 553.0793\n",
      "Epoch 180/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 416.8414 - mae: 417.5337 - val_loss: 607.5415 - val_mae: 608.2346\n",
      "Epoch 181/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 60ms/step - loss: 474.0519 - mae: 474.7448 - val_loss: 546.8130 - val_mae: 547.5061\n",
      "Epoch 182/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 45ms/step - loss: 553.5965 - mae: 554.2896 - val_loss: 377.6089 - val_mae: 378.3022\n",
      "Epoch 183/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 34ms/step - loss: 577.7221 - mae: 578.4152 - val_loss: 370.2587 - val_mae: 370.9518\n",
      "Epoch 184/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 504.1602 - mae: 504.8531 - val_loss: 512.8710 - val_mae: 513.5642\n",
      "Epoch 185/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 452.2180 - mae: 452.9107 - val_loss: 483.2216 - val_mae: 483.9148\n",
      "Epoch 186/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 456.3577 - mae: 457.0453 - val_loss: 483.6111 - val_mae: 484.3043\n",
      "Epoch 187/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 483.6242 - mae: 484.3169 - val_loss: 543.4673 - val_mae: 544.1605\n",
      "Epoch 188/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 489.1172 - mae: 489.8085 - val_loss: 440.0298 - val_mae: 440.7176\n",
      "Epoch 189/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 444.1959 - mae: 444.8882 - val_loss: 495.4583 - val_mae: 496.1515\n",
      "Epoch 190/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 445.2675 - mae: 445.9583 - val_loss: 575.2897 - val_mae: 575.9829\n",
      "Epoch 191/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 450.8277 - mae: 451.5199 - val_loss: 453.6442 - val_mae: 454.3374\n",
      "Epoch 192/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 461.7395 - mae: 462.4313 - val_loss: 414.0873 - val_mae: 414.7805\n",
      "Epoch 193/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 507.5598 - mae: 508.2498 - val_loss: 470.3894 - val_mae: 471.0826\n",
      "Epoch 194/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 414.3665 - mae: 415.0594 - val_loss: 360.9363 - val_mae: 361.6291\n",
      "Epoch 195/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 452.0061 - mae: 452.6976 - val_loss: 414.7527 - val_mae: 415.4459\n",
      "Epoch 196/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 501.8624 - mae: 502.5516 - val_loss: 407.7596 - val_mae: 408.4528\n",
      "Epoch 197/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 482.4862 - mae: 483.1787 - val_loss: 362.7126 - val_mae: 363.4057\n",
      "Epoch 198/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 457.7962 - mae: 458.4854 - val_loss: 418.7560 - val_mae: 419.4492\n",
      "Epoch 199/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 35ms/step - loss: 399.0984 - mae: 399.7878 - val_loss: 332.7422 - val_mae: 333.4354\n",
      "Epoch 200/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 442.5763 - mae: 443.2693 - val_loss: 405.6215 - val_mae: 406.3146\n",
      "Epoch 201/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 481.0804 - mae: 481.7730 - val_loss: 348.0293 - val_mae: 348.7222\n",
      "Epoch 202/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 476.3406 - mae: 477.0315 - val_loss: 332.1229 - val_mae: 332.8160\n",
      "Epoch 203/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 477.5356 - mae: 478.2273 - val_loss: 501.7379 - val_mae: 502.4310\n",
      "Epoch 204/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 506.4158 - mae: 507.1088 - val_loss: 410.8818 - val_mae: 411.5750\n",
      "Epoch 205/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 446.7539 - mae: 447.4464 - val_loss: 467.1053 - val_mae: 467.7985\n",
      "Epoch 206/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 455.9531 - mae: 456.6453 - val_loss: 407.7151 - val_mae: 408.4083\n",
      "Epoch 207/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 562.1242 - mae: 562.8159 - val_loss: 498.3543 - val_mae: 499.0474\n",
      "Epoch 208/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 451.1154 - mae: 451.8082 - val_loss: 433.3536 - val_mae: 434.0468\n",
      "Epoch 209/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 483.3234 - mae: 484.0161 - val_loss: 372.2415 - val_mae: 372.9347\n",
      "Epoch 210/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 534.6169 - mae: 535.3090 - val_loss: 355.6395 - val_mae: 356.3326\n",
      "Epoch 211/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 409.9354 - mae: 410.6244 - val_loss: 357.7393 - val_mae: 358.4299\n",
      "Epoch 212/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 483.7784 - mae: 484.4710 - val_loss: 463.1907 - val_mae: 463.8839\n",
      "Epoch 213/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 444.5629 - mae: 445.2543 - val_loss: 323.5770 - val_mae: 324.2701\n",
      "Epoch 214/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 517.4051 - mae: 518.0969 - val_loss: 358.8940 - val_mae: 359.5871\n",
      "Epoch 215/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 426.4620 - mae: 427.1536 - val_loss: 358.2459 - val_mae: 358.9391\n",
      "Epoch 216/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 434.6480 - mae: 435.3391 - val_loss: 351.9456 - val_mae: 352.6387\n",
      "Epoch 217/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 501.5829 - mae: 502.2752 - val_loss: 336.3054 - val_mae: 336.9986\n",
      "Epoch 218/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 392.6430 - mae: 393.3355 - val_loss: 383.0214 - val_mae: 383.7145\n",
      "Epoch 219/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 453.1536 - mae: 453.8459 - val_loss: 336.1661 - val_mae: 336.8593\n",
      "Epoch 220/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 548.1801 - mae: 548.8723 - val_loss: 383.3896 - val_mae: 384.0828\n",
      "Epoch 221/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 451.6304 - mae: 452.3214 - val_loss: 376.2662 - val_mae: 376.9594\n",
      "Epoch 222/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 446.4636 - mae: 447.1562 - val_loss: 277.5063 - val_mae: 278.1993\n",
      "Epoch 223/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 518.4998 - mae: 519.1921 - val_loss: 407.0880 - val_mae: 407.7812\n",
      "Epoch 224/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 434.6265 - mae: 435.3193 - val_loss: 389.8591 - val_mae: 390.5523\n",
      "Epoch 225/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 499.2684 - mae: 499.9607 - val_loss: 378.5582 - val_mae: 379.2513\n",
      "Epoch 226/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 487.4887 - mae: 488.1778 - val_loss: 389.2147 - val_mae: 389.9043\n",
      "Epoch 227/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 418.9725 - mae: 419.6645 - val_loss: 290.7055 - val_mae: 291.3987\n",
      "Epoch 228/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 406.8229 - mae: 407.5144 - val_loss: 319.9698 - val_mae: 320.6581\n",
      "Epoch 229/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 509.7677 - mae: 510.4593 - val_loss: 338.0253 - val_mae: 338.7185\n",
      "Epoch 230/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 517.2263 - mae: 517.9189 - val_loss: 388.9365 - val_mae: 389.6296\n",
      "Epoch 231/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 451.5062 - mae: 452.1980 - val_loss: 354.5634 - val_mae: 355.2566\n",
      "Epoch 232/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 455.5781 - mae: 456.2712 - val_loss: 390.2528 - val_mae: 390.9460\n",
      "Epoch 233/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 484.5055 - mae: 485.1980 - val_loss: 343.4860 - val_mae: 344.1791\n",
      "Epoch 234/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 395.6072 - mae: 396.2982 - val_loss: 421.6921 - val_mae: 422.3853\n",
      "Epoch 235/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 422.2299 - mae: 422.9212 - val_loss: 352.3402 - val_mae: 353.0334\n",
      "Epoch 236/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 485.6821 - mae: 486.3748 - val_loss: 262.0018 - val_mae: 262.6949\n",
      "Epoch 237/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 542.6295 - mae: 543.3206 - val_loss: 386.7879 - val_mae: 387.4811\n",
      "Epoch 238/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 406.4913 - mae: 407.1841 - val_loss: 366.1655 - val_mae: 366.8587\n",
      "Epoch 239/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 482.8721 - mae: 483.5647 - val_loss: 305.8674 - val_mae: 306.5605\n",
      "Epoch 240/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 508.0696 - mae: 508.7626 - val_loss: 327.8004 - val_mae: 328.4935\n",
      "Epoch 241/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 458.6376 - mae: 459.3307 - val_loss: 291.3676 - val_mae: 292.0600\n",
      "Epoch 242/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 478.8726 - mae: 479.5656 - val_loss: 305.2581 - val_mae: 305.9495\n",
      "Epoch 243/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 419.6708 - mae: 420.3640 - val_loss: 312.3109 - val_mae: 313.0040\n",
      "Epoch 244/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 516.5508 - mae: 517.2405 - val_loss: 302.0700 - val_mae: 302.7632\n",
      "Epoch 245/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 455.6600 - mae: 456.3521 - val_loss: 363.2444 - val_mae: 363.9376\n",
      "Epoch 246/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 440.3610 - mae: 441.0524 - val_loss: 316.9061 - val_mae: 317.5993\n",
      "Epoch 247/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 422.9267 - mae: 423.6187 - val_loss: 283.0836 - val_mae: 283.7768\n",
      "Epoch 248/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 409.2004 - mae: 409.8934 - val_loss: 356.9773 - val_mae: 357.6705\n",
      "Epoch 249/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 442.7753 - mae: 443.4651 - val_loss: 302.6085 - val_mae: 303.3016\n",
      "Epoch 250/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 40ms/step - loss: 447.1355 - mae: 447.8285 - val_loss: 243.3448 - val_mae: 244.0379\n",
      "Epoch 251/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 458.5225 - mae: 459.2151 - val_loss: 278.8491 - val_mae: 279.5422\n",
      "Epoch 252/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 431.5508 - mae: 432.2425 - val_loss: 326.0435 - val_mae: 326.7347\n",
      "Epoch 253/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 399.6635 - mae: 400.3546 - val_loss: 354.8182 - val_mae: 355.5114\n",
      "Epoch 254/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 513.2183 - mae: 513.9114 - val_loss: 329.1580 - val_mae: 329.8511\n",
      "Epoch 255/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 398.7978 - mae: 399.4909 - val_loss: 362.4178 - val_mae: 363.1110\n",
      "Epoch 256/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 450.9032 - mae: 451.5948 - val_loss: 363.1517 - val_mae: 363.8448\n",
      "Epoch 257/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 448.5170 - mae: 449.2093 - val_loss: 269.6980 - val_mae: 270.3912\n",
      "Epoch 258/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 420.9221 - mae: 421.6141 - val_loss: 368.4850 - val_mae: 369.1781\n",
      "Epoch 259/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 477.1200 - mae: 477.8128 - val_loss: 335.7386 - val_mae: 336.4318\n",
      "Epoch 260/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 396.1994 - mae: 396.8922 - val_loss: 390.0810 - val_mae: 390.7742\n",
      "Epoch 261/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 453.4677 - mae: 454.1605 - val_loss: 368.5088 - val_mae: 369.2019\n",
      "Epoch 262/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 510.7119 - mae: 511.4042 - val_loss: 333.7736 - val_mae: 334.4668\n",
      "Epoch 263/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 501.2840 - mae: 501.9734 - val_loss: 267.9562 - val_mae: 268.6493\n",
      "Epoch 264/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 451.1909 - mae: 451.8839 - val_loss: 297.7559 - val_mae: 298.4490\n",
      "Epoch 265/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 455.6520 - mae: 456.3448 - val_loss: 292.6011 - val_mae: 293.2943\n",
      "Epoch 266/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 480.3868 - mae: 481.0784 - val_loss: 313.7820 - val_mae: 314.4751\n",
      "Epoch 267/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 431.2762 - mae: 431.9644 - val_loss: 256.0110 - val_mae: 256.7042\n",
      "Epoch 268/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 452.0522 - mae: 452.7446 - val_loss: 341.4741 - val_mae: 342.1672\n",
      "Epoch 269/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 479.2224 - mae: 479.9094 - val_loss: 403.7292 - val_mae: 404.4224\n",
      "Epoch 270/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 416.6416 - mae: 417.3340 - val_loss: 367.0650 - val_mae: 367.7582\n",
      "Epoch 271/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 543.2849 - mae: 543.9740 - val_loss: 265.6403 - val_mae: 266.3330\n",
      "Epoch 272/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 531.3762 - mae: 532.0691 - val_loss: 284.8439 - val_mae: 285.5369\n",
      "Epoch 273/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 453.3806 - mae: 454.0737 - val_loss: 313.4406 - val_mae: 314.1337\n",
      "Epoch 274/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 512.0379 - mae: 512.7309 - val_loss: 287.6699 - val_mae: 288.3631\n",
      "Epoch 275/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 410.7827 - mae: 411.4753 - val_loss: 347.0526 - val_mae: 347.7458\n",
      "Epoch 276/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 480.7253 - mae: 481.4173 - val_loss: 310.0201 - val_mae: 310.7116\n",
      "Epoch 277/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 420.5018 - mae: 421.1945 - val_loss: 298.5006 - val_mae: 299.1937\n",
      "Epoch 278/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 412.9038 - mae: 413.5954 - val_loss: 323.0602 - val_mae: 323.7534\n",
      "Epoch 279/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 442.7524 - mae: 443.4439 - val_loss: 247.2293 - val_mae: 247.9224\n",
      "Epoch 280/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 406.1199 - mae: 406.8126 - val_loss: 268.2307 - val_mae: 268.9200\n",
      "Epoch 281/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 524.8711 - mae: 525.5627 - val_loss: 340.2492 - val_mae: 340.9424\n",
      "Epoch 282/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 440.7538 - mae: 441.4394 - val_loss: 313.7990 - val_mae: 314.4915\n",
      "Epoch 283/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 465.8777 - mae: 466.5704 - val_loss: 416.7062 - val_mae: 417.3994\n",
      "Epoch 284/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 487.8519 - mae: 488.5447 - val_loss: 360.6787 - val_mae: 361.3719\n",
      "Epoch 285/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 391.0380 - mae: 391.7308 - val_loss: 284.9153 - val_mae: 285.6085\n",
      "Epoch 286/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 542.6133 - mae: 543.3025 - val_loss: 397.9085 - val_mae: 398.6012\n",
      "Epoch 287/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 402.3351 - mae: 403.0274 - val_loss: 290.5562 - val_mae: 291.2484\n",
      "Epoch 288/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 482.9339 - mae: 483.6264 - val_loss: 298.6584 - val_mae: 299.3516\n",
      "Epoch 289/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 418.4197 - mae: 419.1107 - val_loss: 243.6961 - val_mae: 244.3893\n",
      "Epoch 290/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 414.6785 - mae: 415.3700 - val_loss: 275.2118 - val_mae: 275.9050\n",
      "Epoch 291/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 416.9974 - mae: 417.6873 - val_loss: 267.2615 - val_mae: 267.9547\n",
      "Epoch 292/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 427.9462 - mae: 428.6385 - val_loss: 244.0538 - val_mae: 244.7469\n",
      "Epoch 293/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 460.9127 - mae: 461.6044 - val_loss: 320.3715 - val_mae: 321.0646\n",
      "Epoch 294/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 384.3236 - mae: 385.0153 - val_loss: 296.1809 - val_mae: 296.8740\n",
      "Epoch 295/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 470.1454 - mae: 470.8383 - val_loss: 352.7686 - val_mae: 353.4617\n",
      "Epoch 296/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 499.6135 - mae: 500.3053 - val_loss: 315.1190 - val_mae: 315.8122\n",
      "Epoch 297/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 486.9372 - mae: 487.6281 - val_loss: 278.4061 - val_mae: 279.0993\n",
      "Epoch 298/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 421.8044 - mae: 422.4964 - val_loss: 288.9036 - val_mae: 289.5941\n",
      "Epoch 299/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 460.0788 - mae: 460.7702 - val_loss: 347.4493 - val_mae: 348.1425\n",
      "Epoch 300/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 422.1293 - mae: 422.8205 - val_loss: 348.4509 - val_mae: 349.1398\n",
      "Epoch 301/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 472.7544 - mae: 473.4456 - val_loss: 283.5834 - val_mae: 284.2766\n",
      "Epoch 302/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 42ms/step - loss: 431.1631 - mae: 431.8541 - val_loss: 217.9218 - val_mae: 218.6149\n",
      "Epoch 303/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 421.7150 - mae: 422.4080 - val_loss: 270.1201 - val_mae: 270.8131\n",
      "Epoch 304/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 423.1327 - mae: 423.8224 - val_loss: 261.7580 - val_mae: 262.4511\n",
      "Epoch 305/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 395.8590 - mae: 396.5511 - val_loss: 306.5423 - val_mae: 307.2355\n",
      "Epoch 306/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 426.0405 - mae: 426.7291 - val_loss: 345.8521 - val_mae: 346.5453\n",
      "Epoch 307/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 395.8282 - mae: 396.5181 - val_loss: 352.3152 - val_mae: 353.0084\n",
      "Epoch 308/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 501.5057 - mae: 502.1971 - val_loss: 339.4446 - val_mae: 340.1377\n",
      "Epoch 309/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 458.2710 - mae: 458.9613 - val_loss: 309.6620 - val_mae: 310.3547\n",
      "Epoch 310/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 433.6628 - mae: 434.3535 - val_loss: 357.2267 - val_mae: 357.9199\n",
      "Epoch 311/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 453.3695 - mae: 454.0614 - val_loss: 370.3040 - val_mae: 370.9972\n",
      "Epoch 312/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 406.4261 - mae: 407.1165 - val_loss: 371.0762 - val_mae: 371.7694\n",
      "Epoch 313/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 390.9825 - mae: 391.6757 - val_loss: 296.5350 - val_mae: 297.2279\n",
      "Epoch 314/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 419.7231 - mae: 420.4151 - val_loss: 337.3511 - val_mae: 338.0443\n",
      "Epoch 315/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 408.8992 - mae: 409.5899 - val_loss: 315.0723 - val_mae: 315.7655\n",
      "Epoch 316/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 433.7092 - mae: 434.4021 - val_loss: 351.3846 - val_mae: 352.0778\n",
      "Epoch 317/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 422.3292 - mae: 423.0220 - val_loss: 309.7795 - val_mae: 310.4727\n",
      "Epoch 318/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 435.2059 - mae: 435.8982 - val_loss: 362.6768 - val_mae: 363.3700\n",
      "Epoch 319/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 26ms/step - loss: 435.4671 - mae: 436.1600 - val_loss: 398.7301 - val_mae: 399.4233\n",
      "Epoch 320/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 454.1615 - mae: 454.8540 - val_loss: 346.7979 - val_mae: 347.4910\n",
      "Epoch 321/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 393.3675 - mae: 394.0574 - val_loss: 283.4455 - val_mae: 284.1386\n",
      "Epoch 322/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 36ms/step - loss: 454.2263 - mae: 454.9139 - val_loss: 189.5292 - val_mae: 190.2223\n",
      "Epoch 323/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 455.1552 - mae: 455.8470 - val_loss: 214.0225 - val_mae: 214.7133\n",
      "Epoch 324/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 496.5018 - mae: 497.1917 - val_loss: 461.2072 - val_mae: 461.9005\n",
      "Epoch 325/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 518.1898 - mae: 518.8828 - val_loss: 229.4167 - val_mae: 230.1098\n",
      "Epoch 326/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 411.1492 - mae: 411.8414 - val_loss: 252.0860 - val_mae: 252.7791\n",
      "Epoch 327/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 417.5021 - mae: 418.1942 - val_loss: 336.3207 - val_mae: 337.0139\n",
      "Epoch 328/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 526.9581 - mae: 527.6511 - val_loss: 356.2880 - val_mae: 356.9811\n",
      "Epoch 329/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 465.2166 - mae: 465.9090 - val_loss: 300.0154 - val_mae: 300.7085\n",
      "Epoch 330/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 509.1207 - mae: 509.8116 - val_loss: 386.2456 - val_mae: 386.9376\n",
      "Epoch 331/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 480.0526 - mae: 480.7450 - val_loss: 415.7638 - val_mae: 416.4570\n",
      "Epoch 332/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 431.7398 - mae: 432.4319 - val_loss: 340.6091 - val_mae: 341.3023\n",
      "Epoch 333/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 482.3097 - mae: 482.9992 - val_loss: 198.3890 - val_mae: 199.0811\n",
      "Epoch 334/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 440.2112 - mae: 440.9036 - val_loss: 357.1957 - val_mae: 357.8888\n",
      "Epoch 335/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 432.4116 - mae: 433.1044 - val_loss: 300.9736 - val_mae: 301.6663\n",
      "Epoch 336/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 487.1335 - mae: 487.8257 - val_loss: 328.9584 - val_mae: 329.6516\n",
      "Epoch 337/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 481.1610 - mae: 481.8528 - val_loss: 402.6558 - val_mae: 403.3487\n",
      "Epoch 338/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 469.9773 - mae: 470.6701 - val_loss: 254.7542 - val_mae: 255.4473\n",
      "Epoch 339/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 465.0008 - mae: 465.6927 - val_loss: 371.1268 - val_mae: 371.8199\n",
      "Epoch 340/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 432.3095 - mae: 433.0011 - val_loss: 338.7404 - val_mae: 339.4336\n",
      "Epoch 341/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 540.0488 - mae: 540.7406 - val_loss: 254.9417 - val_mae: 255.6348\n",
      "Epoch 342/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 415.5344 - mae: 416.2243 - val_loss: 333.4167 - val_mae: 334.1099\n",
      "Epoch 343/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 403.6639 - mae: 404.3562 - val_loss: 294.8062 - val_mae: 295.4993\n",
      "Epoch 344/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 425.0276 - mae: 425.7170 - val_loss: 252.4441 - val_mae: 253.1372\n",
      "Epoch 345/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 395.8201 - mae: 396.5113 - val_loss: 265.2821 - val_mae: 265.9753\n",
      "Epoch 346/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 410.1879 - mae: 410.8796 - val_loss: 243.4611 - val_mae: 244.1534\n",
      "Epoch 347/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 414.8500 - mae: 415.5417 - val_loss: 343.2741 - val_mae: 343.9673\n",
      "Epoch 348/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 488.3965 - mae: 489.0893 - val_loss: 355.8942 - val_mae: 356.5873\n",
      "Epoch 349/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 491.1310 - mae: 491.8237 - val_loss: 358.9294 - val_mae: 359.6226\n",
      "Epoch 350/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 525.2057 - mae: 525.8988 - val_loss: 288.1521 - val_mae: 288.8452\n",
      "Epoch 351/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 441.7702 - mae: 442.4631 - val_loss: 303.0386 - val_mae: 303.7317\n",
      "Epoch 352/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 444.5334 - mae: 445.2248 - val_loss: 228.0546 - val_mae: 228.7422\n",
      "Epoch 353/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 451.2875 - mae: 451.9788 - val_loss: 250.2215 - val_mae: 250.9146\n",
      "Epoch 354/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 471.6860 - mae: 472.3736 - val_loss: 237.6347 - val_mae: 238.3279\n",
      "Epoch 355/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 429.8888 - mae: 430.5816 - val_loss: 220.5552 - val_mae: 221.2478\n",
      "Epoch 356/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 479.9903 - mae: 480.6828 - val_loss: 253.8157 - val_mae: 254.5088\n",
      "Epoch 357/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 416.9516 - mae: 417.6422 - val_loss: 290.3470 - val_mae: 291.0401\n",
      "Epoch 358/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 426.9138 - mae: 427.6059 - val_loss: 361.6389 - val_mae: 362.3320\n",
      "Epoch 359/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 397.0522 - mae: 397.7442 - val_loss: 281.0936 - val_mae: 281.7864\n",
      "Epoch 360/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 465.2283 - mae: 465.9212 - val_loss: 255.5057 - val_mae: 256.1989\n",
      "Epoch 361/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 389.7871 - mae: 390.4785 - val_loss: 278.8529 - val_mae: 279.5461\n",
      "Epoch 362/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 400.6385 - mae: 401.3296 - val_loss: 272.9392 - val_mae: 273.6324\n",
      "Epoch 363/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 433.0395 - mae: 433.7317 - val_loss: 255.5932 - val_mae: 256.2864\n",
      "Epoch 364/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 457.8820 - mae: 458.5746 - val_loss: 199.4483 - val_mae: 200.1412\n",
      "Epoch 365/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 479.6890 - mae: 480.3818 - val_loss: 263.1289 - val_mae: 263.8221\n",
      "Epoch 366/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 470.3685 - mae: 471.0614 - val_loss: 218.6859 - val_mae: 219.3778\n",
      "Epoch 367/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 556.0193 - mae: 556.7113 - val_loss: 303.7735 - val_mae: 304.4667\n",
      "Epoch 368/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 422.7148 - mae: 423.4055 - val_loss: 282.2779 - val_mae: 282.9711\n",
      "Epoch 369/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 38ms/step - loss: 478.5370 - mae: 479.2289 - val_loss: 173.5596 - val_mae: 174.2513\n",
      "Epoch 370/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 508.5404 - mae: 509.2334 - val_loss: 241.0970 - val_mae: 241.7889\n",
      "Epoch 371/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 527.8403 - mae: 528.5327 - val_loss: 235.1962 - val_mae: 235.8883\n",
      "Epoch 372/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 405.5684 - mae: 406.2594 - val_loss: 234.2860 - val_mae: 234.9789\n",
      "Epoch 373/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 476.9253 - mae: 477.6169 - val_loss: 419.7455 - val_mae: 420.4387\n",
      "Epoch 374/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 446.9845 - mae: 447.6764 - val_loss: 285.8413 - val_mae: 286.5333\n",
      "Epoch 375/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 447.2055 - mae: 447.8978 - val_loss: 337.5476 - val_mae: 338.2408\n",
      "Epoch 376/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 383.0967 - mae: 383.7870 - val_loss: 316.6779 - val_mae: 317.3711\n",
      "Epoch 377/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 451.5847 - mae: 452.2776 - val_loss: 296.8187 - val_mae: 297.5119\n",
      "Epoch 378/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 455.4395 - mae: 456.1310 - val_loss: 329.3495 - val_mae: 330.0426\n",
      "Epoch 379/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 444.3426 - mae: 445.0333 - val_loss: 301.4592 - val_mae: 302.1523\n",
      "Epoch 380/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 452.8513 - mae: 453.5439 - val_loss: 255.5302 - val_mae: 256.2233\n",
      "Epoch 381/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 511.4836 - mae: 512.1750 - val_loss: 241.3586 - val_mae: 242.0517\n",
      "Epoch 382/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 529.7523 - mae: 530.4448 - val_loss: 215.4600 - val_mae: 216.1532\n",
      "Epoch 383/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 498.0427 - mae: 498.7352 - val_loss: 269.1906 - val_mae: 269.8838\n",
      "Epoch 384/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 398.2610 - mae: 398.9540 - val_loss: 285.2607 - val_mae: 285.9536\n",
      "Epoch 385/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 463.0159 - mae: 463.7087 - val_loss: 337.2628 - val_mae: 337.9560\n",
      "Epoch 386/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 432.4879 - mae: 433.1767 - val_loss: 322.4904 - val_mae: 323.1835\n",
      "Epoch 387/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 413.3875 - mae: 414.0801 - val_loss: 227.5417 - val_mae: 228.2349\n",
      "Epoch 388/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 431.1973 - mae: 431.8858 - val_loss: 260.3004 - val_mae: 260.9882\n",
      "Epoch 389/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 431.6357 - mae: 432.3287 - val_loss: 317.9970 - val_mae: 318.6902\n",
      "Epoch 390/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 413.1850 - mae: 413.8775 - val_loss: 255.6490 - val_mae: 256.3422\n",
      "Epoch 391/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 429.4306 - mae: 430.1208 - val_loss: 276.7885 - val_mae: 277.4816\n",
      "Epoch 392/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 419.9078 - mae: 420.6006 - val_loss: 224.4268 - val_mae: 225.1198\n",
      "Epoch 393/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 458.6847 - mae: 459.3753 - val_loss: 288.1452 - val_mae: 288.8384\n",
      "Epoch 394/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 504.1398 - mae: 504.8291 - val_loss: 221.6633 - val_mae: 222.3564\n",
      "Epoch 395/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 451.6266 - mae: 452.3192 - val_loss: 305.2138 - val_mae: 305.9069\n",
      "Epoch 396/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 418.1928 - mae: 418.8850 - val_loss: 293.4926 - val_mae: 294.1833\n",
      "Epoch 397/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 455.0172 - mae: 455.7047 - val_loss: 260.5054 - val_mae: 261.1985\n",
      "Epoch 398/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 457.6154 - mae: 458.3051 - val_loss: 246.5702 - val_mae: 247.2632\n",
      "Epoch 399/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 416.4223 - mae: 417.1152 - val_loss: 175.7655 - val_mae: 176.4569\n",
      "Epoch 400/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 504.8904 - mae: 505.5826 - val_loss: 278.9480 - val_mae: 279.6394\n",
      "Epoch 401/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 453.8301 - mae: 454.5214 - val_loss: 279.8634 - val_mae: 280.5565\n",
      "Epoch 402/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 410.5179 - mae: 411.2089 - val_loss: 301.9866 - val_mae: 302.6797\n",
      "Epoch 403/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 488.4500 - mae: 489.1430 - val_loss: 307.3210 - val_mae: 308.0142\n",
      "Epoch 404/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 458.5174 - mae: 459.2094 - val_loss: 220.6372 - val_mae: 221.3304\n",
      "Epoch 405/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 500.8045 - mae: 501.4974 - val_loss: 238.9769 - val_mae: 239.6700\n",
      "Epoch 406/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 388.3367 - mae: 389.0286 - val_loss: 216.0644 - val_mae: 216.7576\n",
      "Epoch 407/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 465.0742 - mae: 465.7655 - val_loss: 302.8651 - val_mae: 303.5582\n",
      "Epoch 408/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 463.0433 - mae: 463.7350 - val_loss: 245.2872 - val_mae: 245.9803\n",
      "Epoch 409/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 411.2946 - mae: 411.9876 - val_loss: 276.2744 - val_mae: 276.9675\n",
      "Epoch 410/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 419.5388 - mae: 420.2315 - val_loss: 336.4839 - val_mae: 337.1771\n",
      "Epoch 411/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 440.0139 - mae: 440.7068 - val_loss: 228.2156 - val_mae: 228.9072\n",
      "Epoch 412/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 400.2789 - mae: 400.9715 - val_loss: 219.9345 - val_mae: 220.6277\n",
      "Epoch 413/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 481.3903 - mae: 482.0819 - val_loss: 233.9007 - val_mae: 234.5939\n",
      "Epoch 414/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 429.5516 - mae: 430.2445 - val_loss: 318.6464 - val_mae: 319.3396\n",
      "Epoch 415/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 492.3887 - mae: 493.0815 - val_loss: 306.2042 - val_mae: 306.8973\n",
      "Epoch 416/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 439.2961 - mae: 439.9876 - val_loss: 265.8805 - val_mae: 266.5736\n",
      "Epoch 417/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 432.8457 - mae: 433.5386 - val_loss: 260.1853 - val_mae: 260.8779\n",
      "Epoch 418/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 547.9044 - mae: 548.5948 - val_loss: 241.8887 - val_mae: 242.5819\n",
      "Epoch 419/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 429.8776 - mae: 430.5703 - val_loss: 277.7024 - val_mae: 278.3955\n",
      "Epoch 420/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 436.0617 - mae: 436.7541 - val_loss: 328.5297 - val_mae: 329.2228\n",
      "Epoch 421/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 469.0540 - mae: 469.7456 - val_loss: 263.5443 - val_mae: 264.2375\n",
      "Epoch 422/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 514.0315 - mae: 514.7210 - val_loss: 241.5824 - val_mae: 242.2720\n",
      "Epoch 423/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 442.8615 - mae: 443.5546 - val_loss: 233.7482 - val_mae: 234.4413\n",
      "Epoch 424/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 501.5873 - mae: 502.2801 - val_loss: 384.0373 - val_mae: 384.7305\n",
      "Epoch 425/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 427.8353 - mae: 428.5283 - val_loss: 312.1473 - val_mae: 312.8392\n",
      "Epoch 426/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 411.2032 - mae: 411.8952 - val_loss: 304.1928 - val_mae: 304.8848\n",
      "Epoch 427/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 445.3010 - mae: 445.9939 - val_loss: 244.8324 - val_mae: 245.5221\n",
      "Epoch 428/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 431.4086 - mae: 432.0998 - val_loss: 283.9598 - val_mae: 284.6529\n",
      "Epoch 429/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 472.5299 - mae: 473.2200 - val_loss: 343.2049 - val_mae: 343.8981\n",
      "Epoch 430/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 433.6809 - mae: 434.3739 - val_loss: 237.8623 - val_mae: 238.5548\n",
      "Epoch 431/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 504.4602 - mae: 505.1506 - val_loss: 255.3543 - val_mae: 256.0475\n",
      "Epoch 432/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 424.3742 - mae: 425.0655 - val_loss: 200.3996 - val_mae: 201.0879\n",
      "Epoch 433/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 21ms/step - loss: 457.7334 - mae: 458.4263 - val_loss: 191.0440 - val_mae: 191.7371\n",
      "Epoch 434/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 576.7170 - mae: 577.4092 - val_loss: 207.5232 - val_mae: 208.2163\n",
      "Epoch 435/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 516.9458 - mae: 517.6368 - val_loss: 252.5147 - val_mae: 253.2078\n",
      "Epoch 436/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 404.5454 - mae: 405.2339 - val_loss: 277.5163 - val_mae: 278.2094\n",
      "Epoch 437/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 25ms/step - loss: 381.0186 - mae: 381.7118 - val_loss: 252.3520 - val_mae: 253.0452\n",
      "Epoch 438/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 512.5366 - mae: 513.2256 - val_loss: 224.4009 - val_mae: 225.0933\n",
      "Epoch 439/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 481.9558 - mae: 482.6487 - val_loss: 242.5964 - val_mae: 243.2896\n",
      "Epoch 440/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 394.1265 - mae: 394.8175 - val_loss: 274.0002 - val_mae: 274.6933\n",
      "Epoch 441/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 419.2687 - mae: 419.9613 - val_loss: 276.7844 - val_mae: 277.4776\n",
      "Epoch 442/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 410.9915 - mae: 411.6807 - val_loss: 263.6152 - val_mae: 264.3084\n",
      "Epoch 443/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 448.4149 - mae: 449.1073 - val_loss: 298.2435 - val_mae: 298.9366\n",
      "Epoch 444/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 419.6524 - mae: 420.3444 - val_loss: 276.4248 - val_mae: 277.1177\n",
      "Epoch 445/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 492.5968 - mae: 493.2898 - val_loss: 294.6034 - val_mae: 295.2966\n",
      "Epoch 446/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 433.3351 - mae: 434.0263 - val_loss: 310.8328 - val_mae: 311.5214\n",
      "Epoch 447/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 408.7133 - mae: 409.4056 - val_loss: 259.4331 - val_mae: 260.1263\n",
      "Epoch 448/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 414.2567 - mae: 414.9479 - val_loss: 268.5149 - val_mae: 269.2080\n",
      "Epoch 449/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 416.0592 - mae: 416.7499 - val_loss: 209.2919 - val_mae: 209.9850\n",
      "Epoch 450/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 400.5208 - mae: 401.2113 - val_loss: 200.9627 - val_mae: 201.6537\n",
      "Epoch 451/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 428.6482 - mae: 429.3410 - val_loss: 225.9630 - val_mae: 226.6561\n",
      "Epoch 452/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 515.7716 - mae: 516.4637 - val_loss: 207.0625 - val_mae: 207.7551\n",
      "Epoch 453/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 420.2503 - mae: 420.9413 - val_loss: 229.2964 - val_mae: 229.9881\n",
      "Epoch 454/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 429.9342 - mae: 430.6271 - val_loss: 310.1386 - val_mae: 310.8318\n",
      "Epoch 455/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 402.5429 - mae: 403.2340 - val_loss: 246.5365 - val_mae: 247.2297\n",
      "Epoch 456/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 27ms/step - loss: 342.9763 - mae: 343.6681 - val_loss: 245.0322 - val_mae: 245.7229\n",
      "Epoch 457/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 386.7172 - mae: 387.4077 - val_loss: 275.1979 - val_mae: 275.8911\n",
      "Epoch 458/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 495.1490 - mae: 495.8413 - val_loss: 306.5128 - val_mae: 307.2058\n",
      "Epoch 459/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 442.1142 - mae: 442.8060 - val_loss: 277.0374 - val_mae: 277.7305\n",
      "Epoch 460/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 24ms/step - loss: 374.3334 - mae: 375.0251 - val_loss: 240.6181 - val_mae: 241.3112\n",
      "Epoch 461/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 439.0046 - mae: 439.6973 - val_loss: 265.1022 - val_mae: 265.7953\n",
      "Epoch 462/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 468.6014 - mae: 469.2941 - val_loss: 285.0333 - val_mae: 285.7265\n",
      "Epoch 463/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 431.4585 - mae: 432.1483 - val_loss: 325.1438 - val_mae: 325.8369\n",
      "Epoch 464/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 420.9937 - mae: 421.6861 - val_loss: 232.0708 - val_mae: 232.7639\n",
      "Epoch 465/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 450.8303 - mae: 451.5230 - val_loss: 210.7694 - val_mae: 211.4607\n",
      "Epoch 466/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 447.3070 - mae: 447.9993 - val_loss: 275.2657 - val_mae: 275.9561\n",
      "Epoch 467/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 491.5473 - mae: 492.2398 - val_loss: 304.7092 - val_mae: 305.4023\n",
      "Epoch 468/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 23ms/step - loss: 471.5806 - mae: 472.2725 - val_loss: 323.7158 - val_mae: 324.4090\n",
      "Epoch 469/5000\n",
      "\u001B[1m16/16\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 22ms/step - loss: 404.5935 - mae: 405.2858 - val_loss: 271.3864 - val_mae: 272.0795\n",
      "Epoch 469: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x208b411e970>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LRZ1nHe0Gjy5"
   },
   "source": [
    "# **Testing Model**"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:12.879185Z",
     "start_time": "2024-04-25T06:27:12.865663Z"
    }
   },
   "cell_type": "code",
   "source": "#model.save('LSTM_complete_model344.h5', overwrite=True)",
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyAUCY0FGwsM",
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:12.894694Z",
     "start_time": "2024-04-25T06:27:12.880687Z"
    }
   },
   "source": [
    "#from tensorflow.keras.models import load_model\n",
    "#loaded_model = load_model('LSTM_complete_model344.h5')"
   ],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:12.910215Z",
     "start_time": "2024-04-25T06:27:12.896206Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "lT71_QwcHEof",
    "outputId": "674692de-7a3b-4e60-addc-39ce1d9a328d",
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.251176Z",
     "start_time": "2024-04-25T06:27:12.911716Z"
    }
   },
   "source": "y_pred = np.ravel(model.predict(X_test))",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 3ms/step  \n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.266696Z",
     "start_time": "2024-04-25T06:27:13.252678Z"
    }
   },
   "source": [
    "y_test=np.ravel(y_test)"
   ],
   "outputs": [],
   "execution_count": 56
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.282215Z",
     "start_time": "2024-04-25T06:27:13.268196Z"
    }
   },
   "cell_type": "code",
   "source": "y_pred",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([19858.191, 20646.291, 20984.748, 21235.31 , 21299.861, 21013.057,\n",
       "       20823.135, 21150.578, 21340.031, 21330.9  , 21140.402, 20305.383,\n",
       "       19696.863, 19624.488, 19862.545, 20044.982, 19943.525, 19922.396,\n",
       "       19652.943, 19658.479, 19656.328, 19648.236, 19064.178, 19016.865,\n",
       "       20001.602, 21011.85 , 21166.98 , 20585.477, 19797.648, 19367.979,\n",
       "       19563.605, 19642.004, 19287.393, 19016.805, 18837.623, 18873.127,\n",
       "       18834.574, 18860.82 , 18857.117, 18897.709, 19358.252, 19187.738,\n",
       "       19243.99 , 19130.193, 19090.475, 18875.576, 18925.404, 19417.557,\n",
       "       19740.3  , 19841.73 , 19544.973, 19197.71 , 19009.326, 19085.848,\n",
       "       18934.295, 18849.795, 18809.984, 19162.723, 19001.586, 18994.273,\n",
       "       19030.705, 19264.564, 19167.234, 18949.979, 18828.68 , 18892.367,\n",
       "       19001.246, 19136.762, 19326.121, 20058.518, 20454.88 , 20391.596,\n",
       "       20448.764, 20458.77 , 20442.727, 20309.736, 20265.34 , 20188.426,\n",
       "       20360.889, 20780.746, 21180.31 , 20772.547, 19494.826, 17671.793,\n",
       "       16145.537, 16387.627, 16454.674, 16276.973, 16424.115, 16450.523,\n",
       "       16464.152, 16491.695, 16463.621, 16546.959, 16445.947, 16352.108,\n",
       "       16292.762, 16466.219, 16808.6  , 16826.943, 16745.078, 16719.791,\n",
       "       16851.043, 16659.658, 16562.62 , 16516.94 , 16777.758, 16871.107,\n",
       "       16895.307, 16719.66 , 16912.203, 16858.059, 16255.702, 16151.738,\n",
       "       16352.262, 16498.232, 16569.777, 16597.086, 16607.375, 16609.533,\n",
       "       16627.682, 16641.86 , 16631.434, 16530.424, 16432.117, 16351.437,\n",
       "       16362.191, 16374.129], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.297732Z",
     "start_time": "2024-04-25T06:27:13.284215Z"
    }
   },
   "source": [
    "r2=r2_score(y_test,y_pred) #testing score/ r^2\n",
    "r2"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9594395957925618"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.313242Z",
     "start_time": "2024-04-25T06:27:13.299733Z"
    }
   },
   "source": [
    "mae=mean_absolute_error(y_test,y_pred) #mae\n",
    "mae"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272.07953"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.328689Z",
     "start_time": "2024-04-25T06:27:13.314667Z"
    }
   },
   "source": [
    "rmse=np.sqrt(mean_squared_error(y_test,y_pred)) #rmse\n",
    "rmse"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "325.80548"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.343921Z",
     "start_time": "2024-04-25T06:27:13.330464Z"
    }
   },
   "source": [
    "mape=mean_absolute_percentage_error(y_test,y_pred) #mape\n",
    "mape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4558171853423119"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.359489Z",
     "start_time": "2024-04-25T06:27:13.345926Z"
    }
   },
   "source": [
    "pd.DataFrame(zip(['MAE','RMSE','MAPE','R^2'],[mae,rmse,mape,r2])).transpose()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            0           1         2        3\n",
       "0         MAE        RMSE      MAPE      R^2\n",
       "1  272.079529  325.805481  1.455817  0.95944"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>RMSE</td>\n",
       "      <td>MAPE</td>\n",
       "      <td>R^2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>272.079529</td>\n",
       "      <td>325.805481</td>\n",
       "      <td>1.455817</td>\n",
       "      <td>0.95944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.374924Z",
     "start_time": "2024-04-25T06:27:13.361490Z"
    }
   },
   "source": [
    "pd.DataFrame([y_test,y_pred]).transpose()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           0             1\n",
       "0    20382.0  19858.191406\n",
       "1    20722.0  20646.291016\n",
       "2    21030.0  20984.748047\n",
       "3    21455.0  21235.310547\n",
       "4    21490.0  21299.861328\n",
       "..       ...           ...\n",
       "123  16643.0  16530.423828\n",
       "124  16579.0  16432.117188\n",
       "125  16567.0  16351.436523\n",
       "126  16561.0  16362.191406\n",
       "127  16627.0  16374.128906\n",
       "\n",
       "[128 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20382.0</td>\n",
       "      <td>19858.191406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20722.0</td>\n",
       "      <td>20646.291016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21030.0</td>\n",
       "      <td>20984.748047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21455.0</td>\n",
       "      <td>21235.310547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21490.0</td>\n",
       "      <td>21299.861328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>16643.0</td>\n",
       "      <td>16530.423828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>16579.0</td>\n",
       "      <td>16432.117188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>16567.0</td>\n",
       "      <td>16351.436523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>16561.0</td>\n",
       "      <td>16362.191406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>16627.0</td>\n",
       "      <td>16374.128906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.390442Z",
     "start_time": "2024-04-25T06:27:13.376433Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.405991Z",
     "start_time": "2024-04-25T06:27:13.392322Z"
    }
   },
   "source": [],
   "outputs": [],
   "execution_count": 63
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T06:27:13.421205Z",
     "start_time": "2024-04-25T06:27:13.407497Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 63
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Stock Market Predictor.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
